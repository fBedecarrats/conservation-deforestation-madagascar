[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Impact des aires protégées sur la déforestation : guide de formation pratique",
    "section": "",
    "text": "Ce contenu a été développé afin de servir de support pédagogique pour l’atelier “évaluation des politiques” de la session 2022 des Universités en sciences sociales Tany Vao. Les universités Tany Vao visent à dispenser une formation à la recherche de haut niveau à l’attention de doctorants et jeunes chercheurs de Madagascar et d’Afrique de l’Ouest. Après deux jours de plénières, les participants se répartissent pendant cinq jours entre quatre ateliers parallèles : socioéconomie, éthno-écologie, anthropologie et évaluation des politiques.\nL’atelier “évaluation des politiques” adopte une approche axée sur l’économétrie et la science des données. Il alterne des sessions théorique et pratique. Conformément au thème phare de Tany Vao pour 2022 (“environnement et sociétés”), le cas d’étude choisi pour servir de fil rouge à ces travaux est l’impact des aires protégées sur la déforestation.\nPhoto en couverture : “Déforestation à Madagascar” © IRD - Bernard Moizo"
  },
  {
    "objectID": "00-intro.html#outils-utilisés",
    "href": "00-intro.html#outils-utilisés",
    "title": "Introduction",
    "section": "Outils utilisés",
    "text": "Outils utilisés\n\nNotebook Quarto\nLes éléments ci-dessous constituent le support pour les sessions pratiques de cet atelier. Ils sont réalisés en suivant une approche ouverte et reproductible fondée sur un document de type “notebook” (Bédécarrats and Hobeika 2017). Un notebook rassemble à la fois :\n\nles lignes de code du programme statistique qui traite les données ;\nles résultats (calculs, tableaux, graphiques…) produits lors de l’exécution de ce programme ;\nle texte rédigé par les auteurs pour expliquer le processus d’analyse et en interpréter les résultats.\n\nL’intérêt du format notebook, par rapport à l’utilisation de documents distincts pour traiter les données d’une part, et en analyser les résultats d’autre part, est multiple :\n\nfavoriser la reproductibité de la recherche (tout le processus de traitement, analyse, interprétation peut être inspecté et dupliqué) ;\nfaciliter le travail du chercheur (une interface pour tout faire) ; et\nassurer les meilleures pratiques de collaboration (utilisation pour le versionnage, partage et fusion des travaux les outils performants développés en programmation informatique).\n\nLes traitements sont réalisés en R, qui est à la fois un logiciel et un langage open sources dédiés à l’analyse de données. Les traitements R sont inclus dans un document Quarto, un format qui exécute aussi bien des codes en R, Python, e rendus dans différents formats (LaTeX/PDF, HTML ou Word).\nLa mise en forme des rendus Quarto est paramétrable. Ici, on a notamment placé un argument code-fold: true dans le fichier _quarto.yml. Cela fait que les blocs de code ne sont pas visible dans le rendu web par défaut : il faut cliquer sur “code” pour les déplier.\n\n\nMapme.biodiversity\nOn s’appuie sur le package R {mapme.biodiversity}, développé par la KfW dans le cadre de l’initiative commune MAPME qui associe la KfW et l’AFD. Le package {mapme.biodiversity} facilite l’acquisition et la préparation d’un grand nombre de données (CHIRPS, Global Forest Watch, FIRMS, SRTM, Worldpop…) et calculer un grand nombre d’indicateurs de manière harmonisée (active_fire_counts, biome classification, land cover classification, population count, precipitation, soil properties, tree cover loss, travel time…). Une documentation riche est disponible sur le portail dédié du package en question (Kluve et al. 2022).\nOn mobilise aussi les codes d’analyse d’impact développés par la même équipe et mises à disposition dans le dépôt Github: https://github.com/openkfw/mapme.protectedareas. Le code développé par l’équipe est assez complexe. A des fins pédagogiques et pour s’assurer qu’on l’a bien compris, on propose ici une version simplifiée (en cours de développement).\n\n\nOnyxia/SSP Cloud\nLes sources pour l’ensemble du code source et du texte du présent document est accessible sur Github à l’adresse suivante : https://github.com/fBedecarrats/conservation-deforestation-madagascar. Les analyses sont menées sur la plateforme SSP Cloud, mises à disposition par l’INSEE pour les data scientists travaillant pour des administrations publiques. Il s’agit d’une instance de stockage de données massif (S3) et de calcul haute performance (cluster Kubernetes) disposant d’une interface simplifiée permettant à l’utilisateur de configurer, lancer et administrer facilement des environnements de traitement de données (RStudio server, Jupyter lab ou autres…). Le code est conçu pour s’exécuter de la même manière en local sur un PC, mais la préparation des données sera certainement beaucoup plus longue à exécuter.\n\n\nLibrairies R\nOutre Mapme.biodiversity, on mobilise une série de librairies (appelées “packages” en R), qui facilitent grandement l’analyse. Elles sont listées dans le bloc ci-dessous.\n\n\nCode\n# # Le package est en cours de développement, toujours installer la version en cours\n# remotes::install_github(\"mapme-initiative/mapme.biodiversity\", \n#                         upgrade = \"always\")\n\nlibrairies_requises <- c( # On liste les librairies dont on a besoin\n  \"tidyverse\", # Une série de packages pour faciliter la manipulation de données\n  \"readxl\", # Pour lire les fichiers excel (Carvalho et al. 2018)\n  \"cowplot\", # Pour arranger des graphiques en illustrations composées\n  \"gt\", # Pour des rendus graphiques harmonisés html et pdf/LaTeX\n  \"sf\", # Pour faciliter la manipulation de données géographiques\n  \"wdpar\", # Pour télécharger simplement la base d'aires protégées WDPA\n  \"webdriver\", # requis pour installer phantomjs pour wdpar\n  \"tmap\", # Pour produire de jolies carte\n  \"geodata\", # Pour télécharger simplement les frontières administratives\n  \"tidygeocoder\", # pour obtenir les coordo GPS d'un point à partir de son nom\n  \"maptiles\", # Pour télécharger des fonds de carte \n  \"mapme.biodiversity\", # Acquisition et traitement des données du projet\n  \"plm\", # Linear Models for Panel Data and robust covariance matrices\n  \"broom\", # pour reformater simplement les rendus de tests statistiques\n  \"stargazer\", # Reformater de manière plus lisible les résumé des régressions\n  \"MatchIt\", # Pour le matching\n  #\"glm\", # Modèles linéaires généralisés (pour le PSM)\n  \"optmatch\", # Fonctions d'optimisation du matching\n  \"rgee\",\n  \"rgeeExtra\",\n  \"cobalt\") # Tables et graphs d'équilibre des groupes de matching\n  \n# On regarde parmi ces librairies lesquelles ne sont pas installées\nmanquantes <- !(librairies_requises %in% installed.packages())\n# On installe celles qui manquent\nif(any(manquantes)) install.packages(librairies_requises[manquantes])\n\n## On charge toutes les librairies requises\n## On fera le chargement dans le chapitres pour expliciter les manips\n# invisible(lapply(librairies_requises, require, character.only= TRUE))\n\n# TODO : repasser les paramètres ci-dessous en clair dans les chapitres\n# Système de coordonnées géographiques utilisées pour le projet : EPSG:29739\nmon_scr <- \"EPSG:29739\" # correspondant à Tananarive / UTM zone 39S\n# Surface des hexagones en km2\ntaille_hex <- 5\n# Taille des titres des cartes\ntaille_titres_cartes = 1\n# on crée un dossier de données si pas déjà disponible\ndir.create(\"data\")\n# Désactiver les notations scientifiques\noptions(scipen =999)"
  },
  {
    "objectID": "00-intro.html#mode-demploi",
    "href": "00-intro.html#mode-demploi",
    "title": "Introduction",
    "section": "Mode d’emploi",
    "text": "Mode d’emploi\n\n\n\n\nBédécarrats, Florent, and Alexandre Hobeika. 2017. “Une Alternative à Word : Écrire En RMarkdown.” Billet. Data Sciences Sociales. http://data.hypotheses.org/1144.\n\n\nKluve, Jochen, Johannes Schielain, Melvin Wong, and Yota Eilers. 2022. “The KfW Protected Areas Portfolio: A Rigorous Impact Evaluation.” Frankfürt."
  },
  {
    "objectID": "01-aires_protegees.html#données-de-lassociation-vahatra",
    "href": "01-aires_protegees.html#données-de-lassociation-vahatra",
    "title": "1  Aires protégées",
    "section": "1.1 Données de l’association Vahatra",
    "text": "1.1 Données de l’association Vahatra\nLes études sur les aires protégées s’appuient fréquemment sur la base WDPA (World Database on Protected Area), consultable en ligne sur https://protectedplanet.net. On s’aperçoit dans le cas de Madagascar que cette base de données comporte de nombreuses erreurs (qu’on étudiera plus bas). La base rassemblée par l’association Vahatra dans le cadre de la monographie qu’elle a coordonnée sur l’ensemble des aires protégées terrestres malgaches semble beaucoup plus fiable (Goodman et al. 2018). Les données en question sont disponibles sur le portail https://protectedareas.mg avec une licence creative commons (CC-BY).\nLe bloc de code ci-dessous (cliquer sur “code” pour visualiser), présente la séquence d’opérations réalisées pour préparer les données.Pour comprendre certaines opérations contenues dans le bloc de code, il est utile d’être familier de la syntaxe de R et des packages du tidyverse. Voir le chapitre (fondamentaux_R?).\n\n\nCode\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(sf)\nlibrary(tmap)\nlibrary(geodata)\nlibrary(cowplot)\nlibrary(wdpar)\nlibrary(gt) # Pour faciliter le rendu des tableaux (et ils sont jolis)\n\n# Le shapefile est composé d'une série de fichiers, (.shp, .dbf, .prj, .shx)\n# qui doivent avoir le même nom et être au même endroits pour être ouverts en\n# même temps. Comme souvent, ils sont compressés ensemble dans un fichier zip.\n# On commence par dézipper (décompresser) ce fichier.\nunzip(\"data/Vahatra98AP.zip\", exdir = \"data/Vahatra\")\n# On importe dans R en pointant vers le fichier .shp, mais c'est bien toute la\n# collection de fichiers homonymes .shp, .dbf, .shx qui est chargée.\nAP_Vahatra <- st_read(\"data/Vahatra/Vahatra98AP.shp\", quiet = TRUE) %>%\n  # Il manque la projection (pas de fichier .prj), on la spécifie à la main\n  st_set_crs(\"EPSG:4326\") # EPSG 4325 = WSG 84 = le standard pour le web\n\n# L'option ci-dessous est un peu cryptique : des caractéristiques topologiques\n# de la carte source sont incompatibles avec la possibilité d'avoir des objets\n# sphériques dans sf. Cela disparait si on désactive cette possibilité\nsf_use_s2(FALSE) \n\n# Identification des dates ----------------------------------------------------\n# Cette section est un brin complexe, à base de manipulation de chaînes de \n# caractères et de dates\n\n# Détecte les dates écrites 2 avril 2020 ou 02 avril 2020, etc.\ndate_ecrite <- \"[:digit:]{1,2} [:alpha:]* [:digit:]{4}\"\n# Détecte les dates écrites 02/04/20 ou 02.04.20 ou 02.04.2020, etc.\ndate_abrev <- \"[:digit:]{2}[:punct:][:digit:]{2}[:punct:][:digit:]{2,4}\"\n# Des années écrites à 2 chiffres\ndate_ecrite_an_abrev <- \"[:digit:]{1,2} [:alpha:]* [:digit:]{4}\"\n# Détecte l'une ou l'autre des formes précédentes\ntoute_date <- paste(date_ecrite, date_abrev, date_ecrite_an_abrev, sep = \"|\")\n# Détecte une mention d'année seule : 1984, 2015, etc.\nannee_seule <- \"[:digit:]{4}\"\n# Détecte les formes indicatrices d'un changement\nmention_changement <- \"Changement|changement|anciennement|actuel|auparavant\"\n# Une fonction qui traduit les dates écrites en toutes lettre du français à \n# l'anglais (pour les parser ensuite car ça ne fonctionne qu'en anglais)\ntrad_dates <- function(date_fr) {\n  str_replace_all(date_fr,\n                  c(\"janvier\" = \"January\",\n                    \"fevrier\" = \"February\",\n                    \"mars\" = \"March\",\n                    \"avril\" = \"April\",\n                    \"mai\" = \"May\",\n                    \"juin\" = \"June\",\n                    \"juillet\" = \"July\",\n                    \"aout\" = \"August\",\n                    \"septembre|setembre\" = \"September\",\n                    \"octobre\" = \"October\",\n                    \"novembre\" = \"November\",\n                    \"decembre|decmbre\" = \"December\"))\n}\n# Cette fonction remplace 01.04.58 par 01.04.1958 et marche avec . ou /\n# On indique avec limite le nombre d'année où on considère que c'est 1900 vs 2000\ncomplete_annee <- function(date_abrev, limite = 20) {\n  if (str_detect(date_abrev, \"([:punct:])([:digit:]{2})[:punct:]?$\")) {\n    date_abrev <- str_remove(date_abrev, \":punct:]?$\")\n    if (as.numeric(str_extract(date_abrev, \"[:digit:]{2}$\")) > limite) {\n      date_abrev <- str_replace(date_abrev, \n                                \"([:punct:])([:digit:]{2})[:punct:]?$\", \"\\\\119\\\\2\")\n    } else {\n      date_abrev <- str_replace(date_abrev, \n                                \"([:punct:])([:digit:]{2})[:punct:]?$\", \"\\\\120\\\\2\")\n    }\n  }\n  return(date_abrev)\n}\n# La fonction précédente est unitaire, on la transforme pour qu'elle s'applique à une liste.\ncomplete_liste_dates <- function(liste_dates) {\n  map(liste_dates, complete_annee)\n}\n\nAP_Vahatra <- AP_Vahatra %>%\n  # On extrait les dates des champs de texte\n  mutate(date_creation = str_extract_all(creation, toute_date), \n         # Une date a un format incohérent, on la recode à la main\n         date_creation = ifelse(creation == \"Créée le 07 aout 04\",\n                                \"07 aout 2004\", date_creation),\n         date_creationA = map(date_creation, 1), # La 1ère date\n         date_creationB = map(date_creation, 2)) %>% # Si 2 dates, la seconde\n  # On traduit les mois en anglais pour une conversion au format date\n  mutate(across(c(\"date_creationA\", \"date_creationB\"), trad_dates)) %>%\n  mutate(across(c(\"date_creationA\", \"date_creationB\"), complete_liste_dates)) %>%\n  mutate(across(c(\"date_creationA\", \"date_creationB\"), dmy)) %>%\n  mutate(date_creation = case_when(is.na(date_creationB) ~ date_creationA,\n                                    date_creationA > date_creationB ~ date_creationB,\n                                    date_creationA <= date_creationB ~ date_creationA),\n         date_modification = case_when(is.na(date_creationB) ~ date_creationB,\n                                       date_creationA < date_creationB ~ date_creationB,\n                                       date_creationA >= date_creationB ~ date_creationA),\n         # On repère si il y a eu un changement de statut ou de frontières\n         mention_changement = str_detect(creation, mention_changement)) %>%\n    # On enlève les colonnes inutiles\n  select(-date_creationA, -date_creationB) %>%\n  # On place les colonnes créées à gauche pour les inspecter facilement\n  relocate(date_creation:mention_changement, .after = creation) \n\n# Après une vérification manuelle, on remarque les données de l'association Vahatra comportent des mentions incomplètes pour certaines aires, qui n'ont pas été extraites:\n\n\n# Lokobe : 31 décembre 1927\nAP_Vahatra <- AP_Vahatra %>%\n  mutate(date_creation = case_when(nom == \"Lokobe\" ~ ymd(\"1927-12-31\"),\n                                   nom == \"Mantadia\" ~ ymd(\"1989-01-11\"),\n                                   TRUE ~ date_creation),\n         date_modification = case_when(nom == \"Bemaraha\" ~ ymd(\"2011-07-06\"),\n                                       nom == \"Lokobe\" ~ ymd(\"2011-07-06\"),\n                                       nom == \"Tsaratanana\" ~ ymd(\"2011-07-06\"),\n                                       nom == \"Pic d'Ivohibe\" ~ ymd(\"2015-04-28\"),\n                                       nom == \"Mantadia\" ~ ymd(\"2002-08-07\"),\n                                       TRUE ~ date_modification)) %>%\n  st_make_valid() # fiabilise qu'il n'y a pas d'erreurs topologiques\n# dir.create(\"AP_Vahatra\")\n# st_write(AP_Vahatra, \"out/AP_Vahatra.shp\")\n# writexl::write_xlsx(st_drop_geometry(AP_Vahatra), \"AP_Vahatra.xlsx\")\n\n\nLe bloc de code suivant génère une carte interactive. On a également inclus des lignes de code qui permettent de formater la carte joliment pour un rendu figé (pdf/LaTeX, html statique, word), mais ce code est “commenté”, c’est-à-dire qu’on a placé des dièses au début de chaque ligne, de sorte qu’il ne s’exécute pas (R n’exécute jamais ce qui se trouve à droite d’un # sur une ligne). Pour plus de détails sur la manière dont on produit des cartes, voire l’annexe : Cartes simples en R\n\n\nCode\nif (file.exists(\"data/contour_mada.rds\")) {\n  load(\"data/contour_mada.rds\")\n} else {\n  contour_mada <- gadm(country = \"Madagascar\", resolution = 1, level = 0,\n                     path = \"data/GADM\") %>%\n  st_as_sf()\n# On enregistre contour_mada pour s'en servir par la suite\nsave(contour_mada, file = \"data/contour_mada.rds\")\n}\n\n# On génère un rendu cartographique\ntmap_mode(\"view\") # En mode interactif\ntm_shape(contour_mada) +\n  tm_borders() +\n  tm_shape(AP_Vahatra) + \n  tm_polygons(col = \"cat__iucn\", alpha = 0.6, title = \"Catégorie IUCN\") +\n  tmap_options(check.and.fix = TRUE) # +\n\n\n\n\n\n\n\nCode\n# Les dièses en début de ligne font que ce qui suit ne s'exécute pas.\n# La suite est uniquement pour les rendus fixes (tmap_mode = \"plot\"), p. ex. pour les pdf\n  # # NB : on note les positions en majuscules quand on veut coller aux marges\n  # tm_credits(\"Sources: WDPA et GADM\", position = c(\"RIGHT\", \"BOTTOM\"),\n  #            size = 0.6) +\n  # tm_layout(main.title = \"Aires protégées de Madagascar\",\n  #           # NB : position en minuscules pour laisser un espace avec la marge\n  #           main.title.position = c(\"center\", \"top\"),\n  #           main.title.size = taille_titres_cartes,\n  #           legend.position = c(\"left\", \"top\"),\n  #           legend.outside = TRUE)\n\n\nOn peut également réaliser un graphique qui présente l’historique de création des aires protégées. Pour plus de précisions sur la manière de produire des graphiques en R, voir l’annexe correspondante.\n\n\nCode\n# On ordonne les nom d'aires protégées dans l'ordre de leur séquence de création\nordre_chrono_AP <- AP_Vahatra %>%\n  arrange(desc(date_creation), desc(nom)) %>%\n  pull(nom)\n# On transforme le champ \"nom\" de caractère, à une catégorisation ordonnée où\n# l'ordre correspond \nAP_Vahatra_carte <- AP_Vahatra %>%\n  mutate(nom = factor(nom, levels = ordre_chrono_AP),\n         cat_taille = case_when(hectares > 300000 ~ 2,\n                                hectares > 150000 ~ 1.5,\n                                hectares >  50000 ~ 1,\n                                             TRUE ~ 0.5)) %>%\n  rename(`Catégorie IUCN` = cat__iucn)\n\n# On crée un graph pour les anciennetés\ngraph_gauche <- AP_Vahatra_carte %>%\n  ggplot(aes(x = date_creation, xend = ymd(\"2022-10-01\"), y = nom, yend = nom, \n                   color = `Catégorie IUCN`)) +\n  geom_segment(size = 2) +\n  ggtitle(\"Ancienneté\") +\n  theme(axis.ticks.y = element_blank(),\n        legend.position = \"none\",\n        axis.title = element_blank(),\n        axis.text.x.bottom =  element_text(angle = 45, hjust = 1),\n        axis.text.x.top = element_text(angle = -45, hjust = 1)) + \n  scale_x_date(sec.axis = dup_axis())\n\ngraph_droite <- AP_Vahatra_carte %>%\n  ggplot(aes(x = 0, xend = hectares/100, y = nom, yend = nom, \n                   color = `Catégorie IUCN`)) +\n  geom_segment(size = 2) + \n  ggtitle(\"Surface (km2)\") +\n  theme(axis.text.y = element_blank(),\n        axis.title = element_blank(),\n        axis.text.x.bottom =  element_text(angle = 45, hjust = 1),\n        axis.text.x.top = element_text(angle = -45, hjust = 0),\n        legend.position = \"none\") + \n  scale_x_continuous(sec.axis = dup_axis())\n\nlegende <- get_legend(graph_gauche  +\n                        guides(color = guide_legend(nrow = 1)) +\n                        theme(legend.position = \"bottom\"))\n\n# On colle les deux\ngraphs <- plot_grid(graph_gauche, graph_droite, rel_widths = c(2.2, 1),\n          nrow = 1)\nplot_grid(graphs, legende, ncol = 1,\n          rel_heights = c(1,.1))\n\n\n\n\n\nIl faut aussi s’assurer qu’on filtre bien les entités analysées selon un critère pertinent. Actuellement, on exclut les aires marines. Il pourrait toutefois sembler utile d’écarter les aires dont le statut de protection est considéré comme trop faible. Il pourrait aussi être pertinent de ne garder que les aires protégées comportant un niveau minimum de couvert forestier : autrement, cela signifie que la forêt n’est pas un habitat pertinent pour les écosystèmes que la démarche de conservation cherche à protéger dans cette aire."
  },
  {
    "objectID": "01-aires_protegees.html#world-database-on-protected-areas",
    "href": "01-aires_protegees.html#world-database-on-protected-areas",
    "title": "1  Aires protégées",
    "section": "1.2 World Database on Protected Areas",
    "text": "1.2 World Database on Protected Areas\nOn commence par télécharger et présenter ces données.\n\n\nCode\n# On regarde si les données WDPA sont disponibles sur l'ordinateur qui exécute\nif (file.exists(\"data/WDPA/WDPA_Oct2022_MDG-shapefile.zip\")) {\n  # Si oui, on charge\n  WDPA_Mada <- wdpa_read(\"data/WDPA/WDPA_Oct2022_MDG-shapefile.zip\")\n} else {\n  # Si non, on télécharge depuis protectedplanet\n  WDPA_Mada <- wdpa_fetch(\"Madagascar\", wait = TRUE,\n                      download_dir = \"data/WDPA\") \n}\n\n\n\n# TODO: inclure graph et description des données."
  },
  {
    "objectID": "01-aires_protegees.html#comparaison-des-données-vahatra-et-wdpa",
    "href": "01-aires_protegees.html#comparaison-des-données-vahatra-et-wdpa",
    "title": "1  Aires protégées",
    "section": "1.3 Comparaison des données Vahatra et WDPA",
    "text": "1.3 Comparaison des données Vahatra et WDPA\nOn commence par visualiser les différences spatiales entre les polygones, en affichant les 10 qui sont les plus différents entre les WDPA et Vahatra.\n\n\nCode\n# On harmonise les noms qui sont parfois notés différemment entre les sources\nAP_Vahatra <- AP_Vahatra %>%\n  mutate(nom_wdpa = case_when(\n    nom == \"Corridor Forestier Bongolava\" ~ \"Corridor forestier Bongolava\",\n    nom == \"Ranobe PK32\" ~ \"Ranobe PK 32\",\n    str_detect(nom, \"Ambositra-Vondrozo\") ~ \"Corridor Forestier Ambositra Vondrozo\",\n    nom == \"Réserve deTampolo\" ~ \"Réserve de Tampolo\",\n    nom == \"Bombetoka Beloboka\" ~ \"Bombetoka Belemboka\",\n    nom == \"Ampananganandehibe-Behasina\" ~ \"Ampanganandehibe-Behasina\",\n    nom == \"Forêt Sacrée Alandraza Analavelo\" ~ \"Analavelona\", # vérfié sur carte : les mêmes\n    nom == \"Réserve speciale Pointe à Larrée\" ~ \"Réserve spéciale Pointe à Larrée\", \n    nom == \"Vohidava-Betsimalaho\" ~ \"Vohidava Betsimalao\", \n    nom == \"Anjanaharibe Sud\" ~ \"Anjanaharibe_sud\",\n    nom == \"Iles Radama/Sahamalaza\" ~ \"Sahamalaza Iles Radama\",\n    nom == \"Kalambatritra\" ~ \"Kalambatrika\",\n    nom == \"Mananara-Nord\" ~ \"Mananara Nord\",\n    nom == \"Kirindy - Mitea\" ~ \"Kirindy Mite\",\n    nom == \"Midongy du Sud\" ~ \"Befotaka Midongy\", # Vérifié sur la carte\n    nom == \"Montagne d'Ambre/Forêt d'Ambre\" ~ \"Montagne d'Ambre\",\n    nom == \"Tsimanampesotsa\" ~ \"Tsimanampesotse\",\n    nom == \"Pic d'Ivohibe\" ~ \"Ivohibe\",\n    nom == \"Forêt Naturelle de Petriky\" ~ \"Forêt Naturel de Petriky\",\n    nom == \"Tsingy de Namoroka\" ~ \"Namoroka\",\n    nom == \"Réserve de Ressources Naturelle Mahimborondro\" ~ \"Mahimborondro\",\n    str_detect(nom, \"Complexe Tsimembo Manambolomaty\") ~ \"Complexe Tsimembo Manambolomaty\",\n    nom == \"Mandrozo\" ~ \"Zone Humide de Mandrozo\",\n    nom == \"Paysage Harmonieux Protégés Bemanevika\" ~ \"Complexe des Zones Humides de Bemanevika\",\n    nom == \"Nord Ifotaky\" ~ \"INord fotaky\",\n    TRUE ~ nom)) %>%\n  arrange(nom_wdpa) %>%\n  mutate(rownum = row_number())\n\n# On sauvegarde le résultat\nsave(AP_Vahatra, file = \"data/ch1_AP_Vahatra.rds\")\n\n# On ne garde que les aires de WDPA qui apparaissent dans Vahatra\nWDPA_commun <- WDPA_Mada %>%\n  filter(NAME %in% AP_Vahatra$nom_wdpa) %>%\n  filter(!(NAME == \"Analalava\" & IUCN_CAT == \"Not Reported\")) %>%\n  filter(!(NAME == \"Site Bioculturel d'Antrema\" & IUCN_CAT == \"Not Reported\")) %>%\n  filter(DESIG != \"UNESCO-MAB Biosphere Reserve\") %>%\n  arrange(NAME)  %>%\n  mutate(rownum = row_number())\n       \n# Cette fonction calcule la part d'un polygone incluse dans un \n# autre polygone et retourne un ratio entre 0 et 1\nratio_inclus <- function(x, y) {\n  inclus <- st_intersection(x, y)\n  ratio <- st_area(inclus) / st_area(x)\n  return(ratio)\n}\n\n# On calcule la part des polygones Vahatra incluse dans les polgones WDPA \nV_in_W <- map2_dbl(WDPA_commun$geometry, AP_Vahatra$geometry, ratio_inclus)\n# Puis l'inverse\nW_in_V <- map2_dbl(AP_Vahatra$geometry, WDPA_commun$geometry, ratio_inclus)\n# On fait un facteur des deux\nrecoupement_mutuel <- V_in_W * W_in_V\n# Qu'on ramène dans les jeux de données d'origine\nWDPA_commun2 <- bind_cols(WDPA_commun, V_in_W = V_in_W, W_in_V = W_in_V,\n                         recoupement_mutuel = recoupement_mutuel) %>%\n  arrange(recoupement_mutuel, rownum)\nAP_Vahatra2 <- bind_cols(AP_Vahatra, V_in_W = V_in_W, W_in_V = W_in_V,\n                        recoupement_mutuel = recoupement_mutuel) %>%\n  arrange(recoupement_mutuel, rownum)\n\n# On prend maintenant les 5 les plus éloignés et on les visualise\nmin_recoup <- WDPA_commun2 %>%\n  filter(row_number() <= 10) %>%\n  select(nom_wdpa = NAME, rownum) %>%\n  mutate(source = \"WDPA\") %>%\n  bind_rows(select(filter(AP_Vahatra2, rownum %in% .$rownum), nom_wdpa, rownum)) %>%\n  mutate(source = ifelse(is.na(source), \"Vahatra\", source))\ntmap_mode(\"plot\")\nmin_recoup %>%\n  tm_shape() +\n  tm_polygons() +\n  tm_facets(by = c(\"nom_wdpa\", \"source\")) +\n  tm_layout(panel.label.size=3)\n\n\n\n\n\nOn peut également comparer ceux pour lesquels on a des différences de date ou de statut.\n\n\nCode\n# On garde seulement les métadonnées qu'on veut comparer\nWDPA_a_comparer <- WDPA_commun %>% # On repart des AP communes\n  st_drop_geometry() %>% # Plus besoin de spatial\n  select(nom_wdpa = NAME, type_wdpa = INT_CRIT, cat_iucn_wdpa = IUCN_CAT,\n         year_wdpa = STATUS_YR) # On ne garde que les colonnes à comparer\n\nverif_meta_wdpa <-AP_Vahatra %>%\n  st_drop_geometry() %>% # Pas besoin d'un jeu spatial\n  select(nom:date_modification, nom_wdpa) %>% # colonnes à garder dans Vahatra\n  # On renomme la catégorie IUCN de Vahatra et on code les NA comme dans WDPA\n  mutate(cat_iucn = ifelse(is.na(cat__iucn), \"Not Reported\", cat__iucn)) %>%\n  relocate(cat_iucn, .before = cat__iucn) %>% # Nouvelle colonne près de l'ancienne\n  left_join(WDPA_a_comparer, by = \"nom_wdpa\") %>% # On rassemble Vahatra et WDPA\n  select(-nom_wdpa, -cat__iucn) %>% # On enlève les colonnes inutiles\n  # On compare les dates et statuts\n  mutate(`Différence de date` = year(date_creation) != year_wdpa,\n         `Différence de statut` = cat_iucn != cat_iucn_wdpa)\n\nverif_meta_wdpa %>%\n  summarise(`Nombre d'aires protégées comparées` = n(),\n            `Différence de date` = sum(`Différence de date`),\n            `Différence de statut` = sum(`Différence de statut`)) %>%\n  gt() %>%\n  tab_header(title = paste(\"Différences entre les données de WDPA et celles de\",\n                     \"l'assciation Vahatra sur les aires protégées terrestres\",\n                     \"à Madagascar\"))\n\n\n\n\n\n\n  \n    \n      Différences entre les données de WDPA et celles de l'assciation Vahatra sur les aires protégées terrestres à Madagascar\n    \n    \n  \n  \n    \n      Nombre d'aires protégées comparées\n      Différence de date\n      Différence de statut\n    \n  \n  \n    98\n68\n40\n  \n  \n  \n\n\n\n\nDans les cas qu’on peut comparer, les données de l’association Vahatra semblent plus fiables. On va donc privilégier l’utilisation de ces dernières.\nOn va également visualiser les aires de WDPA qui ne sont pas contenues dans Vahatra.\n\n\nCode\nWDPA_exclu <- WDPA_Mada %>%\n  filter(!(NAME %in% AP_Vahatra$nom_wdpa))\n\ntmap_mode(\"view\")\nWDPA_exclu %>%\n  tm_shape() +\n  tm_polygons(col = \"IUCN_CAT\")\n\n\n\n\n\n\n\nCode\nratio_terrestre <- function(x) {\n  inclus <- st_intersection(x, contour_mada$geometry)\n  ratio <- st_area(inclus) / st_area(x)\n  return(ratio)\n}\n\n# On crée un grand polygone avec toutes les AP dans Vahatra\nAP_Vahatra_fusion <- st_union(AP_Vahatra)\n\n# On calcule pour les aires protégées de WDPA qui ne sont pas dans Vahatra\n# dans quelle mesure elles sont terrestres et pas superposées à d'autres AP\n# déjà dans Vahatra\nWDPA_exclu <- WDPA_exclu %>%\n  filter(st_geometry_type(.) == \"MULTIPOLYGON\") %>%\n  mutate(part_terrestre = map2_dbl(.$geometry, contour_mada$geometry, \n                                   ratio_inclus),\n         part_deja_autre = map2_dbl(.$geometry, AP_Vahatra_fusion, \n                                    ratio_inclus))\n\n# On garde celles qui sont au moins 25% terrestre et 75% pas superposées\nWDPA_a_inclure <- WDPA_exclu %>%\n  filter(part_terrestre >= 0.25 & part_deja_autre <= 0.25) %>%\n  mutate(full_name = paste(INT_CRIT, NAME)) %>%\n  select(nom = NAME, WDPAID, full_name, creation = STATUS_YR)\n\n\nOn a visiblement des aires protégées qu’il serait pertinent d’inclure et qui ne sont pas dans Vahatra."
  },
  {
    "objectID": "01-aires_protegees.html#enjeux-de-fiabilité-des-données-daires-protégées",
    "href": "01-aires_protegees.html#enjeux-de-fiabilité-des-données-daires-protégées",
    "title": "1  Aires protégées",
    "section": "1.4 Enjeux de fiabilité des données d’aires protégées",
    "text": "1.4 Enjeux de fiabilité des données d’aires protégées\nImportant pour l’analyse : si périmètres pas juste => phénomènes de leakage, faux positifs ou faux négatifs.\nEnjeu aussi des métadonnées : date ou type sont importants pour l’analyse et celle-ci perd en fiabilité si ces informations ne sont pas correctes."
  },
  {
    "objectID": "02-caracteristiques_AP.html",
    "href": "02-caracteristiques_AP.html",
    "title": "2  Caractéristiques spatiales",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(mapme.biodiversity)\nlibrary(sf)\n\nif (file.exists(\"data/Vahatra_poly.rds\")) {\n  load(\"data/Vahatra_poly.rds\")\n} else {\n\n  Vahatra_poly <- AP_Vahatra %>%\n    filter(st_geometry_type(.) == \"MULTIPOLYGON\") %>%\n    st_cast(\"POLYGON\")\n  \n  # Constitution d'un portefeuille (voir la documentation)\n  Vahatra_poly <- init_portfolio(x = Vahatra_poly, \n                                 years = 2000:2020,\n                                 outdir = \"data/mapme_Vahatra\",\n                                 cores = 24,\n                                 add_resources = TRUE,\n                                 verbose = TRUE)\n  \n  # Données d'accessibilité de Nelson et al. (2018)\n  Vahatra_poly <-  get_resources(x = Vahatra_poly, resource = \"nelson_et_al\",  \n                                 range_traveltime = \"5k_110mio\")\n  # Modèle numérique de terrain SRTM de la NASA\n  Vahatra_poly <- get_resources(x = Vahatra_poly , resource = \"nasa_srtm\")\n  \n    # Indicateurs d'accessibilité\n  Vahatra_poly <- calc_indicators(x = Vahatra_poly,\n                                  \"traveltime\",  stats_accessibility = \"mean\",\n                                  engine = \"extract\")\n  # Indicateurs de relief de terrain\n  Vahatra_poly <- calc_indicators(x = Vahatra_poly,\n                                  indicators = c(\"tri\", \"elevation\"),\n                                  stats_tri = \"mean\", stats_elevation = \"mean\")\n  \n  #   # On récupère aussi les données de Global Forest Watch sur le couver forestier\n  # Vahatra_poly <- get_resources(x = Vahatra_poly, \n  #                               resources = c(\"gfw_treecover\", \"gfw_lossyear\"))\n  #   # Indicateurs de couvert forestier\n  # Vahatra_poly <- calc_indicators(x = Vahatra_poly,\n  #                                 indicators = \"treecover_area\", \n  #                                 min_cover = 30, min_size = 1)\n  \n  save(Vahatra_poly, file = \"data/Vahatra_poly.rds\")\n}\n\n\nMapme produit des colonnes imbriquées pour chaque observation, car dans bien des cas, on peut avoir plusieurs valeurs (par année) pour une même observation, voire plusieurs variables (par exemple, le calcul de l’indicateur traveltime produit des estimations de distance par rapport à une ville pour plusieurs tailles de ville possible. Lorsqu’on spécifie une taille, il produit deux variables : la distance estimée et la taille de la ville prise en compte pour l’estimation.\nCette imbrication n’est pas indispensable pour les trois variables calculées ici (indice de terrain accidenté, distance à une ville et altitude), car on ne cherche qu’une valeur par observation. On va donc dés-imbriquer les variables.\n\n\nCode\n# Valeur agrégées par AP (moyennes pondérées par la surface)\nVahatra_vars_terrain <- Vahatra_poly %>%\n  unnest(cols = c(tri, elevation, traveltime)) %>%\n  st_drop_geometry() %>%\n  select(nom, hectares, indice_accidente = tri_mean, dist_ville = minutes_mean, \n         altitude = elevation_mean) %>%\n  group_by(nom) %>%\n  summarise(indice_accidente = weighted.mean(indice_accidente, hectares,\n                                             na.rm = TRUE),\n            dist_ville = weighted.mean(dist_ville, hectares,\n                                       na.rm = TRUE),\n            altitude = weighted.mean(altitude, hectares,\n                                     na.rm = TRUE))\n# Valeurs qu'on insère dans le jeu de données de travail\nload(\"data/ch1_AP_Vahatra.rds\")\nAP_Vahatra <- AP_Vahatra %>%\n  left_join(Vahatra_vars_terrain, by = \"nom\")\n\nsave(AP_Vahatra, file = \"data/ch2_AP_Vahatra.rds\")\n\n\nOn doit aussi se rappeler que les aires protégées sont parfois composées de plusieurs polygones disjoints et que mapme.biodiversity a calculé chaque indicateur pour chaque polygone séparément. Pour chaque aire protégée, on va donc faire la moyenne de ces indicateurs, pondérée par la surface respective de chaque polygone.\nDonnées d’accessibilité : attention car elles présentent un possible biais d’endogénéité. La construction de route au cours des dernières décennies peut être lié à l’établissement ou non d’aires protégées. L’inclusion d’une variable de contrôle qui peut être en partie affectée par notre variable de traitement (la conservation) est susceptible de problème. Il existe une carte de 2000 qui pourrait être mobilisée :\nOn notera que plusieurs autres indicateurs peuvent être calculés à partir du pabkage mapme.biodiversity:\n\nactive_fire_counts: Calculate active fire counts based on NASA FIRMS polygonsactive_fire_properties: Calculate active fire properties based on NASA FIRMS polygons\nbiome: Calculate biomes statistics (TEOW) based on WWF\ndrought_indicator: Calculate drought indicator statistics\necoregion: Calculate terrestrial ecoregions statistics (TEOW) based on WWF\nlandcover: Calculate area of different landcover classes\nmangroves_area: Calculate mangrove extent based on Global Mangrove Watch (GMW)\npopulation_count: Calculate population count statistics (Worldpop)\nprecipitation_chirps: Calculate precipitation statistics based on CHIRPS\nprecipitation_wc: Calculate precipitation statistics\nsoilproperties: Calculate Zonal Soil Properties\ntemperature_max_wc: Calculate maximum temperature statistics\ntemperature_min_wc: Calculate minimum temperature statistics based on WorldClim\ntraveltime: Calculate accessibility statistics\ntreecover_area: Calculate treecover statistics\ntreecover_area_and_emissions: Calculate treeloss statistics\ntreecoverloss_emissions: Calculate emission statistics\ntri: Calculate Terrain Ruggedness Index (TRI) statistics"
  },
  {
    "objectID": "03-donnees_deforestation.html#mapme",
    "href": "03-donnees_deforestation.html#mapme",
    "title": "3  Couvert forestier",
    "section": "3.1 Mapme",
    "text": "3.1 Mapme"
  },
  {
    "objectID": "03-donnees_deforestation.html#google-earth-engine",
    "href": "03-donnees_deforestation.html#google-earth-engine",
    "title": "3  Couvert forestier",
    "section": "3.2 Google Earth Engine",
    "text": "3.2 Google Earth Engine\nPour aller plus loin : https://r-earthengine.com/rgeebook/"
  },
  {
    "objectID": "03-donnees_deforestation.html#tmf",
    "href": "03-donnees_deforestation.html#tmf",
    "title": "3  Couvert forestier",
    "section": "3.3 TMF",
    "text": "3.3 TMF\nFichiers préparés en python (code à venir), directement sur les rasters.\n\n\nCode\nlibrary(readxl)\nbase <- \"https://github.com/fBedecarrats/conservation-deforestation-madagascar\"\nfile1 <- \"files/9828838/TMFdegradationYear_AP_Vahatra.xlsx\"\nfile2 <- \"files/9828842/TMFdeforestationYear_AP_Vahatra.xlsx\"\n\ndownload.file(url = paste(base, file1, sep = \"/\"),\n              destfile = \"data/TMFdegradationYear_AP_Vahatra.xlsx\")\ndownload.file(url = paste(base, file1, sep = \"/\"),\n              destfile = \"data/TMFdeforestationYear_AP_Vahatra.xlsx\")\n\ntmf_vahatra <- read_excel(\"data/TMFdeforestationYear_AP_Vahatra.xlsx\")\ntmf_vahatra_deg <- read_excel(\"data/TMFdegradationYear_AP_Vahatra.xlsx\")"
  },
  {
    "objectID": "03-donnees_deforestation.html#alternatives",
    "href": "03-donnees_deforestation.html#alternatives",
    "title": "3  Couvert forestier",
    "section": "3.5 Alternatives",
    "text": "3.5 Alternatives\nSi on n’est pas à l’aise avec les outils mentionnés plus haut, l’outil Geoquery d’AidData permet d’obtenir des statistiques par aire administrative. Il est également possible de formuler des demandes spécifiques pour d’autres polygones que des aires administratives au travers d’un formulaire dédié.\n\n\n\n\nCarvalho, Fabio, Kerry A. Brown, Adam D. Gordon, Gabriel U. Yesuf, Marie Jeanne Raherilalao, Achille P. Raselimanana, Voahangy Soarimalala, and Steven M. Goodman. 2020. “Methods for Prioritizing Protected Areas Using Individual and Aggregate Rankings.” Environmental Conservation 47 (2): 113–22. https://doi.org/10.1017/S0376892920000090.\n\n\nGoodman, Steven M., Marie Jeanne Raherilalao, Sébastien Wohlhauser, Jean Clarck N. Rabenandrasana, Herivololona M. Rakotondratsimba, Fanja Andriamialisoa, and Malalarisoa Razafimpahanana. 2018. Les Aires Protégées Terrestres de Madagascar: Leur Histoire, Description Et Biote. Association Vahatra."
  },
  {
    "objectID": "04-donnees_en_mailles.html",
    "href": "04-donnees_en_mailles.html",
    "title": "4  Données en mailles",
    "section": "",
    "text": "Une approche courante consiste à diviser le territoires en mailles, carrées ou en forme d’alvéoles d’abeilles (hexagones), et à calculer des indicateurs pour chacune de ces mailles.\nOn montre ci-dessous comment cette approche fonctionne.\n\n\nCode\nlibrary(tidyverse)\nlibrary(tmap)\nlibrary(sf)\nlibrary(mapme.biodiversity)\nlibrary(tidygeocoder) # pour obtenir les coordo GPS d'un point à partir de son nom\nlibrary(maptiles) # Pour télécharger des fonds de carte\n\n# Taille des titres des cartes\ntaille_titres_cartes = 1\n# Surface des hexagones en km2\ntaille_hex <- 5\n\n# Ce qui suit jusqu'à la commande \"save\" ne s'execute que si le résultat n'a pas\n# déjà été généré lors d'une exécution précédente.\nif (file.exists(\"data/grille_mada_donnees_raster.rds\")) {\n  load(\"data/grille_mada_donnees_raster.rds\")\n} else {\n  \n  # Création d'un maillage du territoire émergé --------------------------------\n  \n  # On crée un cadre autour des aires protégées du pays\n  cadre_autour_mada = st_as_sf(st_as_sfc(st_bbox(aires_prot_mada)))\n  \n  # Cellules de 5km de rayon\n  surface_cellule <- taille_hex * (1e+6)\n  taille_cellule <- 2 * sqrt(surface_cellule / ((3 * sqrt(3) / 2))) * sqrt(3) / 2\n  grille_mada <- st_make_grid(x = cadre_autour_mada,\n                              cellsize = taille_cellule,\n                              square = FALSE)\n  # On découpe la grille pour ne garder que les terres émergées\n  cellules_emergees <- st_intersects(contour_mada, grille_mada) %>%\n    unlist()\n  grille_mada <- grille_mada[sort(cellules_emergees)] %>%\n    st_sf()\n  \n  # Traitement des données satellitaires avec {mapme.bidiversity}---------------\n  \n  # Constitution d'un portefeuille (voir la documentation)\n  grille_mada <- init_portfolio(x = grille_mada, \n                                years = 2000:2020,\n                                outdir = \"data_s3/mapme\",\n                                cores = 24,\n                                add_resources = TRUE,\n                                verbose = TRUE)\n  \n  # Acquisition des données satellitaires requises (rasters) ------------------- \n  # Données d'accessibilité de Nelson et al. (2018)\n  grille_mada <-  get_resources(x = grille_mada, resource = \"nelson_et_al\",  \n                                range_traveltime = \"5k_110mio\")\n  # Données de qualité des sols (uniquement teneur )\n  grille_mada <-  get_resources(x = grille_mada,\n                                resources = \"soilgrids\",  layers = \"clay\", \n                                depths = \"5-15cm\", stats = \"mean\")\n  # Données sur le couvert forestier de Global Forest Watch\n  grille_mada <- get_resources(x = grille_mada, \n                               resources = c(\"gfw_treecover\", \"gfw_lossyear\", \n                                             \"gfw_emissions\"))\n  # Modèle numérique de terrain SRTM de la NASA\n  grille_mada <- get_resources(x = grille_mada, resource = \"nasa_srtm\")\n  # Données de feux\n  grille_mada <- get_resources(x = grille_mada, resource = \"nasa_firms\",\n                               instrument = \"MODIS\")\n  \n  # Calcul des indicateurs -----------------------------------------------------\n  \n  # Indicateurs d'accessibilité\n  grille_mada <- calc_indicators(x = grille_mada,\n                                 \"traveltime\",  stats_accessibility = \"mean\",\n                                 engine = \"extract\")\n  # Indicateurs de sols\n  \n  grille_mada <- calc_indicators(x = grille_mada,\n                                 \"soilproperties\", stats_soil = \"mean\", \n                                 engine = \"extract\")\n \n   # Indicateurs de couvert forestier\n  grille_mada <- calc_indicators(x = grille_mada,\n                                 indicators = \"treecover_area_and_emissions\", \n                                 min_cover = 30, min_size = 1)\n  # Indicateurs de relief de terrain\n  grille_mada <- calc_indicators(x = grille_mada,\n                               indicators = c(\"tri\", \"elevation\"),\n                               stats_tri = \"mean\", stats_elevation = \"mean\")\n  # Indicateurs d'incendies\n  grille_mada <- calc_indicators(x = grille_mada,\n                                 \"active_fire_counts\")\n  grille_mada <- calc_indicators(x = grille_mada,\n                                 \"active_fire_properties\")\n  \n  # Sauvegarde du résultat\n  save(grille_mada, file = \"data_s3/grille_mada_donnees_raster.rds\")\n}\n\n\nLe maillage est trop fin pour être visible à l’échelle du pays, mais on peut l’observer en zoomant sur une zone spécifique.\n\n\nCode\nsf_use_s2(TRUE) \n\n# On compte le nombre d'hexagones\nn_hex <- nrow(grille_mada)\n# Carte pour visualiser le résultat ------------------------------------------\n\n## Carte de droite : zoom sur une zone spécifique-----------------------------\n# On part d'un dataframe contenant une adresse\nnom_centre_zoom <- \"Maroantsetra\"\nzoom_centre <- data.frame(address = nom_centre_zoom) %>%\n  geocode(address, method = \"osm\") %>% # on retrouve sa localisation xy\n  select(long, lat) %>% # on ne garde que le xy\n  as.numeric() %>% # qu'on passe en format numérique attendu par st_point\n  st_point() %>% # On le spécifie en point\n  st_sfc(crs = \"EPSG:4326\") \n\n# On crée une boîte de 100km \nzoom_boite <- zoom_centre %>% # On repart du centre\n  st_buffer(dist = 50000) %>% # On crée un cercle de 50km de rayon\n  st_make_grid(n = 1) \n\n# On filtre les alvéoles pour ne garder que celles qui sont dans le zoom\ngrille_zoom <- st_intersection(grille_mada, zoom_boite)\n\n# On télécharge un fond de carte pour la carte de droite\nfond_carte_zoom <- get_tiles(zoom_boite, provider = \"Stamen.Terrain\", \n                             zoom = 10, crop = TRUE) \n\nsave(n_hex, nom_centre_zoom, zoom_centre, zoom_boite, grille_zoom, \n     fond_carte_zoom, file = \"data_s3/elements_carte_zoom.rds\")\n\n# On était restés en mode interactif, on repasse en mode statique pour les \n# cartes\ntmap_mode(\"plot\")\n\n# On génère la carte de droite\ncarte_zoom <- tm_shape(fond_carte_zoom) + \n  tm_rgb() +\n  tm_shape(grille_zoom) +\n  tm_borders() +\n  tm_shape(zoom_boite) + \n  tm_borders(col = \"red\") +\n  tm_layout(frame = FALSE,\n            main.title = paste(\"Zoom sur la zone de\", nom_centre_zoom),\n            main.title.size = taille_titres_cartes) +\n  tm_credits(get_credit(\"Stamen.Toner\"),\n             bg.color = \"white\",\n             align = \"right\",\n             position = c(\"right\", \"BOTTOM\"))\n\n## Carte de gauche : simple à réaliser mais hexagones non visibles -------------\nload(\"data/contour_mada.rds\")\ncarte_grille <- tm_shape(contour_mada) +\n  tm_polygons(col = \"grey\") + \n  tm_shape(zoom_boite) +\n  tm_borders(col = \"red\") +\n  tm_layout(frame = FALSE) +\n  tm_layout(main.title = paste(\"Découpage en\", n_hex,\n                               \"hexagones de\", taille_hex, \"km2\"),\n            main.title.size = taille_titres_cartes)\n\n# Assemblage des deux cartes ---------------------------------------------------\ntmap_arrange(carte_grille, carte_zoom, ncol = 2) \n\n\n\n\n\nOn peut également représenter les différentes valeurs des indicateurs générés à partir des données satellitaires.\n\n\nCode\nif (file.exists(\"data/grille_mada_summary.rds\")) {\n  load(\"data/grille_mada_summary.rds\")\n} else {\n  grille_mada_summary <- grille_mada %>%\n    # On met à plat les données de distance\n    unnest(cols = c(traveltime, soilproperties, tri, elevation),\n           names_repair = \"universal\") %>%\n    select(-distance, -layer, -depth, -stat,  -active_fire_counts, \n           -active_fire_properties) %>%\n    rename(distance_minutes_5k_110mio = minutes_mean, mean_clay_5_15cm = mean) \n  \n  grille_mada_summary <- grille_mada_summary %>%\n    unnest(cols = treecover_area_and_emissions) %>%\n    pivot_wider(names_from = \"years\", values_from = c(\"treecover\", \"emissions\")) %>%\n    mutate(var_treecover = (treecover_2020 - treecover_2000)/treecover_2000,\n           sum_emissions = rowSums(across(starts_with(\"emission\")), na.rm = T)) %>%\n    rename(init_treecover_2000 = treecover_2000) %>% # pour le garder\n    select(-starts_with(\"treecover\"), -starts_with(\"emission\")) %>%\n    rename(treecover_2000 = init_treecover_2000) %>%\n    relocate(geometry, .after = last_col())\n  \n  save(grille_mada_summary, file = \"data_s3/grille_mada_summary.rds\")\n}\n\ncarte_acces <- tm_shape(grille_mada_summary) +\n  tm_fill(\"distance_minutes_5k_110mio\",\n          title = \"Distance ville (>5K hab)\",\n          palette = \"Oranges\",\n          style = \"fisher\",\n          n = 8,\n          legend.hist = TRUE) +\n  tm_layout(legend.outside = TRUE,\n            # legend.title.size = 0.8,\n            # legend.text.size = 0.6,\n            legend.hist.width = 1,\n            legend.hist.height = 1)\n\ncarte_sol <- tm_shape(grille_mada_summary) +\n  tm_fill(\"mean_clay_5_15cm\",\n          title = \"Sol argileux (5-15cm prof)\",\n          palette = \"YlOrBr\",\n          n = 8,\n          legend.hist = TRUE) +\n  tm_layout(legend.outside = TRUE,\n            # legend.title.size = 0.8,\n            # legend.text.size = 0.6\n            legend.hist.width = 1,\n            legend.hist.height = 1)\n\ncarte_TRI <- tm_shape(grille_mada_summary) +\n  tm_fill(\"tri_mean\",\n          title = c(\"Terrain accidenté (TRI)\"),\n          palette = \"Blues\",\n          n = 8,\n          legend.hist = TRUE) +\n  tm_layout(legend.outside = TRUE,\n            # legend.title.size = 0.8,\n            # legend.text.size = 0.6,\n            legend.hist.width = 1,\n            legend.hist.height = 1)\n\ncarte_alt <- tm_shape(grille_mada_summary) +\n  tm_fill(\"elevation_mean\",\n          title = \"Altitude\",\n          palette = \"Purples\",\n          n = 8,\n          legend.hist = TRUE) +\n  tm_layout(legend.outside = TRUE,\n            # legend.title.size = 0.8,\n            # legend.text.size = 0.6,\n            legend.hist.width = 1,\n            legend.hist.height = 1)\n\ncarte_cover <- graph_alt <- tm_shape(grille_mada_summary) +\n  tm_fill(\"treecover_2000\",\n          title = \"Couvert arboré en 2000\",\n          palette = \"Greens\",\n          n = 8,\n          legend.hist = TRUE) +\n  tm_layout(legend.outside = TRUE,\n            # legend.title.size = 0.8,\n            # legend.text.size = 0.6,\n            legend.hist.width = 1,\n            legend.hist.height = 1)\n\ncarte_loss <- graph_alt <- tm_shape(grille_mada_summary) +\n  tm_fill(\"var_treecover\",\n          title = \"Perte couvert (2000-2020)\",\n          palette = \"Reds\",\n          n = 8,\n          legend.hist = TRUE) +\n  tm_layout(legend.outside = TRUE,\n            # legend.title.size = 0.8,\n            # legend.text.size = 0.6,\n            legend.hist.width = 1,\n            legend.hist.height = 1)\n\ntmap_arrange(carte_acces, carte_sol, \n             carte_alt, carte_TRI, \n             carte_cover, carte_loss,\n             ncol = 2, nrow = 3) \n\n\n\n\n\nCes approches permettent de mieux capter la variabilité des relations entre les variables spatiales. Elle est utile si les estimations qu’on va ensuite réaliser se font aussi au niveau des aires.\n\n4.0.1 Croisement des données d’aires protégées et satellitaires\nOn peut maintenant associer les données d’aires protégées aux hexagones afin de les croiser avec les indicateurs issus des données satellitaires déjà calculés pour ces hexagones.\n\n\nCode\nif (file.exists(\"data/grille_mada_summary_AP.rds\")) {\n  load(\"data/grille_mada_summary_AP.rds\")\n} else {\n  # Le code suivant va asocier les hexagones aux aires protégées en se référant\n  # aux AP par leur rang dans la table des AP. On voudra plutôt leur identifiant, \n  # alors on crée une table d'équivalence rang/identifiant \n  aires_prot_mada_rang_id <- aires_prot_mada %>%\n    st_drop_geometry() %>% # Enlève l'information spatiale\n    mutate(AP_ligne = row_number()) %>% # Intègre le numéro de ligne dans un champ\n    select(AP_ligne, WDPAID) # On ne garde que le numéro de ligne et l'identifiant\n  \n  # Pour chaque hexagone, on va maintenant identifier s'ils touchent (\"intersect\")\n  # ou s'ils sont strictiement inclus dans (\"within\") une aire protégé\n  grille_mada_summary_AP <- grille_mada_summary %>%\n    st_transform(crs = mon_scr) %>%\n    mutate(AP_ligne = st_intersects(., aires_prot_mada), # liste des n° de lignes d'AP qui recoupent\n           AP_ligne = map(AP_ligne, 1), # On extrait le 1° élément de la liste (toutes n'ont qu'1 élément)\n           AP_ligne = as.integer(as.character(AP_ligne))) %>%  # formattage en numérique\n    left_join(aires_prot_mada_rang_id, by = \"AP_ligne\") %>% # récupère l'id de l'AP\n    rename(WDPAID_touche = WDPAID) %>% # on renomme pour différentier\n    mutate(AP_ligne = st_within(., aires_prot_mada),\n           AP_ligne = map(AP_ligne, 1),\n           AP_ligne = as.integer(as.character(AP_ligne))) %>%\n    left_join(aires_prot_mada_rang_id, by = \"AP_ligne\") %>%\n    rename(WDPAID_inclus = WDPAID) %>%\n    select(-AP_ligne) \n  \n  grille_mada_summary_AP <- grille_mada_summary_AP %>%\n    st_sf() %>%\n    mutate(position_ap = ifelse(is.na(WDPAID_touche), \"Extérieur\",\n                                ifelse(!is.na(WDPAID_inclus), \"Intérieur\",\n                                       \"Frontière\"))) %>%\n    relocate(geometry, .after = last_col()) \n  save(grille_mada_summary_AP, file = \"data_s3/grille_mada_summary_AP.rds\")\n}\n\n# Une vue après classification\ntm_shape(grille_mada_summary_AP) +\n  tm_fill(col = \"position_ap\", title = \"par rapport aux aires protégées\") +\n  tm_layout(main.title = \"Localisation des hexagones\",\n            # NB : position en minuscules pour laisser un espace avec la marge\n            main.title.position = c(\"center\", \"top\"),\n            main.title.size = taille_titres_cartes,\n            legend.position = c(\"left\", \"top\"),\n            legend.outside = FALSE)\n\n\n\n\n\nEn plus d’un format natif R (rds), on a aussi enregistré l’export au format Stata (.dta)"
  },
  {
    "objectID": "09-bibliographie.html",
    "href": "09-bibliographie.html",
    "title": "References",
    "section": "",
    "text": "Bédécarrats, Florent, and Alexandre Hobeika. 2017. “Une\nAlternative à Word : Écrire En\nRMarkdown.” Billet. Data Sciences Sociales.\nhttp://data.hypotheses.org/1144.\n\n\nGoodman, Steven M., Marie Jeanne Raherilalao, Sébastien Wohlhauser, Jean\nClarck N. Rabenandrasana, Herivololona M. Rakotondratsimba, Fanja\nAndriamialisoa, and Malalarisoa Razafimpahanana. 2018. Les Aires\nProtégées Terrestres de Madagascar: Leur Histoire,\nDescription Et Biote. Association Vahatra.\n\n\nKluve, Jochen, Johannes Schielain, Melvin Wong, and Yota Eilers. 2022.\n“The KfW Protected Areas\nPortfolio: A Rigorous Impact\nEvaluation.” Frankfürt."
  },
  {
    "objectID": "10-fondamentaux_R.html#principes-élémentaires-de-manipulation-de-données-en-r",
    "href": "10-fondamentaux_R.html#principes-élémentaires-de-manipulation-de-données-en-r",
    "title": "10  Fondamentaux pour l’utilisation de R",
    "section": "10.3 Principes élémentaires de manipulation de données en R",
    "text": "10.3 Principes élémentaires de manipulation de données en R\nOn se focalise ici sur quelques aspects qui peuvent être requis pour la manipulation du code et à la marge. Points à traiter :\n\n<- / =\n%>%\nfonctions\nna.rm : Les valeurs manquantes, notées NA dans R (certaines peuvent avoir pour valeur NaN). On utilise na.rm pour les éluder dans les opérations simples.\nverbes : select, filter, mutate, group_by / summarise\n\nDeux opérations particulière requièrent une étude plus approfondies\n\nJointures\nPivots\nmap\nunnest\n\nUn point important est relatif aux types des variables : numérique, catégorielles, textes, dates, spatiales… En général, les opérations ne peuvent concerner que des variables du même type. Les fonctions sont souvent contraignantes quant aux types des variables qu’elles prennent comme arguments.\nPour une analyse plus approfondie, voir juba."
  },
  {
    "objectID": "10-fondamentaux_R.html#produire-des-cartes-simples-avec-r",
    "href": "10-fondamentaux_R.html#produire-des-cartes-simples-avec-r",
    "title": "10  Fondamentaux pour l’utilisation de R",
    "section": "10.4 Produire des cartes simples avec R",
    "text": "10.4 Produire des cartes simples avec R"
  },
  {
    "objectID": "10-fondamentaux_R.html#produire-des-graphiques-avec-r",
    "href": "10-fondamentaux_R.html#produire-des-graphiques-avec-r",
    "title": "10  Fondamentaux pour l’utilisation de R",
    "section": "10.5 Produire des graphiques avec R",
    "text": "10.5 Produire des graphiques avec R\n\n\n\n\nBarnier, Julien. 2022. “Introduction à r Et Au Tidyverse.” https://juba.github.io/tidyverse/index.html.\n\n\nGaliana, Lino, and Olivier Meslin, eds. 2022. “utilitR: Documentation Collaborative Sur r.” https://www.book.utilitr.org/.\n\n\nGörgen, Darius A., and Om Prakash Bhandari. 2022. Mapme.biodiversity: Efficient Monitoring of Global Biodiversity Portfolios. https://CRAN.R-project.org/package=mapme.biodiversity.\n\n\nGrolemund, Garrett, and Hadley Wickham. 2022. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. 1st edition. Sebastopol, CA: O’Reilly Media. https://r4ds.had.co.nz/.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2022. Geocomputation with R. Boca Raton London New York: Routledge. https://geocompr.robinlovelace.net/."
  },
  {
    "objectID": "05-assignation_aleatoire.html",
    "href": "05-assignation_aleatoire.html",
    "title": "6  Méthode randomisée",
    "section": "",
    "text": "ATTENTION : Il va de soi que les AP malgaches n’ont à aucun moment été assignées aléatoirement. Lors de cette séquence, on fait “comme si” pour montrer la manière dont les données sont analysées quand il y a eu assignation aléatoire. On verra en fin de session les limites d’une telle approche et dans les suivantes des manières de construire des contrefactuels plus vraisemblables pour un sujet comme celui-ci.\n\nLe jeu de données AP_Vahatra contenait 98 aires protégées, avec des géométries de types “multi-polygones”. Certaines de ces aires protégées étaient en effet composées de plusieurs polygones disjoints. Ces polygones disjoints ont été scindés pour être traités séparément dans le jeu de données AP_poly. Avant de repasser sur des analyses agrégées, on va agrégéer les statistiques d’AP_poly afin d’avoir pour chaque variable une valeur par aire protégée.\n\n\nCode\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(broom)\nlibrary(stargazer)\nlibrary(sf)\nlibrary(lubridate)\n\nload(\"data/AP_Vahatra_Carvalho.rds\")\n\nrct_AP_Mada <- AP_Vahatra_Carvalho %>%\n  st_drop_geometry() %>%\n  rename(`Déforestation 1996-2006 (%)` = \n           `Forest loss (ha) between 1996-2006 (percent loss)`,\n         `Déforestation 2006-2016 (%)` = \n           `Forest loss (ha) between 2006-2016 (percent loss)`,\n         `Surface (ha)` = hectares) %>%\n  mutate(Groupe = ifelse(year(date_creation) < 2015, \"Traitement\", \"Controle\"),\n         `Couvert forestier en 1996 (%)` = `Forest cover (ha) in 1996` / \n                                              `Surface (ha)` * 100,\n         `Déforestation 1996-2016 (%)` = \n           (`Forest loss (ha) between 1996-2006 (absolute loss)` + \n             `Forest loss (ha) between 2006-2016 (absolute loss)`) /\n           `Forest cover (ha) in 1996` * 100)\n\n# On fait une série de tests de comparaison de moyenne\nt_tests <- rct_AP_Mada %>% \n  # On applique aux variables de déforestation, couvert en 96 et taille\n  summarise(across(ends_with(\"(%)\") | ends_with(\"(ha)\"),# toutes finissent ainsi\n                   ~ t.test(.[Groupe == \"Controle\"], # on applique un t.test\n                            .[Groupe == \"Traitement\"])$p.value)) %>%\n  mutate(Groupe = \"t-test\")\n\nequilibre_avant <- rct_AP_Mada %>%\n  group_by(Groupe) %>%\n  summarise(`Nombre d'aires` = n(),\n            `Sans forêt` = sum(is.na(`Couvert forestier en 1996 (%)`)), \n            `Surface (ha)` = mean(`Surface (ha)`),\n            `Couvert forestier en 1996 (%)` = \n              mean(`Couvert forestier en 1996 (%)`, na.rm = TRUE)) %>%\n  bind_rows(t_tests) %>% # On colle tous les t-tests \n  mutate(across(!Groupe, ~round(., 2))) %>%# arrondit tout sauf colonne \"Groupe\"\n  select(-starts_with(\"Déforestation\"))# On ne garde que les t-tests de baseline\n\n# Ce qui suit est une série d'opération pour formater le rendu en tableau\nequilibre_avant %>%\n  t() %>% # On transpose lignes <=> colonnes\n  as.data.frame() %>% # La transposition a altéré le format, on remet en tableau\n  tibble::rownames_to_column() %>% # On met le nom des lignes en 1° colonne\n  # \"Truc pour renommer avec le contenu de la première ligne\n  `colnames<-` (filter(., row_number() == 1)) %>% \n  filter(row_number() != 1)%>% # Enlève la 1° ligne qui est maintenant en entête\n  gt() %>%\n  tab_header(title = \"Equilibre des variables avant intervention\",\n             subtitle = \"(exercice : \\\"comme si\\\" c'était une RCT)\") %>%\n  tab_source_note(\"Source : Association Vahatra et Carvalho et al. 2018\")\n\n\n\n\n\n\n  \n    \n      Equilibre des variables avant intervention\n    \n    \n      (exercice : \"comme si\" c'était une RCT)\n    \n  \n  \n    \n      Groupe\n      Controle\n      Traitement\n      t-test\n    \n  \n  \n    Nombre d'aires\n53\n45\nNA\n    Sans forêt\n 4\n 0\nNA\n    Surface (ha)\n66308.62\n63513.89\n    0.88\n    Couvert forestier en 1996 (%)\n54.31\n62.24\n 0.14\n  \n  \n    \n      Source : Association Vahatra et Carvalho et al. 2018\n    \n  \n  \n\n\n\n\nOn a à première vue des équilibres limités “avant intervention”. En moyenne, les deux groupes sont assez proches en termes de surface et de couvert forestier et le test de Stydent ne permet pas de rejeter l’hypothèse nulle.\nOn va maintenant s’intéresser aux différences de déforestation observées “après intervention” dans le groupe de traitement.\n\n\nCode\ncomparaison_apres <- rct_AP_Mada %>%\n  group_by(Groupe) %>%\n  summarise(across(starts_with(\"Déforestation\"), ~ mean(., na.rm = TRUE))) %>%\n  bind_rows(t_tests) %>% # On colle tous les t-tests \n  mutate(across(!Groupe, ~round(., 2))) %>%# arrondit tout sauf colonne \"Groupe\"\n  select(Groupe, starts_with(\"Déforestation\"))# On ne garde que les t-tests de baseline\n\n\n# Même procédure que plus haut pour formater le rendu en tableau\ncomparaison_apres  %>%\n  t() %>% # On transpose lignes <=> colonnes\n  as.data.frame() %>% # La transposition a altéré le format, on remet en tableau\n  tibble::rownames_to_column() %>% # On met le nom des lignes en 1° colonne\n  # \"Truc pour renommer avec le contenu de la première ligne\n  `colnames<-` (filter(., row_number() == 1)) %>% \n  filter(row_number() != 1)%>% # Enlève la 1° ligne qui est maintenant en entête\n  gt() %>%\n  tab_header(title = \"Moyennes après intervention\",\n             subtitle = \"(exercice : \\\"comme si\\\" c'était une RCT)\") %>%\n  tab_source_note(\"Source : Association Vahatra et Carvalho et al. 2018\")\n\n\n\n\n\n\n  \n    \n      Moyennes après intervention\n    \n    \n      (exercice : \"comme si\" c'était une RCT)\n    \n  \n  \n    \n      Groupe\n      Controle\n      Traitement\n      t-test\n    \n  \n  \n    Déforestation 1996-2006 (%)\n8.21\n4.12\n0.07\n    Déforestation 2006-2016 (%)\n8.50\n3.91\n0.01\n    Déforestation 1996-2016 (%)\n15.90\n 7.87\n 0.00\n  \n  \n    \n      Source : Association Vahatra et Carvalho et al. 2018\n    \n  \n  \n\n\n\n\nOn peut également réaliser une régression simple.\n\n\nCode\ndef_96_06 <- lm(`Déforestation 1996-2006 (%)`  ~ Groupe, data = rct_AP_Mada)\ndef_06_16 <- lm(`Déforestation 2006-2016 (%)`  ~ Groupe, data = rct_AP_Mada)\ndef_96_16 <- lm(`Déforestation 1996-2016 (%)`  ~ Groupe, data = rct_AP_Mada)\n\ntidy(def_96_06) %>%\n  gt() %>%\n  tab_header(title = \"Déforestation 1996-2006 (%)\",\n             subtitle = \"(exercice : \\\"comme si\\\" c'était une RCT)\") %>%\n  tab_source_note(\"Source : Association Vahatra et Carvalho et al. 2018\")\n\n\n\n\n\n\n  \n    \n      Déforestation 1996-2006 (%)\n    \n    \n      (exercice : \"comme si\" c'était une RCT)\n    \n  \n  \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n    \n  \n  \n    (Intercept)\n8.213539\n1.596988\n5.143146\n1.516642e-06\n    GroupeTraitement\n-4.091723\n2.308124\n-1.772748\n7.958037e-02\n  \n  \n    \n      Source : Association Vahatra et Carvalho et al. 2018\n    \n  \n  \n\n\n\n\nCode\ntidy(def_06_16) %>%\n  gt() %>%\n  tab_header(title = \"Déforestation 2006-2016 (%)\",\n             subtitle = \"(exercice : \\\"comme si\\\" c'était une RCT)\") %>%\n  tab_source_note(\"Source : Association Vahatra et Carvalho et al. 2018\")\n\n\n\n\n\n\n  \n    \n      Déforestation 2006-2016 (%)\n    \n    \n      (exercice : \"comme si\" c'était une RCT)\n    \n  \n  \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n    \n  \n  \n    (Intercept)\n8.499417\n1.207649\n7.037989\n3.414988e-10\n    GroupeTraitement\n-4.592813\n1.745413\n-2.631362\n9.971843e-03\n  \n  \n    \n      Source : Association Vahatra et Carvalho et al. 2018\n    \n  \n  \n\n\n\n\nCode\ntidy(def_96_16) %>%\n  gt() %>%\n  tab_header(title = \"Déforestation 1996-2016 (%)\",\n             subtitle = \"(exercice : \\\"comme si\\\" c'était une RCT)\") %>%\n  tab_source_note(\"Source : Association Vahatra et Carvalho et al. 2018\")\n\n\n\n\n\n\n  \n    \n      Déforestation 1996-2016 (%)\n    \n    \n      (exercice : \"comme si\" c'était une RCT)\n    \n  \n  \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n    \n  \n  \n    (Intercept)\n15.901617\n1.959011\n8.117166\n2.053697e-12\n    GroupeTraitement\n-8.031104\n2.831356\n-2.836486\n5.609702e-03\n  \n  \n    \n      Source : Association Vahatra et Carvalho et al. 2018\n    \n  \n  \n\n\n\n\nOn tente une autre mise en forme\n\n\nCode\nstargazer(def_96_06, def_06_16, def_96_16, type = \"text\",\n          title = \"Impact de la conservation sur la perte de couvert forestier\",\n          notes = \"Données : Association Vahatra et Carvalho et al. 2018\")\n\n\n\nImpact de la conservation sur la perte de couvert forestier\n=======================================================================================================================\n                                                                 Dependent variable:                                   \n                              -----------------------------------------------------------------------------------------\n                              `Déforestation 1996-2006 (%)` `Déforestation 2006-2016 (%)` `Déforestation 1996-2016 (%)`\n                                           (1)                           (2)                           (3)             \n-----------------------------------------------------------------------------------------------------------------------\nGroupeTraitement                         -4.092*                      -4.593***                     -8.031***          \n                                         (2.308)                       (1.745)                       (2.831)           \n                                                                                                                       \nConstant                                8.214***                      8.499***                      15.902***          \n                                         (1.597)                       (1.208)                       (1.959)           \n                                                                                                                       \n-----------------------------------------------------------------------------------------------------------------------\nObservations                               94                            94                            94              \nR2                                        0.033                         0.070                         0.080            \nAdjusted R2                               0.023                         0.060                         0.070            \nResidual Std. Error (df = 92)            11.179                         8.454                        13.713            \nF Statistic (df = 1; 92)                 3.143*                       6.924***                      8.046***           \n=======================================================================================================================\nNote:                                                                                       *p<0.1; **p<0.05; ***p<0.01\n                                                                  Données : Association Vahatra et Carvalho et al. 2018"
  },
  {
    "objectID": "10-fondamentaux_R.html",
    "href": "10-fondamentaux_R.html",
    "title": "10  Fondamentaux pour l’utilisation de R",
    "section": "",
    "text": "Ressources en français :\nRessources en anglais Les bonnes ressources anglophones gratuites sont très nombreuses, très facile à trouver sur le Web. Les grands classiques est R for data science, de Grolemund et Wickham (2022). On se focalise ici avec elles qui sont le plus en lien avec nos sujets."
  },
  {
    "objectID": "10-fondamentaux_R.html#installation",
    "href": "10-fondamentaux_R.html#installation",
    "title": "10  Fondamentaux pour l’utilisation de R",
    "section": "10.1 Installation",
    "text": "10.1 Installation\nOn installe R et RStudio :\n\nTélécharger et installer R (page officielle proposant les installateurs et instructions d’installation)\nTélécharger et installer RStudio (page officielle proposant les installateurs et instructions d’installation)\n\n\nA noter : un nombre croissant d’utilisteurs utilise VS Code. C’est une alternative intéressante, pour des utilisateurs déjà confirmés :"
  },
  {
    "objectID": "10-fondamentaux_R.html#import-des-données",
    "href": "10-fondamentaux_R.html#import-des-données",
    "title": "10  Fondamentaux pour l’utilisation de R",
    "section": "10.2 Import des données",
    "text": "10.2 Import des données\nEn très bref :\n\nPour les fichiers excle ou csv, dans le volet “files” du panneau en bas à droite de l’interface Rstudio, cliquer sur le fichier en question et utiliser l’assistant d’import.\nPour les autres fichiers, se référer à l’aide ou chercher sur internet.\n\nVoir cette page pour un topo sur les imports. [#TODO:Préciser l’url]"
  },
  {
    "objectID": "01-aires_protegees.html",
    "href": "01-aires_protegees.html",
    "title": "1  Aires protégées",
    "section": "",
    "text": "Les études sur les aires protégées s’appuient fréquemment sur la base WDPA (World Database on Protected Area), consultable en ligne sur https://protectedplanet.net. On s’aperçoit dans le cas de Madagascar que cette base de données comporte de nombreuses erreurs (qu’on étudiera plus bas). La base rassemblée par l’association Vahatra dans le cadre de la monographie qu’elle a coordonnée sur l’ensemble des aires protégées terrestres malgaches semble beaucoup plus fiable (Goodman et al. 2018). Les données en question sont disponibles sur le portail https://protectedareas.mg avec une licence creative commons (CC-BY).\nLe bloc de code ci-dessous (cliquer sur “code” pour visualiser), présente la séquence d’opérations réalisées pour préparer les données.Pour comprendre certaines opérations contenues dans le bloc de code, il est utile d’être familier de la syntaxe de R et des packages du tidyverse. Voir le chapitre Chapter 10.\n\n\nCode\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(sf)\nlibrary(tmap)\nlibrary(geodata)\nlibrary(cowplot)\nlibrary(wdpar)\nlibrary(gt) # Pour faciliter le rendu des tableaux (et ils sont jolis)\n\n# Le shapefile est composé d'une série de fichiers, (.shp, .dbf, .prj, .shx)\n# qui doivent avoir le même nom et être au même endroits pour être ouverts en\n# même temps. Comme souvent, ils sont compressés ensemble dans un fichier zip.\n# On commence par dézipper (décompresser) ce fichier.\nunzip(\"data/Vahatra98AP.zip\", exdir = \"data/Vahatra\")\n# On importe dans R en pointant vers le fichier .shp, mais c'est bien toute la\n# collection de fichiers homonymes .shp, .dbf, .shx qui est chargée.\nAP_Vahatra <- st_read(\"data/Vahatra/Vahatra98AP.shp\", quiet = TRUE) %>%\n  # Il manque la projection (pas de fichier .prj), on la spécifie à la main\n  st_set_crs(\"EPSG:4326\") # EPSG 4325 = WSG 84 = le standard pour le web\n\n# L'option ci-dessous est un peu cryptique : des caractéristiques topologiques\n# de la carte source sont incompatibles avec la possibilité d'avoir des objets\n# sphériques dans sf. Cela disparait si on désactive cette possibilité\nsf_use_s2(FALSE) \n\n# Identification des dates ----------------------------------------------------\n# Cette section est un brin complexe, à base de manipulation de chaînes de \n# caractères et de dates\n\n# Détecte les dates écrites 2 avril 2020 ou 02 avril 2020, etc.\ndate_ecrite <- \"[:digit:]{1,2} [:alpha:]* [:digit:]{4}\"\n# Détecte les dates écrites 02/04/20 ou 02.04.20 ou 02.04.2020, etc.\ndate_abrev <- \"[:digit:]{2}[:punct:][:digit:]{2}[:punct:][:digit:]{2,4}\"\n# Des années écrites à 2 chiffres\ndate_ecrite_an_abrev <- \"[:digit:]{1,2} [:alpha:]* [:digit:]{4}\"\n# Détecte l'une ou l'autre des formes précédentes\ntoute_date <- paste(date_ecrite, date_abrev, date_ecrite_an_abrev, sep = \"|\")\n# Détecte une mention d'année seule : 1984, 2015, etc.\nannee_seule <- \"[:digit:]{4}\"\n# Détecte les formes indicatrices d'un changement\nmention_changement <- \"Changement|changement|anciennement|actuel|auparavant\"\n# Une fonction qui traduit les dates écrites en toutes lettre du français à \n# l'anglais (pour les parser ensuite car ça ne fonctionne qu'en anglais)\ntrad_dates <- function(date_fr) {\n  str_replace_all(date_fr,\n                  c(\"janvier\" = \"January\",\n                    \"fevrier\" = \"February\",\n                    \"mars\" = \"March\",\n                    \"avril\" = \"April\",\n                    \"mai\" = \"May\",\n                    \"juin\" = \"June\",\n                    \"juillet\" = \"July\",\n                    \"aout\" = \"August\",\n                    \"septembre|setembre\" = \"September\",\n                    \"octobre\" = \"October\",\n                    \"novembre\" = \"November\",\n                    \"decembre|decmbre\" = \"December\"))\n}\n# Cette fonction remplace 01.04.58 par 01.04.1958 et marche avec . ou /\n# On indique avec limite le nombre d'année où on considère que c'est 1900 vs 2000\ncomplete_annee <- function(date_abrev, limite = 20) {\n  if (str_detect(date_abrev, \"([:punct:])([:digit:]{2})[:punct:]?$\")) {\n    date_abrev <- str_remove(date_abrev, \":punct:]?$\")\n    if (as.numeric(str_extract(date_abrev, \"[:digit:]{2}$\")) > limite) {\n      date_abrev <- str_replace(date_abrev, \n                                \"([:punct:])([:digit:]{2})[:punct:]?$\", \"\\\\119\\\\2\")\n    } else {\n      date_abrev <- str_replace(date_abrev, \n                                \"([:punct:])([:digit:]{2})[:punct:]?$\", \"\\\\120\\\\2\")\n    }\n  }\n  return(date_abrev)\n}\n# La fonction précédente est unitaire, on la transforme pour qu'elle s'applique à une liste.\ncomplete_liste_dates <- function(liste_dates) {\n  map(liste_dates, complete_annee)\n}\n\nAP_Vahatra <- AP_Vahatra %>%\n  # On extrait les dates des champs de texte\n  mutate(date_creation = str_extract_all(creation, toute_date), \n         # Une date a un format incohérent, on la recode à la main\n         date_creation = ifelse(creation == \"Créée le 07 aout 04\",\n                                \"07 aout 2004\", date_creation),\n         date_creationA = map(date_creation, 1), # La 1ère date\n         date_creationB = map(date_creation, 2)) %>% # Si 2 dates, la seconde\n  # On traduit les mois en anglais pour une conversion au format date\n  mutate(across(c(\"date_creationA\", \"date_creationB\"), trad_dates)) %>%\n  mutate(across(c(\"date_creationA\", \"date_creationB\"), complete_liste_dates)) %>%\n  mutate(across(c(\"date_creationA\", \"date_creationB\"), dmy)) %>%\n  mutate(date_creation = case_when(is.na(date_creationB) ~ date_creationA,\n                                    date_creationA > date_creationB ~ date_creationB,\n                                    date_creationA <= date_creationB ~ date_creationA),\n         date_modification = case_when(is.na(date_creationB) ~ date_creationB,\n                                       date_creationA < date_creationB ~ date_creationB,\n                                       date_creationA >= date_creationB ~ date_creationA),\n         # On repère si il y a eu un changement de statut ou de frontières\n         mention_changement = str_detect(creation, mention_changement)) %>%\n    # On enlève les colonnes inutiles\n  select(-date_creationA, -date_creationB) %>%\n  # On place les colonnes créées à gauche pour les inspecter facilement\n  relocate(date_creation:mention_changement, .after = creation) \n\n# Après une vérification manuelle, on remarque les données de l'association Vahatra comportent des mentions incomplètes pour certaines aires, qui n'ont pas été extraites:\n\n\n# Lokobe : 31 décembre 1927\nAP_Vahatra <- AP_Vahatra %>%\n  mutate(date_creation = case_when(nom == \"Lokobe\" ~ ymd(\"1927-12-31\"),\n                                   nom == \"Mantadia\" ~ ymd(\"1989-01-11\"),\n                                   TRUE ~ date_creation),\n         date_modification = case_when(nom == \"Bemaraha\" ~ ymd(\"2011-07-06\"),\n                                       nom == \"Lokobe\" ~ ymd(\"2011-07-06\"),\n                                       nom == \"Tsaratanana\" ~ ymd(\"2011-07-06\"),\n                                       nom == \"Pic d'Ivohibe\" ~ ymd(\"2015-04-28\"),\n                                       nom == \"Mantadia\" ~ ymd(\"2002-08-07\"),\n                                       TRUE ~ date_modification)) %>%\n  st_make_valid() # fiabilise qu'il n'y a pas d'erreurs topologiques\n# dir.create(\"AP_Vahatra\")\n# st_write(AP_Vahatra, \"out/AP_Vahatra.shp\")\n# writexl::write_xlsx(st_drop_geometry(AP_Vahatra), \"AP_Vahatra.xlsx\")\n\n\nLe bloc de code suivant génère une carte interactive. On a également inclus des lignes de code qui permettent de formater la carte joliment pour un rendu figé (pdf/LaTeX, html statique, word), mais ce code est “commenté”, c’est-à-dire qu’on a placé des dièses au début de chaque ligne, de sorte qu’il ne s’exécute pas (R n’exécute jamais ce qui se trouve à droite d’un # sur une ligne). Pour plus de détails sur la manière dont on produit des cartes, voire l’annexe : Cartes simples en R\n\n\nCode\nif (file.exists(\"data/contour_mada.rds\")) {\n  load(\"data/contour_mada.rds\")\n} else {\n  contour_mada <- gadm(country = \"Madagascar\", resolution = 1, level = 0,\n                     path = \"data/GADM\") %>%\n  st_as_sf()\n# On enregistre contour_mada pour s'en servir par la suite\nsave(contour_mada, file = \"data/contour_mada.rds\")\n}\n\n# On génère un rendu cartographique\ntmap_mode(\"view\") # En mode interactif\ntm_shape(contour_mada) +\n  tm_borders() +\n  tm_shape(AP_Vahatra) + \n  tm_polygons(col = \"cat__iucn\", alpha = 0.6, title = \"Catégorie IUCN\") +\n  tmap_options(check.and.fix = TRUE) # +\n\n\n\n\n\n\n\nCode\n# Les dièses en début de ligne font que ce qui suit ne s'exécute pas.\n# La suite est uniquement pour les rendus fixes (tmap_mode = \"plot\"), p. ex. pour les pdf\n  # # NB : on note les positions en majuscules quand on veut coller aux marges\n  # tm_credits(\"Sources: WDPA et GADM\", position = c(\"RIGHT\", \"BOTTOM\"),\n  #            size = 0.6) +\n  # tm_layout(main.title = \"Aires protégées de Madagascar\",\n  #           # NB : position en minuscules pour laisser un espace avec la marge\n  #           main.title.position = c(\"center\", \"top\"),\n  #           main.title.size = taille_titres_cartes,\n  #           legend.position = c(\"left\", \"top\"),\n  #           legend.outside = TRUE)\n\n\nOn peut également réaliser un graphique qui présente l’historique de création des aires protégées. Pour plus de précisions sur la manière de produire des graphiques en R, voir l’annexe correspondante.\n\n\nCode\n# On ordonne les nom d'aires protégées dans l'ordre de leur séquence de création\nordre_chrono_AP <- AP_Vahatra %>%\n  arrange(desc(date_creation), desc(nom)) %>%\n  pull(nom)\n# On transforme le champ \"nom\" de caractère, à une catégorisation ordonnée où\n# l'ordre correspond \nAP_Vahatra_carte <- AP_Vahatra %>%\n  mutate(nom = factor(nom, levels = ordre_chrono_AP),\n         cat_taille = case_when(hectares > 300000 ~ 2,\n                                hectares > 150000 ~ 1.5,\n                                hectares >  50000 ~ 1,\n                                             TRUE ~ 0.5)) %>%\n  rename(`Catégorie IUCN` = cat__iucn)\n\n# On crée un graph pour les anciennetés\ngraph_gauche <- AP_Vahatra_carte %>%\n  ggplot(aes(x = date_creation, xend = ymd(\"2022-10-01\"), y = nom, yend = nom, \n                   color = `Catégorie IUCN`)) +\n  geom_segment(size = 2) +\n  ggtitle(\"Ancienneté\") +\n  theme(axis.ticks.y = element_blank(),\n        legend.position = \"none\",\n        axis.title = element_blank(),\n        axis.text.x.bottom =  element_text(angle = 45, hjust = 1),\n        axis.text.x.top = element_text(angle = -45, hjust = 1)) + \n  scale_x_date(sec.axis = dup_axis())\n\ngraph_droite <- AP_Vahatra_carte %>%\n  ggplot(aes(x = 0, xend = hectares/100, y = nom, yend = nom, \n                   color = `Catégorie IUCN`)) +\n  geom_segment(size = 2) + \n  ggtitle(\"Surface (km2)\") +\n  theme(axis.text.y = element_blank(),\n        axis.title = element_blank(),\n        axis.text.x.bottom =  element_text(angle = 45, hjust = 1),\n        axis.text.x.top = element_text(angle = -45, hjust = 0),\n        legend.position = \"none\") + \n  scale_x_continuous(sec.axis = dup_axis())\n\nlegende <- get_legend(graph_gauche  +\n                        guides(color = guide_legend(nrow = 1)) +\n                        theme(legend.position = \"bottom\"))\n\n# On colle les deux\ngraphs <- plot_grid(graph_gauche, graph_droite, rel_widths = c(2.2, 1),\n          nrow = 1)\nplot_grid(graphs, legende, ncol = 1,\n          rel_heights = c(1,.1))\n\n\n\n\n\nIl faut aussi s’assurer qu’on filtre bien les entités analysées selon un critère pertinent. Actuellement, on exclut les aires marines. Il pourrait toutefois sembler utile d’écarter les aires dont le statut de protection est considéré comme trop faible. Il pourrait aussi être pertinent de ne garder que les aires protégées comportant un niveau minimum de couvert forestier : autrement, cela signifie que la forêt n’est pas un habitat pertinent pour les écosystèmes que la démarche de conservation cherche à protéger dans cette aire."
  },
  {
    "objectID": "03-donnees_deforestation.html",
    "href": "03-donnees_deforestation.html",
    "title": "3  Couvert forestier",
    "section": "",
    "text": "Pour commencer, on récupère le travail réalisé par Carvalho et al. (2020) qui complète les informations physiques de Goodman et al. (2018) avec des données relatives au couvert forestier en 1996, 2006 et 2016 et la diversité d’espèces présentes.\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(sf)\n\n# Voir le chapitre \"Fondamentaux R\" pour une aide à l'import.\nsup2 <- read_xlsx(\"data/Carvalho2018sup2.xlsx\", # Enplacement du fichier\n                  skip = 8, # Premières lignes du tableau excel à ne pas lire\n                  n_max = 101,  # on ne lit pas les dernières lignes (notes)\n                  col_types = c(\"text\", \"text\", \"text\", \"text\", \n        \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \n        \"numeric\", \"numeric\", \"numeric\", \"numeric\"))\nsup4 <- read_xlsx(\"data/Carvalho2018sup4.xlsx\", skip = 6,\n                  col_types = c(\"text\", \"numeric\", \"text\", \"numeric\", \"numeric\", \n        \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\"))\n        \n\n# Carvalho et al. 2008 document in their supp. material 2: \"The three parcels that made up\n# Andohahela (Parcels I, II and III) comprised different types of dominant vegetation and\n# associated animal species, and were exposed to distinct pressures. Andohahela was analysed\n# in its entirety (site number 57), as well as separated\"\n\nsup2 <- sup2 %>% \n  mutate(PA = recode(PA, `Andohahela complete` = \"Andohahela\"),\n         num_atlas_ = as.integer(`Site number`))\n\nsup4 <- sup4 %>%\n  filter(`Habitat type` == \"TOTAL\") %>%\n  mutate(num_atlas_ = as.numeric(Parcel))\n\n\nload(\"data/ch2_AP_Vahatra.rds\")\n\nAP_Vahatra <- AP_Vahatra %>%\n  left_join(sup2, by = \"num_atlas_\") %>%\n  relocate(PA, .after = nom) %>%\n  left_join(sup4, by = \"num_atlas_\")\n\n\nOn complète cette information avec des données de couvert forestier."
  },
  {
    "objectID": "03-donnees_deforestation.html#mapme-exemple-gfc",
    "href": "03-donnees_deforestation.html#mapme-exemple-gfc",
    "title": "3  Couvert forestier",
    "section": "3.2 Mapme (exemple GFC)",
    "text": "3.2 Mapme (exemple GFC)\nLa procédure de traitement de ces fichiers sur Mapme est analogue à celle employée dans la section Chapter 2.\n\n\nCode\n# On charge les polygones travaillés au chapitre 2\nload(\"data/Vahatra_poly.rds\")\n\n# Constitution d'un portefeuille (voir la documentation)\nAP_poly <- init_portfolio(x = AP_poly, \n                          years = 2000:2020,\n                          outdir = \"data_s3/mapme\",\n                          cores = 16,\n                          add_resources = TRUE,\n                          verbose = TRUE)\n\n\n# Get GFW data\nAP_poly <- get_resources(x = AP_poly, \n                         resources = c(\"gfw_treecover\", \"gfw_lossyear\", \n                                       \"gfw_emissions\"))\n\n# Données d'accessibilité de Nelson et al. (2018)\nAP_poly <-  get_resources(x = AP_poly, resource = \"nelson_et_al\",  \n                          range_traveltime = \"5k_110mio\")\n# Données de qualité des sols (uniquement teneur )\nAP_poly  <-  get_resources(x = AP_poly,\n                           resources = \"soilgrids\",  layers = \"clay\", \n                           depths = \"5-15cm\", stats = \"mean\")\n# Modèle numérique de terrain SRTM de la NASA\nAP_poly <- get_resources(x = AP_poly, resource = \"nasa_srtm\")\n# Données de feux\nAP_poly <- get_resources(x = AP_poly, resource = \"nasa_firms\",\n                         instrument = \"MODIS\")\n\n# Get \n# Indicateurs de couvert forestier\nAP_poly  <- calc_indicators(x = AP_poly,\n                            indicators = \"treecover_area_and_emissions\", \n                            min_cover = 30, min_size = 1)\n\n# On réorganise les variables -----------------------------------------------\n# Couvert forestier annuel en colonnes plutôt qu'en liste imbriquée  \ndeforest_par_an <- AP_poly %>%\n  unnest(treecover_area_and_emissions) %>%\n  select(assetid, nom, years, treecover) %>%\n  filter(!is.na(years)) %>%\n  pivot_wider(names_from = \"years\", values_from = \"treecover\", \n              names_prefix = \"treecover_\") %>%\n  st_drop_geometry()\n\n# Jointure du couvert forestier en colonne avec les données initiales\nAP_poly <- AP_poly %>%\n  select(-treecover_area_and_emissions) %>%\n  left_join(deforest_par_an, by = \"assetid\")\n\n\nToutefois, en raison d’un problème liés à la gestion des calculs volumineux, les calculs pour certaines aires protégées renvoient des données aberrantes. Ce point sera mis à jour dans ce guide dès la résolution des erreurs rencontrées.\nA ce stade on se concentrera donc sur les données de TFM présentées plus bas."
  },
  {
    "objectID": "03-donnees_deforestation.html#google-earth-engine-exemple-gfc",
    "href": "03-donnees_deforestation.html#google-earth-engine-exemple-gfc",
    "title": "3  Couvert forestier",
    "section": "3.3 Google Earth Engine (exemple GFC)",
    "text": "3.3 Google Earth Engine (exemple GFC)\nLa plateforme Google Earth Engine est un outil particulièrement pratique et performant pour mobiliser et traiter des données satellitaires. Google Earth Engine peut être utilisé :\n\nen interrogeant son API, et notamment :\n\nen python, avec la librairie gee permet d’interroger l’API de Google Earth Engine.\nen R, au travers de la librairie rgee. Cette dernière est relativement facile d’usage, mais elle est difficile à configurer. Pour aller plus loin : https://r-earthengine.com/rgeebook/\n\ndirectement sur la plateforme https://code.earthengine.google.com/\n\nLa consolde de codage de Google Earth Engine prend la forme suivante :\n\n\n\nDiagramme des composants de la console Google Earth Engine\n\n\nLe langage utilisé sur cet interface est du Javascript. Ci-dessous un exemple de code qui génère les surface (en hectares) de perte de couvert forestier. Pour fonctionner, ce code doit être collé dans un script sur la plateforme Google Earth Engine lancé en cliquant sur “Run”, puis en cliquant sur “Tasks” pour exécuter le code.\n\n\nCode\n scale = 30\n    \n    // PREPARE DATA\n    //look at tree cover, find the area\n    var treeCover = gfc2021.select(['treecover2000']);\n    var areaCover = treeCover.multiply(ee.Image.pixelArea())\n                    .divide(10000).select([0],[\"areacover\"])\n    // total loss area\n    var loss = gfc2021.select(['loss']);\n    var areaLoss = loss.gt(0).multiply(ee.Image.pixelArea())\n                   .divide(10000).select([0],[\"arealoss\"]);\n    // total gain area\n    var gain = gfc2021.select(['gain'])\n    var areaGain = gain.gt(0).multiply(ee.Image.pixelArea())\n                   .divide(10000).select([0],[\"areagain\"]);\n    // final image\n    var total = gfc2021.addBands(areaCover)\n                .addBands(areaLoss)\n                .addBands(areaGain)\n\n    // TOTAL COVER\n    // Map cover area per feature\n    var districtSums = areaCover.reduceRegions({\n      collection: testgu,\n      reducer: ee.Reducer.sum(),\n      scale: scale,\n    });         \n    \n    var addVar = function(feature) {\n\n      // function to iterate over the sequence of years\n      var addVarYear = function(year, feat) {\n        // cast var\n        year = ee.Number(year).toInt()\n        feat = ee.Feature(feat)\n\n        // actual year to write as property\n        var actual_year = ee.Number(2000).add(year)\n\n        // filter year:\n        // 1st: get mask\n        var filtered = total.select(\"lossyear\").eq(year)\n        // 2nd: apply mask\n        filtered = total.updateMask(filtered)\n\n        // reduce variables over the feature\n        var reduc = filtered.reduceRegion({\n          geometry: feature.geometry(),\n          reducer: ee.Reducer.sum(),\n          scale: scale,\n          maxPixels: 1e9\n        })\n\n        // get results\n        var loss = ee.Number(reduc.get(\"arealoss\"))\n        var gain = ee.Number(reduc.get(\"areagain\"))\n\n        // set names\n        var nameloss = ee.String(\"loss_\").cat(actual_year)\n        var namegain = ee.String(\"gain_\").cat(actual_year)\n\n        // set properties to the feature\n        return feat.set(nameloss, loss, namegain, gain)\n      }\n\n      // iterate over the sequence\n      var newfeat = ee.Feature(years.iterate(addVarYear, feature));\n\n      // return feature with new properties\n      return newfeat\n    }\n\n    // Map over the FeatureCollection\n    var areas = districtSums.map(addVar);\n    \n    // Export PA deforestation to a CSV file.\n    Export.table.toDrive({\n      collection: areas,\n      description: 'forest_loss_WDPA_Madagascar',\n      fileFormat: 'CSV'\n    });"
  },
  {
    "objectID": "03-donnees_deforestation.html#python-exemple-tmf",
    "href": "03-donnees_deforestation.html#python-exemple-tmf",
    "title": "3  Couvert forestier",
    "section": "3.4 Python (exemple TMF)",
    "text": "3.4 Python (exemple TMF)\nFichiers préparés en python (code à venir), directement sur les rasters.\n\n\nCode\n# On charge les fichiers préparés par Marc en python (contient 2 feuilles)\ntableur_tmf <- \"data/TMFchangeYear_AP_Vahatra.xlsx\"\n# On commence par charger la feuille déforestation\ntmf_vahatra_defor <- read_excel(tableur_tmf,\n                              sheet = \"TMFdeforestationYear\") %>%\n  select(nom, starts_with(\"TMF\")) # on ne garde que les variables pertinentes\n# On fait ensuite de même avec la feuille dégradation\ntmf_vahatra_degrad <- read_excel(tableur_tmf,\n                              sheet = \"TMFdegradationYear\") %>%\n  select(nom, starts_with(\"TMF\")) # Onn ne garde que les feuilles pertinentes\n\nAP_Vahatra <- AP_Vahatra %>%\n  left_join(tmf_vahatra_degrad, by = \"nom\")\n  # left_join(tmf_vahatra_defor, by = \"nom\") %>%\n\n\nTMF_ratios <- AP_Vahatra %>%\n  st_drop_geometry() %>%\n  select(nom, starts_with(\"Forest cover\"), starts_with(\"TMF\")) %>%\n  pivot_longer(cols = starts_with(\"TMF\"), \n               names_to = \"variable\", \n               values_to = \"surface_ha\") %>%\n  mutate(an_valeur = str_extract(variable, \"[:digit:]{4}\"),\n         an_valeur = as.numeric(an_valeur),\n         surface_ratio = case_when(\n           an_valeur < 2000 ~ surface_ha / `Forest cover (ha) in 2006`,\n           an_valeur > 2009 ~ surface_ha / `Forest cover (ha) in 2016`,\n           TRUE ~ surface_ha / `Forest cover (ha) in 2006`),\n         variable = str_replace(variable, \"HA\", \"ratio\")) %>%\n  select(nom, variable, surface_ratio) %>%\n  pivot_wider(names_from = variable, values_from = surface_ratio) %>%\n  select(nom, starts_with(\"TMF\"))\n  \nAP_Vahatra <- AP_Vahatra %>%\n   left_join(TMF_ratios, by = \"nom\")\n\nsave(AP_Vahatra, file = \"data/ch3_AP_Vahatra.rds\")"
  },
  {
    "objectID": "01-aires_protegees.html#carvalho-et-al.-source-modis",
    "href": "01-aires_protegees.html#carvalho-et-al.-source-modis",
    "title": "1  Aires protégées",
    "section": "3.1 Carvalho et al. (source MODIS)",
    "text": "3.1 Carvalho et al. (source MODIS)\nPour commencer, on récupère le travail réalisé par Carvalho et al. (2020) qui complète les informations physiques de Goodman et al. (2018) avec des données relatives au couvert forestier en 1996, 2006 et 2016 et la diversité d’espèces présentes.\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(sf)\n\n# Voir le chapitre \"Fondamentaux R\" pour une aide à l'import.\nsup2 <- read_xlsx(\"data/Carvalho2018sup2.xlsx\", # Enplacement du fichier\n                  skip = 8, # Premières lignes du tableau excel à ne pas lire\n                  n_max = 101,  # on ne lit pas les dernières lignes (notes)\n                  col_types = c(\"text\", \"text\", \"text\", \"text\", \n        \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \n        \"numeric\", \"numeric\", \"numeric\", \"numeric\"))\nsup4 <- read_xlsx(\"data/Carvalho2018sup4.xlsx\", skip = 6,\n                  col_types = c(\"text\", \"numeric\", \"text\", \"numeric\", \"numeric\", \n        \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\"))\n        \n\n# Carvalho et al. 2008 document in their supp. material 2: \"The three parcels that made up\n# Andohahela (Parcels I, II and III) comprised different types of dominant vegetation and\n# associated animal species, and were exposed to distinct pressures. Andohahela was analysed\n# in its entirety (site number 57), as well as separated\"\n\nsup2 <- sup2 %>% \n  mutate(PA = recode(PA, `Andohahela complete` = \"Andohahela\"),\n         num_atlas_ = as.integer(`Site number`))\n\nsup4 <- sup4 %>%\n  filter(`Habitat type` == \"TOTAL\") %>%\n  mutate(num_atlas_ = as.numeric(Parcel))\n\n\nload(\"data/ch2_AP_Vahatra.rds\")\n\nAP_Vahatra <- AP_Vahatra %>%\n  left_join(sup2, by = \"num_atlas_\") %>%\n  relocate(PA, .after = nom) %>%\n  left_join(sup4, by = \"num_atlas_\")\n\nOn complète cette information avec des données de couvert forestier."
  },
  {
    "objectID": "01-aires_protegees.html#mapme-exemple-gfc",
    "href": "01-aires_protegees.html#mapme-exemple-gfc",
    "title": "1  Aires protégées",
    "section": "3.2 Mapme (exemple GFC)",
    "text": "3.2 Mapme (exemple GFC)\nLa procédure de traitement de ces fichiers sur Mapme est analogue à celle employée dans la section Chapter 2.\n#| eval: false\n\n# On charge les polygones travaillés au chapitre 2\nload(\"data/Vahatra_poly.rds\")\n\n# Constitution d'un portefeuille (voir la documentation)\nAP_poly <- init_portfolio(x = AP_poly, \n                          years = 2000:2020,\n                          outdir = \"data_s3/mapme\",\n                          cores = 16,\n                          add_resources = TRUE,\n                          verbose = TRUE)\n\n\n# Get GFW data\nAP_poly <- get_resources(x = AP_poly, \n                         resources = c(\"gfw_treecover\", \"gfw_lossyear\", \n                                       \"gfw_emissions\"))\n\n# Données d'accessibilité de Nelson et al. (2018)\nAP_poly <-  get_resources(x = AP_poly, resource = \"nelson_et_al\",  \n                          range_traveltime = \"5k_110mio\")\n# Données de qualité des sols (uniquement teneur )\nAP_poly  <-  get_resources(x = AP_poly,\n                           resources = \"soilgrids\",  layers = \"clay\", \n                           depths = \"5-15cm\", stats = \"mean\")\n# Modèle numérique de terrain SRTM de la NASA\nAP_poly <- get_resources(x = AP_poly, resource = \"nasa_srtm\")\n# Données de feux\nAP_poly <- get_resources(x = AP_poly, resource = \"nasa_firms\",\n                         instrument = \"MODIS\")\n\n# Get \n# Indicateurs de couvert forestier\nAP_poly  <- calc_indicators(x = AP_poly,\n                            indicators = \"treecover_area_and_emissions\", \n                            min_cover = 30, min_size = 1)\n\n# On réorganise les variables -----------------------------------------------\n# Couvert forestier annuel en colonnes plutôt qu'en liste imbriquée  \ndeforest_par_an <- AP_poly %>%\n  unnest(treecover_area_and_emissions) %>%\n  select(assetid, nom, years, treecover) %>%\n  filter(!is.na(years)) %>%\n  pivot_wider(names_from = \"years\", values_from = \"treecover\", \n              names_prefix = \"treecover_\") %>%\n  st_drop_geometry()\n\n# Jointure du couvert forestier en colonne avec les données initiales\nAP_poly <- AP_poly %>%\n  select(-treecover_area_and_emissions) %>%\n  left_join(deforest_par_an, by = \"assetid\")\nToutefois, en raison d’un problème liés à la gestion des calculs volumineux, les calculs pour certaines aires protégées renvoient des données aberrantes. Ce point sera mis à jour dans ce guide dès la résolution des erreurs rencontrées.\nA ce stade on se concentrera donc sur les données de TFM présentées plus bas."
  },
  {
    "objectID": "01-aires_protegees.html#google-earth-engine-exemple-gfc",
    "href": "01-aires_protegees.html#google-earth-engine-exemple-gfc",
    "title": "1  Aires protégées",
    "section": "3.3 Google Earth Engine (exemple GFC)",
    "text": "3.3 Google Earth Engine (exemple GFC)\nLa plateforme Google Earth Engine est un outil particulièrement pratique et performant pour mobiliser et traiter des données satellitaires. Google Earth Engine peut être utilisé :\n\nen interrogeant son API, et notamment :\n\nen python, avec la librairie gee permet d’interroger l’API de Google Earth Engine.\nen R, au travers de la librairie rgee. Cette dernière est relativement facile d’usage, mais elle est difficile à configurer. Pour aller plus loin : https://r-earthengine.com/rgeebook/\n\ndirectement sur la plateforme https://code.earthengine.google.com/\n\nLa consolde de codage de Google Earth Engine prend la forme suivante :\n\n\n\nDiagramme des composants de la console Google Earth Engine\n\n\nLe langage utilisé sur cet interface est du Javascript. Ci-dessous un exemple de code qui génère les surface (en hectares) de perte de couvert forestier. Pour fonctionner, ce code doit être collé dans un script sur la plateforme Google Earth Engine lancé en cliquant sur “Run”, puis en cliquant sur “Tasks” pour exécuter le code.\n#| eval: false\n\n scale = 30\n    \n    // PREPARE DATA\n    //look at tree cover, find the area\n    var treeCover = gfc2021.select(['treecover2000']);\n    var areaCover = treeCover.multiply(ee.Image.pixelArea())\n                    .divide(10000).select([0],[\"areacover\"])\n    // total loss area\n    var loss = gfc2021.select(['loss']);\n    var areaLoss = loss.gt(0).multiply(ee.Image.pixelArea())\n                   .divide(10000).select([0],[\"arealoss\"]);\n    // total gain area\n    var gain = gfc2021.select(['gain'])\n    var areaGain = gain.gt(0).multiply(ee.Image.pixelArea())\n                   .divide(10000).select([0],[\"areagain\"]);\n    // final image\n    var total = gfc2021.addBands(areaCover)\n                .addBands(areaLoss)\n                .addBands(areaGain)\n\n    // TOTAL COVER\n    // Map cover area per feature\n    var districtSums = areaCover.reduceRegions({\n      collection: testgu,\n      reducer: ee.Reducer.sum(),\n      scale: scale,\n    });         \n    \n    var addVar = function(feature) {\n\n      // function to iterate over the sequence of years\n      var addVarYear = function(year, feat) {\n        // cast var\n        year = ee.Number(year).toInt()\n        feat = ee.Feature(feat)\n\n        // actual year to write as property\n        var actual_year = ee.Number(2000).add(year)\n\n        // filter year:\n        // 1st: get mask\n        var filtered = total.select(\"lossyear\").eq(year)\n        // 2nd: apply mask\n        filtered = total.updateMask(filtered)\n\n        // reduce variables over the feature\n        var reduc = filtered.reduceRegion({\n          geometry: feature.geometry(),\n          reducer: ee.Reducer.sum(),\n          scale: scale,\n          maxPixels: 1e9\n        })\n\n        // get results\n        var loss = ee.Number(reduc.get(\"arealoss\"))\n        var gain = ee.Number(reduc.get(\"areagain\"))\n\n        // set names\n        var nameloss = ee.String(\"loss_\").cat(actual_year)\n        var namegain = ee.String(\"gain_\").cat(actual_year)\n\n        // set properties to the feature\n        return feat.set(nameloss, loss, namegain, gain)\n      }\n\n      // iterate over the sequence\n      var newfeat = ee.Feature(years.iterate(addVarYear, feature));\n\n      // return feature with new properties\n      return newfeat\n    }\n\n    // Map over the FeatureCollection\n    var areas = districtSums.map(addVar);\n    \n    // Export PA deforestation to a CSV file.\n    Export.table.toDrive({\n      collection: areas,\n      description: 'forest_loss_WDPA_Madagascar',\n      fileFormat: 'CSV'\n    });"
  },
  {
    "objectID": "01-aires_protegees.html#python-exemple-tmf",
    "href": "01-aires_protegees.html#python-exemple-tmf",
    "title": "1  Aires protégées",
    "section": "3.4 Python (exemple TMF)",
    "text": "3.4 Python (exemple TMF)\nFichiers préparés en python (code à venir), directement sur les rasters.\n#| eval: false\n# On charge les fichiers préparés par Marc en python (contient 2 feuilles)\ntableur_tmf <- \"data/TMFchangeYear_AP_Vahatra.xlsx\"\n# On commence par charger la feuille déforestation\ntmf_vahatra_defor <- read_excel(tableur_tmf,\n                              sheet = \"TMFdeforestationYear\") %>%\n  select(nom, starts_with(\"TMF\")) # on ne garde que les variables pertinentes\n# On fait ensuite de même avec la feuille dégradation\ntmf_vahatra_degrad <- read_excel(tableur_tmf,\n                              sheet = \"TMFdegradationYear\") %>%\n  select(nom, starts_with(\"TMF\")) # Onn ne garde que les feuilles pertinentes\n\nAP_Vahatra <- AP_Vahatra %>%\n  left_join(tmf_vahatra_degrad, by = \"nom\")\n  # left_join(tmf_vahatra_defor, by = \"nom\") %>%\n\n\nTMF_ratios <- AP_Vahatra %>%\n  st_drop_geometry() %>%\n  select(nom, starts_with(\"Forest cover\"), starts_with(\"TMF\")) %>%\n  pivot_longer(cols = starts_with(\"TMF\"), \n               names_to = \"variable\", \n               values_to = \"surface_ha\") %>%\n  mutate(an_valeur = str_extract(variable, \"[:digit:]{4}\"),\n         an_valeur = as.numeric(an_valeur),\n         surface_ratio = case_when(\n           an_valeur < 2000 ~ surface_ha / `Forest cover (ha) in 2006`,\n           an_valeur > 2009 ~ surface_ha / `Forest cover (ha) in 2016`,\n           TRUE ~ surface_ha / `Forest cover (ha) in 2006`),\n         variable = str_replace(variable, \"HA\", \"ratio\")) %>%\n  select(nom, variable, surface_ratio) %>%\n  pivot_wider(names_from = variable, values_from = surface_ratio) %>%\n  select(nom, starts_with(\"TMF\"))\n  \nAP_Vahatra <- AP_Vahatra %>%\n   left_join(TMF_ratios, by = \"nom\")\n\nsave(AP_Vahatra, file = \"data/ch3_AP_Vahatra.rds\")"
  },
  {
    "objectID": "01-aires_protegees.html#alternatives",
    "href": "01-aires_protegees.html#alternatives",
    "title": "1  Aires protégées",
    "section": "3.5 Alternatives",
    "text": "3.5 Alternatives\nSi on n’est pas à l’aise avec les outils mentionnés plus haut, l’outil Geoquery d’AidData permet d’obtenir des statistiques par aire administrative. Il est également possible de formuler des demandes spécifiques pour d’autres polygones que des aires administratives au travers d’un formulaire dédié."
  }
]