[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Impact des aires protégées sur la déforestation : guide de formation pratique",
    "section": "",
    "text": "Préface\nCe contenu a été développé afin de servir de support pédagogique pour l’atelier “évaluation des politiques” de la session 2022 des Universités en sciences sociales Tany Vao. Les universités Tany Vao visent à dispenser une formation à la recherche de haut niveau à l’attention de doctorants et jeunes chercheurs de Madagascar et d’Afrique de l’Ouest. Après deux jours de plénières, les participants se répartissent pendant cinq jours entre quatre ateliers parallèles : socioéconomie, éthno-écologie, anthropologie et évaluation des politiques.\nL’atelier “évaluation des politiques” adopte une approche axée sur l’économétrie et la science des données. Il alterne des sessions théorique et pratique. Conformément au thème phare de Tany Vao pour 2022 (“environnement et sociétés”), le cas d’étude choisi pour servir de fil rouge à ces travaux est l’impact des aires protégées sur la déforestation.\n\nMise en garde : ce document est en cours de développement : il est encore incomplet et il est susceptible de contenir des erreurs. N’hésitez pas à les signaler en cliquant sur l’icône Github en haut à gauche et en créant un signalement (“Issue”).\n\nPhoto en couverture : “Déforestation à Madagascar” © IRD - Bernard Moizo"
  },
  {
    "objectID": "00-intro.html#démarche",
    "href": "00-intro.html#démarche",
    "title": "Introduction",
    "section": "Démarche",
    "text": "Démarche\nIl s’agit d’un support de formation conçu pour initier des étudiants et jeunes chercheurs non familiers de l’économétrie spatiale, avec un objet très concret. Ce document a été élaboré avec les priorités suivantes :\n\nFamiliarisation avec la démarche scientifique : recherche bibliographique, revue d’articles économétriques ;\nFormulaion d’une question de recherche relevant de l’évaluation économétrique et recherche des donnéees permettant d’y répondre ;\nCompréhension des différentes approches pour constituer un contrefactuel : randomisation, appariement, comparaison avant-après, différence de différences ;\nFamiliarisation avec l’outil de traitement statistique R.\n\nD’autres aspects ont volontairement été placés au second plan, en particulier la discussion technique de la fiabilité, différences et biais des sources de données mobilisées, ou encore les subtilités associées aux modèles économétriques. Les méthodes économétriques mobilisées ici sont volontairement simples : pour être publiable dans une revue scientifique, un travail d’évaluation doit mobiliser des spécifications plus sophistiquées.\n\nAméliorations à venir\n\nRemplacer la variable de temps de parcours à une ville d’au moins 5000 habitants par une variable moins exposée à l’endogénéité, soit :\n\nLa distance à une ville d’au moins 5000 habitants en 2000 ; ou\nLa distance euclidienne à une ville, sans tenir compte du réseau de transport.\n\nAjouter de la discontinuité de la régression"
  },
  {
    "objectID": "00-intro.html#outils-utilisés",
    "href": "00-intro.html#outils-utilisés",
    "title": "Introduction",
    "section": "Outils utilisés",
    "text": "Outils utilisés\n\nNotebook Quarto\nLes éléments ci-dessous constituent le support pour les sessions pratiques de cet atelier. Ils sont réalisés en suivant une approche ouverte et reproductible fondée sur un document de type “notebook” (Bédécarrats and Hobeika 2017). Un notebook rassemble à la fois :\n\nles lignes de code du programme statistique qui traite les données ;\nles résultats (calculs, tableaux, graphiques…) produits lors de l’exécution de ce programme ;\nle texte rédigé par les auteurs pour expliquer le processus d’analyse et en interpréter les résultats.\n\nL’intérêt du format notebook, par rapport à l’utilisation de documents distincts pour traiter les données d’une part, et en analyser les résultats d’autre part, est multiple :\n\nfavoriser la reproductibité de la recherche (tout le processus de traitement, analyse, interprétation peut être inspecté et dupliqué) ;\nfaciliter le travail du chercheur (une interface pour tout faire) ; et\nassurer les meilleures pratiques de collaboration (utilisation pour le versionnage, partage et fusion des travaux les outils performants développés en programmation informatique).\n\nLes traitements sont réalisés en R, qui est à la fois un logiciel et un langage open sources dédiés à l’analyse de données. Les traitements R sont inclus dans un document Quarto, un format qui exécute aussi bien des codes en R, Python, e rendus dans différents formats (LaTeX/PDF, HTML ou Word).\nLa mise en forme des rendus Quarto est paramétrable. Ici, on a notamment placé un argument code-fold: true dans le fichier _quarto.yml. Cela fait que les blocs de code ne sont pas visible dans le rendu web par défaut : il faut cliquer sur “code” pour les déplier.\n\n\nMapme.biodiversity\nOn s’appuie sur le package R {mapme.biodiversity}, développé par la KfW dans le cadre de l’initiative commune MAPME qui associe la KfW et l’AFD. Le package {mapme.biodiversity} facilite l’acquisition et la préparation d’un grand nombre de données (CHIRPS, Global Forest Watch, FIRMS, SRTM, Worldpop…) et calculer un grand nombre d’indicateurs de manière harmonisée (active_fire_counts, biome classification, land cover classification, population count, precipitation, soil properties, tree cover loss, travel time…). Une documentation riche est disponible sur le portail dédié du package en question (Kluve et al. 2022).\nOn mobilise aussi les codes d’analyse d’impact développés par la même équipe et mises à disposition dans le dépôt Github: https://github.com/openkfw/mapme.protectedareas. Le code développé par l’équipe est assez complexe. A des fins pédagogiques et pour s’assurer qu’on l’a bien compris, on propose ici une version simplifiée (en cours de développement).\n\n\nOnyxia/SSP Cloud\nLes sources pour l’ensemble du code source et du texte du présent document est accessible sur Github à l’adresse suivante : https://github.com/fBedecarrats/conservation-deforestation-madagascar. Les analyses sont menées sur la plateforme SSP Cloud, mises à disposition par l’INSEE pour les data scientists travaillant pour des administrations publiques. Il s’agit d’une instance de stockage de données massif (S3) et de calcul haute performance (cluster Kubernetes) disposant d’une interface simplifiée permettant à l’utilisateur de configurer, lancer et administrer facilement des environnements de traitement de données (RStudio server, Jupyter lab ou autres…). Le code est conçu pour s’exécuter de la même manière en local sur un PC, mais la préparation des données sera certainement beaucoup plus longue à exécuter.\n\n\nLibrairies R\nOutre Mapme.biodiversity, on mobilise une série de librairies (appelées “packages” en R), qui facilitent grandement l’analyse. Elles sont listées dans le bloc ci-dessous.\n\n\nCode\n# # Le package est en cours de développement, toujours installer la version en cours\nremotes::install_github(\"mapme-initiative/mapme.biodiversity\",\n                        upgrade = \"always\")\n\nlibrairies_requises <- c( # On liste les librairies dont on a besoin\n  \"tidyverse\", # Une série de packages pour faciliter la manipulation de données\n  \"readxl\", # Pour lire les fichiers excel (Carvalho et al. 2018)\n  \"writexl\", # Pour écrire des fichiers excel\n  \"cowplot\", # Pour arranger des graphiques en illustrations composées\n  \"gt\", # Pour des rendus graphiques harmonisés html et pdf/LaTeX\n  \"sf\", # Pour faciliter la manipulation de données géographiques\n  \"wdpar\", # Pour télécharger simplement la base d'aires protégées WDPA\n  \"webdriver\", # requis pour installer phantomjs pour wdpar\n  \"tmap\", # Pour produire de jolies carte\n  \"geodata\", # Pour télécharger simplement les frontières administratives\n  \"tidygeocoder\", # pour obtenir les coordo GPS d'un point à partir de son nom\n  \"maptiles\", # Pour télécharger des fonds de carte \n  # \"mapme.biodiversity\", # Acquisition et traitement des données du projet\n  \"plm\", # Linear Models for Panel Data and robust covariance matrices\n  \"broom\", # pour reformater simplement les rendus de tests statistiques\n  \"stargazer\", # Reformater de manière plus lisible les résumé des régressions\n  \"MatchIt\", # Pour le matching\n  #\"glm\", # Modèles linéaires généralisés (pour le PSM)\n  \"optmatch\", # Fonctions d'optimisation du matching\n  \"rgee\",\n  \"did\", # Méthode de double différence échelonnée de Callaway et Sant'Anna\n  \"cobalt\") # Tables et graphs d'équilibre des groupes de matching\n  \n# On regarde parmi ces librairies lesquelles ne sont pas installées\nmanquantes <- !(librairies_requises %in% installed.packages())\n# On installe celles qui manquent\nif(any(manquantes)) install.packages(librairies_requises[manquantes])\n\n## On charge toutes les librairies requises\n## On fera le chargement dans le chapitres pour expliciter les manips\n# invisible(lapply(librairies_requises, require, character.only= TRUE))\n\n# TODO : repasser les paramètres ci-dessous en clair dans les chapitres\n# Système de coordonnées géographiques utilisées pour le projet : EPSG:29739\nmon_scr <- \"EPSG:29739\" # correspondant à Tananarive / UTM zone 39S\n# Surface des hexagones en km2\ntaille_hex <- 5\n# Taille des titres des cartes\ntaille_titres_cartes = 1\n# on crée un dossier de données si pas déjà disponible\ndir.create(\"data\")\n# Désactiver les notations scientifiques\noptions(scipen =999)"
  },
  {
    "objectID": "00-intro.html#cadrage-général-pour-les-méthodes-dévaluation",
    "href": "00-intro.html#cadrage-général-pour-les-méthodes-dévaluation",
    "title": "Introduction",
    "section": "Cadrage général pour les méthodes d’évaluation",
    "text": "Cadrage général pour les méthodes d’évaluation\nCliquer sur ce lien pour télécharger la présentation.\n\n\n\n\nBédécarrats, Florent, and Alexandre Hobeika. 2017. “Une Alternative à Word : Écrire En RMarkdown.” Billet. Data Sciences Sociales. http://data.hypotheses.org/1144.\n\n\nKluve, Jochen, Johannes Schielain, Melvin Wong, and Yota Eilers. 2022. “The KfW Protected Areas Portfolio: A Rigorous Impact Evaluation.” Frankfürt."
  },
  {
    "objectID": "01-aires_protegees.html#données-de-lassociation-vahatra",
    "href": "01-aires_protegees.html#données-de-lassociation-vahatra",
    "title": "1  Aires protégées",
    "section": "1.1 Données de l’association Vahatra",
    "text": "1.1 Données de l’association Vahatra\nLes études sur les aires protégées s’appuient fréquemment sur la base WDPA (World Database on Protected Area), consultable en ligne sur https://protectedplanet.net. On s’aperçoit dans le cas de Madagascar que cette base de données comporte de nombreuses erreurs (qu’on étudiera plus bas). La base rassemblée par l’association Vahatra dans le cadre de la monographie qu’elle a coordonnée sur l’ensemble des aires protégées terrestres malgaches semble beaucoup plus fiable (Goodman et al. 2018). Les données en question sont disponibles sur le portail https://protectedareas.mg avec une licence creative commons (CC-BY).\nLe bloc de code ci-dessous (cliquer sur “code” pour visualiser), présente la séquence d’opérations réalisées pour préparer les données.Pour comprendre certaines opérations contenues dans le bloc de code, il est utile d’être familier de la syntaxe de R et des packages du tidyverse. Voir le chapitre Chapter 11.\n\n\nCode\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(sf)\nlibrary(tmap)\nlibrary(geodata)\nlibrary(cowplot)\nlibrary(wdpar)\nlibrary(gt) # Pour faciliter le rendu des tableaux (et ils sont jolis)\n\n# Le shapefile est composé d'une série de fichiers, (.shp, .dbf, .prj, .shx)\n# qui doivent avoir le même nom et être au même endroits pour être ouverts en\n# même temps. Comme souvent, ils sont compressés ensemble dans un fichier zip.\n# On commence par dézipper (décompresser) ce fichier.\nunzip(\"data/Vahatra98AP.zip\", exdir = \"data/Vahatra\")\n# On importe dans R en pointant vers le fichier .shp, mais c'est bien toute la\n# collection de fichiers homonymes .shp, .dbf, .shx qui est chargée.\nAP_Vahatra <- st_read(\"data/Vahatra/Vahatra98AP.shp\", quiet = TRUE) %>%\n  # Il manque la projection (pas de fichier .prj), on la spécifie à la main\n  st_set_crs(\"EPSG:4326\") %>% # EPSG 4325 = WSG 84 = le standard pour le web\n  rename(cat_iucn = cat__iucn) # une variable a un nom étrange : on simplifie\n# L'option ci-dessous est un peu cryptique : des caractéristiques topologiques\n# de la carte source sont incompatibles avec la possibilité d'avoir des objets\n# sphériques dans sf. Cela disparait si on désactive cette possibilité\nsf_use_s2(FALSE) \n\n# Identification des dates ----------------------------------------------------\n# Cette section est un brin complexe, à base de manipulation de chaînes de \n# caractères et de dates\n\n# Détecte les dates écrites 2 avril 2020 ou 02 avril 2020, etc.\ndate_ecrite <- \"[:digit:]{1,2} [:alpha:]* [:digit:]{4}\"\n# Détecte les dates écrites 02/04/20 ou 02.04.20 ou 02.04.2020, etc.\ndate_abrev <- \"[:digit:]{2}[:punct:][:digit:]{2}[:punct:][:digit:]{2,4}\"\n# Des années écrites à 2 chiffres\ndate_ecrite_an_abrev <- \"[:digit:]{1,2} [:alpha:]* [:digit:]{4}\"\n# Détecte l'une ou l'autre des formes précédentes\ntoute_date <- paste(date_ecrite, date_abrev, date_ecrite_an_abrev, sep = \"|\")\n# Détecte une mention d'année seule : 1984, 2015, etc.\nannee_seule <- \"[:digit:]{4}\"\n# Détecte les formes indicatrices d'un changement\nmention_changement <- \"Changement|changement|anciennement|actuel|auparavant\"\n# Une fonction qui traduit les dates écrites en toutes lettre du français à \n# l'anglais (pour les parser ensuite car ça ne fonctionne qu'en anglais)\ntrad_dates <- function(date_fr) {\n  str_replace_all(date_fr,\n                  c(\"janvier\" = \"January\",\n                    \"fevrier\" = \"February\",\n                    \"mars\" = \"March\",\n                    \"avril\" = \"April\",\n                    \"mai\" = \"May\",\n                    \"juin\" = \"June\",\n                    \"juillet\" = \"July\",\n                    \"aout\" = \"August\",\n                    \"septembre|setembre\" = \"September\",\n                    \"octobre\" = \"October\",\n                    \"novembre\" = \"November\",\n                    \"decembre|decmbre\" = \"December\"))\n}\n# Cette fonction remplace 01.04.58 par 01.04.1958 et marche avec . ou /\n# On indique avec limite le nombre d'année où on considère que c'est 1900 vs 2000\ncomplete_annee <- function(date_abrev, limite = 20) {\n  if (str_detect(date_abrev, \"([:punct:])([:digit:]{2})[:punct:]?$\")) {\n    date_abrev <- str_remove(date_abrev, \":punct:]?$\")\n    if (as.numeric(str_extract(date_abrev, \"[:digit:]{2}$\")) > limite) {\n      date_abrev <- str_replace(date_abrev, \n                                \"([:punct:])([:digit:]{2})[:punct:]?$\", \"\\\\119\\\\2\")\n    } else {\n      date_abrev <- str_replace(date_abrev, \n                                \"([:punct:])([:digit:]{2})[:punct:]?$\", \"\\\\120\\\\2\")\n    }\n  }\n  return(date_abrev)\n}\n# La fonction précédente est unitaire, on la transforme pour qu'elle s'applique à une liste.\ncomplete_liste_dates <- function(liste_dates) {\n  map(liste_dates, complete_annee)\n}\n\nAP_Vahatra <- AP_Vahatra %>%\n  # On extrait les dates des champs de texte\n  mutate(date_creation = str_extract_all(creation, toute_date), \n         # Une date a un format incohérent, on la recode à la main\n         date_creation = ifelse(creation == \"Créée le 07 aout 04\",\n                                \"07 aout 2004\", date_creation),\n         date_creationA = map(date_creation, 1), # La 1ère date\n         date_creationB = map(date_creation, 2)) %>% # Si 2 dates, la seconde\n  # On traduit les mois en anglais pour une conversion au format date\n  mutate(across(c(date_creationA, date_creationB), trad_dates)) %>%\n  mutate(across(c(date_creationA, date_creationB), complete_liste_dates)) %>%\n  mutate(across(c(date_creationA, date_creationB), dmy)) %>%\n  mutate(date_creation = case_when(is.na(date_creationB) ~ date_creationA,\n                                    date_creationA > date_creationB ~ date_creationB,\n                                    date_creationA <= date_creationB ~ date_creationA),\n         date_modification = case_when(is.na(date_creationB) ~ date_creationB,\n                                       date_creationA < date_creationB ~ date_creationB,\n                                       date_creationA >= date_creationB ~ date_creationA),\n         # On repère si il y a eu un changement de statut ou de frontières\n         mention_changement = str_detect(creation, mention_changement)) %>%\n    # On enlève les colonnes inutiles\n  select(-date_creationA, -date_creationB) %>%\n  # On place les colonnes créées à gauche pour les inspecter facilement\n  relocate(date_creation:mention_changement, .after = creation) \n# Après une vérification manuelle, on remarque les données de l'association Vahatra comportent des mentions incomplètes pour certaines aires, qui n'ont pas été extraites:\nAP_Vahatra <- AP_Vahatra %>%\n  mutate(date_creation = case_when(nom == \"Lokobe\" ~ ymd(\"1927-12-31\"),\n                                   nom == \"Mantadia\" ~ ymd(\"1989-01-11\"),\n                                   TRUE ~ date_creation),\n         date_modification = case_when(nom == \"Bemaraha\" ~ ymd(\"2011-07-06\"),\n                                       nom == \"Lokobe\" ~ ymd(\"2011-07-06\"),\n                                       nom == \"Tsaratanana\" ~ ymd(\"2011-07-06\"),\n                                       nom == \"Pic d'Ivohibe\" ~ ymd(\"2015-04-28\"),\n                                       nom == \"Mantadia\" ~ ymd(\"2002-08-07\"),\n                                       TRUE ~ date_modification),\n         an_creation = year(date_creation)) %>%\n  st_make_valid() # fiabilise qu'il n'y a pas d'erreurs topologiques\n# dir.create(\"AP_Vahatra\")\n# st_write(AP_Vahatra, \"out/AP_Vahatra.shp\")\n# writexl::write_xlsx(st_drop_geometry(AP_Vahatra), \"AP_Vahatra.xlsx\")\n\n\nLe bloc de code suivant génère une carte interactive. On a également inclus des lignes de code qui permettent de formater la carte joliment pour un rendu figé (pdf/LaTeX, html statique, word), mais ce code est “commenté”, c’est-à-dire qu’on a placé des dièses au début de chaque ligne, de sorte qu’il ne s’exécute pas (R n’exécute jamais ce qui se trouve à droite d’un # sur une ligne). Pour plus de détails sur la manière dont on produit des cartes, voire la section “Cartes simples avec R” dans le chapitre Chapter 11.\n\n\nCode\n# On regarde si les frontières terrestres de Mada ont déjà été téléchargées\nif (file.exists(\"data/contour_mada.rds\")) {\n  # Si c'\"est le cas, on charge la version déjà disponible localement\n  load(\"data/contour_mada.rds\")\n} else {\n  # Sinon on la télécharge depuis la base GADM\n  contour_mada <- gadm(country = \"Madagascar\", resolution = 1, level = 0,\n                     path = \"data/GADM\") %>%\n  st_as_sf()\n# On enregistre contour_mada pour s'en servir par la suite\nsave(contour_mada, file = \"data/contour_mada.rds\")\n}\n\n# On génère un rendu cartographique\ntmap_mode(\"view\") # En mode interactif\ntm_shape(contour_mada) +\n  tm_borders() +\n  tm_shape(AP_Vahatra) + \n  tm_polygons(col = \"cat_iucn\", alpha = 0.6, title = \"Catégorie IUCN\",\n              id = \"nom\",\n              popup.vars = c(\"Acte de création\" = \"creation\",\n                             \"Année de création\" = \"an_creation\",\n                             \"Surface (ha)\" = \"hectares\",\n                             \"Nom complet\" = \"full_name\",\n                             \"Gestionnaire\" = \"gest_1\")) +\n  tmap_options(check.and.fix = TRUE)\n\n\n\n\n\n\n\nOn peut également réaliser un graphique qui présente l’historique de création des aires protégées. Pour plus de précisions sur la manière de produire des graphiques en R, voir l’annexe correspondante (Chapter 11).\n\n\nCode\n# On ordonne les nom d'aires protégées dans l'ordre de leur séquence de création\nordre_chrono_AP <- AP_Vahatra %>%\n  arrange(desc(date_creation), desc(nom)) %>%\n  pull(nom)\n# On transforme le champ \"nom\" de caractère, à une catégorisation ordonnée où\n# l'ordre correspond \nAP_Vahatra_carte <- AP_Vahatra %>%\n  mutate(nom = factor(nom, levels = ordre_chrono_AP),\n         cat_taille = case_when(hectares > 300000 ~ 2,\n                                hectares > 150000 ~ 1.5,\n                                hectares >  50000 ~ 1,\n                                             TRUE ~ 0.5)) %>%\n  rename(`Catégorie IUCN` = cat_iucn)\n\n# On crée un graph pour les anciennetés\ngraph_gauche <- AP_Vahatra_carte %>%\n  ggplot(aes(x = date_creation, xend = ymd(\"2022-10-01\"), y = nom, yend = nom, \n                   color = `Catégorie IUCN`)) +\n  geom_segment(size = 2) +\n  ggtitle(\"Ancienneté\") +\n  theme(axis.ticks.y = element_blank(),\n        legend.position = \"none\",\n        axis.title = element_blank(),\n        axis.text.x.bottom =  element_text(angle = 45, hjust = 1),\n        axis.text.x.top = element_text(angle = -45, hjust = 1)) + \n  scale_x_date(sec.axis = dup_axis())\n\ngraph_droite <- AP_Vahatra_carte %>%\n  ggplot(aes(x = 0, xend = hectares/100, y = nom, yend = nom, \n                   color = `Catégorie IUCN`)) +\n  geom_segment(size = 2) + \n  ggtitle(\"Surface (km2)\") +\n  theme(axis.text.y = element_blank(),\n        axis.title = element_blank(),\n        axis.text.x.bottom =  element_text(angle = 45, hjust = 1),\n        axis.text.x.top = element_text(angle = -45, hjust = 0),\n        legend.position = \"none\") + \n  scale_x_continuous(sec.axis = dup_axis())\n\nlegende <- get_legend(graph_gauche  +\n                        guides(color = guide_legend(nrow = 1)) +\n                        theme(legend.position = \"bottom\"))\n\n# On colle les deux\ngraphs <- plot_grid(graph_gauche, graph_droite, rel_widths = c(2.2, 1),\n          nrow = 1)\nplot_grid(graphs, legende, ncol = 1,\n          rel_heights = c(1,.1))\n\n\n\n\n\nIl faut aussi s’assurer qu’on filtre bien les entités analysées selon un critère pertinent. Actuellement, on exclut les aires marines. Il pourrait toutefois sembler utile d’écarter les aires dont le statut de protection est considéré comme trop faible. Il pourrait aussi être pertinent de ne garder que les aires protégées comportant un niveau minimum de couvert forestier : autrement, cela signifie que la forêt n’est pas un habitat pertinent pour les écosystèmes que la démarche de conservation cherche à protéger dans cette aire."
  },
  {
    "objectID": "01-aires_protegees.html#world-database-on-protected-areas",
    "href": "01-aires_protegees.html#world-database-on-protected-areas",
    "title": "1  Aires protégées",
    "section": "1.2 World Database on Protected Areas",
    "text": "1.2 World Database on Protected Areas\nOn commence par télécharger et présenter ces données.\n\n\nCode\n# On regarde si les données WDPA sont disponibles sur l'ordinateur qui exécute\nif (file.exists(\"data/WDPA/WDPA_Oct2022_MDG-shapefile.zip\")) {\n  # Si oui, on charge\n  WDPA_Mada <- wdpa_read(\"data/WDPA/WDPA_Oct2022_MDG-shapefile.zip\")\n} else {\n  # Si non, on télécharge depuis protectedplanet\n  WDPA_Mada <- wdpa_fetch(\"Madagascar\", wait = TRUE,\n                      download_dir = \"data/WDPA\") \n}\n\ntm_shape(contour_mada) +\n  tm_borders() +\n  tm_shape(WDPA_Mada) + \n  tm_polygons(col = \"IUCN_CAT\", alpha = 0.6, title = \"Catégorie IUCN\",\n              id = \"NAME\",\n              popup.vars = c(\"Type\" = \"DESIG\",\n                             \"Catégorie UICN\" = \"IUCN_CAT\",\n                             \"Surface déclarée\" = \"REP_AREA\",\n                             \"Année du statut\" = \"STATUS_YR\")) +\n  tmap_options(check.and.fix = TRUE)\n\n\n\n\n\n\n\nEn observant les métadonnées associées aux aires protégées dans la carte interactive ci-dessus, on s’aperçoit que de nombreuses informations sont manquantes. On passe en revue la complétude des données issues de WDPA.\n\n\nCode\n# Résumé des valeurs manquantes\nWDPA_Mada %>%\n  st_drop_geometry() %>%\n  summarise(`Nombre total d'aires protégées` = n(),\n            `Catégorie IUCN manquante` = sum(IUCN_CAT == \"Not Reported\"),\n            `Année de création manquante` = sum(STATUS_YR == 0),\n            `Gestionnaire manquant` = sum(MANG_AUTH == \"Not Reported\")) %>%\n  pivot_longer(cols = everything(),\n               names_to = \" \",\n               values_to = \"Nombre d'aires\") %>%\n  gt() %>%\n  tab_header(\"Valeurs manquantes dans les données WDPA pour Madagascar\") %>%\n  tab_source_note(\"Source : WDPA (octobre 2022)\")\n\n\n\n\n\n\n  \n    \n      Valeurs manquantes dans les données WDPA pour Madagascar\n    \n    \n  \n  \n    \n       \n      Nombre d'aires\n    \n  \n  \n    Nombre total d'aires protégées\n171\n    Catégorie IUCN manquante\n90\n    Année de création manquante\n51\n    Gestionnaire manquant\n163\n  \n  \n    \n      Source : WDPA (octobre 2022)\n    \n  \n  \n\n\n\n\nOutre le problème des données manquantes, on remarque sur la carte interactive ci-dessus que plusieurs aires protégées de la base WDPA se superposent les unes aux autres. Afin de jauger l’empleur de ces superpositions, on calcule tout d’abord la somme des surfaces des aires protégéés enregistrées dans la base WDPA, puis on la compare à leur emprise totale, sans doublon.\n\n\nCode\n# On ne garde que les polygones (sans les points)\nWDPA_Mada_poly <- WDPA_Mada %>% \n  filter(st_geometry_type(.) == \"MULTIPOLYGON\")\n\n# On ne garde que les parties terrestres\nWDPA_Mada_poly_terrestre <- WDPA_Mada_poly %>%\n  st_intersection(contour_mada)\n\n# On calcule le total des surfaces de chaque aires\nsurface_cumul <- WDPA_Mada_poly_terrestre %>%\n  mutate(surface = st_area(.)) %>%\n  st_drop_geometry() %>% \n  summarise(surface = sum(surface, na.rm = TRUE)) %>%\n  mutate(`Type de cumul` = \"Somme des surfaces terrestres de chaque aire protégée\",\n         .before = everything())\n\nlibrary(units)\nsurface_tot <- WDPA_Mada_poly_terrestre %>%\n  st_union() %>%\n  st_as_sf() %>% \n  mutate(surface = st_area(.)) %>%\n  st_drop_geometry() %>% \n  summarise(surface = sum(surface, na.rm = TRUE)) %>%\n  mutate(`Type de cumul` = \"Emprise totale des aires protégées\",\n         .before = everything())\n\ncompare_surfaces <- surface_cumul %>%\n  bind_rows(surface_tot) %>%\n  mutate(surface = set_units(surface, \"hectares\"),\n         surface = as.numeric(surface)) %>%\n  rename(`Surface (ha)` = surface)\n\ncompare_surfaces %>%\n  gt() %>%\n  fmt_number(columns = `Surface (ha)`, use_seps = TRUE, decimals = 0) %>% \n  tab_header(title = \"Superposition des aires WDPA\",\n             subtitle = \"Somme des surfaces d'aires vs. emprise totale\") %>%\n  tab_source_note(\"Source : WDPA (oct. 2022), calculs des auteurs\")\n\n\n\n\n\n\n  \n    \n      Superposition des aires WDPA\n    \n    \n      Somme des surfaces d'aires vs. emprise totale\n    \n  \n  \n    \n      Type de cumul\n      Surface (ha)\n    \n  \n  \n    Somme des surfaces terrestres de chaque aire protégée\n10,697,746\n    Emprise totale des aires protégées\n8,830,866\n  \n  \n    \n      Source : WDPA (oct. 2022), calculs des auteurs\n    \n  \n  \n\n\n\n\nCela signifie qu’on a de nombreuses aires protégées dans la base WDPA qui se superposent et que leur emprise réelle est bien inférieure à la somme de leurs surfaces. Réaliser des sommes ou des moyennes simples sur l’ensemble de la base WDPA revient à compter plusieurs fois les mêmes zones géographiques."
  },
  {
    "objectID": "01-aires_protegees.html#comparaison-des-données-vahatra-et-wdpa",
    "href": "01-aires_protegees.html#comparaison-des-données-vahatra-et-wdpa",
    "title": "1  Aires protégées",
    "section": "1.3 Comparaison des données Vahatra et WDPA",
    "text": "1.3 Comparaison des données Vahatra et WDPA\nOn commence par visualiser les différences spatiales entre les polygones, en affichant les 10 qui sont les plus différents entre les WDPA et Vahatra.\n\n\nCode\n# On harmonise les noms qui sont parfois notés différemment entre les sources\nAP_Vahatra <- AP_Vahatra %>%\n  mutate(nom_wdpa = case_when(\n    nom == \"Corridor Forestier Bongolava\" ~ \"Corridor forestier Bongolava\",\n    nom == \"Ranobe PK32\" ~ \"Ranobe PK 32\",\n    str_detect(nom, \"Ambositra-Vondrozo\") ~ \"Corridor Forestier Ambositra Vondrozo\",\n    nom == \"Réserve deTampolo\" ~ \"Réserve de Tampolo\",\n    nom == \"Bombetoka Beloboka\" ~ \"Bombetoka Belemboka\",\n    nom == \"Ampananganandehibe-Behasina\" ~ \"Ampanganandehibe-Behasina\",\n    nom == \"Forêt Sacrée Alandraza Analavelo\" ~ \"Analavelona\", # vérfié sur carte : les mêmes\n    nom == \"Réserve speciale Pointe à Larrée\" ~ \"Réserve spéciale Pointe à Larrée\", \n    nom == \"Vohidava-Betsimalaho\" ~ \"Vohidava Betsimalao\", \n    nom == \"Anjanaharibe Sud\" ~ \"Anjanaharibe_sud\",\n    nom == \"Iles Radama/Sahamalaza\" ~ \"Sahamalaza Iles Radama\",\n    nom == \"Kalambatritra\" ~ \"Kalambatrika\",\n    nom == \"Mananara-Nord\" ~ \"Mananara Nord\",\n    nom == \"Kirindy - Mitea\" ~ \"Kirindy Mite\",\n    nom == \"Midongy du Sud\" ~ \"Befotaka Midongy\", # Vérifié sur la carte\n    nom == \"Montagne d'Ambre/Forêt d'Ambre\" ~ \"Montagne d'Ambre\",\n    nom == \"Tsimanampesotsa\" ~ \"Tsimanampesotse\",\n    nom == \"Pic d'Ivohibe\" ~ \"Ivohibe\",\n    nom == \"Forêt Naturelle de Petriky\" ~ \"Forêt Naturel de Petriky\",\n    nom == \"Tsingy de Namoroka\" ~ \"Namoroka\",\n    nom == \"Réserve de Ressources Naturelle Mahimborondro\" ~ \"Mahimborondro\",\n    str_detect(nom, \"Complexe Tsimembo Manambolomaty\") ~ \"Complexe Tsimembo Manambolomaty\",\n    nom == \"Mandrozo\" ~ \"Zone Humide de Mandrozo\",\n    nom == \"Paysage Harmonieux Protégés Bemanevika\" ~ \"Complexe des Zones Humides de Bemanevika\",\n    nom == \"Nord Ifotaky\" ~ \"INord fotaky\",\n    TRUE ~ nom)) %>%\n  arrange(nom_wdpa) %>%\n  mutate(rownum = row_number())\n\n# On sauvegarde le résultat\nsave(AP_Vahatra, file = \"data/ch1_AP_Vahatra.rds\")\n\n# On ne garde que les aires de WDPA qui apparaissent dans Vahatra\nWDPA_commun <- WDPA_Mada %>%\n  filter(NAME %in% AP_Vahatra$nom_wdpa) %>%\n  filter(!(NAME == \"Analalava\" & IUCN_CAT == \"Not Reported\")) %>%\n  filter(!(NAME == \"Site Bioculturel d'Antrema\" & IUCN_CAT == \"Not Reported\")) %>%\n  filter(DESIG != \"UNESCO-MAB Biosphere Reserve\") %>%\n  arrange(NAME)  %>%\n  mutate(rownum = row_number())\n       \n# Cette fonction calcule la part d'un polygone incluse dans un \n# autre polygone et retourne un ratio entre 0 et 1\nratio_inclus <- function(x, y) {\n  inclus <- st_intersection(x, y)\n  ratio <- st_area(inclus) / st_area(x)\n  return(ratio)\n}\n\n# On calcule la part des polygones Vahatra incluse dans les polgones WDPA \nV_in_W <- map2_dbl(WDPA_commun$geometry, AP_Vahatra$geometry, ratio_inclus)\n# Puis l'inverse\nW_in_V <- map2_dbl(AP_Vahatra$geometry, WDPA_commun$geometry, ratio_inclus)\n# On fait un facteur des deux\nrecoupement_mutuel <- V_in_W * W_in_V\n# Qu'on ramène dans les jeux de données d'origine\nWDPA_commun2 <- bind_cols(WDPA_commun, V_in_W = V_in_W, W_in_V = W_in_V,\n                         recoupement_mutuel = recoupement_mutuel) %>%\n  arrange(recoupement_mutuel, rownum)\nAP_Vahatra2 <- bind_cols(AP_Vahatra, V_in_W = V_in_W, W_in_V = W_in_V,\n                        recoupement_mutuel = recoupement_mutuel) %>%\n  arrange(recoupement_mutuel, rownum)\n\n# On prend maintenant les 5 les plus éloignés et on les visualise\nmin_recoup <- WDPA_commun2 %>%\n  filter(row_number() <= 10) %>%\n  select(nom_wdpa = NAME, rownum) %>%\n  mutate(source = \"WDPA\") %>%\n  bind_rows(select(filter(AP_Vahatra2, rownum %in% .$rownum), nom_wdpa, rownum)) %>%\n  mutate(source = ifelse(is.na(source), \"Vahatra\", source))\ntmap_mode(\"plot\")\nmin_recoup %>%\n  tm_shape() +\n  tm_polygons() +\n  tm_facets(by = c(\"nom_wdpa\", \"source\")) +\n  tm_layout(panel.label.size=3)\n\n\n\n\n\nOn peut également comparer ceux pour lesquels on a des différences de date ou de statut.\n\n\nCode\n# On garde seulement les métadonnées qu'on veut comparer\nWDPA_a_comparer <- WDPA_commun %>% # On repart des AP communes\n  st_drop_geometry() %>% # Plus besoin de spatial\n  select(nom_wdpa = NAME, type_wdpa = INT_CRIT, cat_iucn_wdpa = IUCN_CAT,\n         year_wdpa = STATUS_YR) # On ne garde que les colonnes à comparer\n\nverif_meta_wdpa <-AP_Vahatra %>%\n  st_drop_geometry() %>% # Pas besoin d'un jeu spatial\n  select(nom:date_modification, nom_wdpa) %>% # colonnes à garder dans Vahatra\n  # On renomme la catégorie IUCN de Vahatra et on code les NA comme dans WDPA\n  mutate(cat_iucn = ifelse(is.na(cat_iucn), \"Not Reported\", cat_iucn)) %>%\n  left_join(WDPA_a_comparer, by = \"nom_wdpa\") %>% # On rassemble Vahatra et WDPA\n  # On compare les dates et statuts\n  mutate(`Différence de date` = year(date_creation) != year_wdpa,\n         `Différence de statut` = cat_iucn != cat_iucn_wdpa)\n\nverif_meta_wdpa %>%\n  summarise(`Nombre d'aires protégées comparées` = n(),\n            `Différence de date` = sum(`Différence de date`),\n            `Différence de statut` = sum(`Différence de statut`)) %>%\n  gt() %>%\n  tab_header(title = paste(\"Différences entre les données de WDPA et celles de\",\n                     \"l'assciation Vahatra sur les aires protégées terrestres\",\n                     \"à Madagascar\"))\n\n\n\n\n\n\n  \n    \n      Différences entre les données de WDPA et celles de l'assciation Vahatra sur les aires protégées terrestres à Madagascar\n    \n    \n  \n  \n    \n      Nombre d'aires protégées comparées\n      Différence de date\n      Différence de statut\n    \n  \n  \n    98\n68\n40\n  \n  \n  \n\n\n\n\nDans les cas qu’on peut comparer, les données de l’association Vahatra semblent plus fiables. On va donc privilégier l’utilisation de ces dernières.\nOn va également visualiser les aires de WDPA qui ne sont pas contenues dans Vahatra.\n\n\nCode\nWDPA_exclu <- WDPA_Mada %>%\n  filter(!(NAME %in% AP_Vahatra$nom_wdpa))\n\ntmap_mode(\"view\")\nWDPA_exclu %>%\n  tm_shape() +\n  tm_polygons(col = \"IUCN_CAT\")\n\n\n\n\n\n\n\nCode\nratio_terrestre <- function(x) {\n  inclus <- st_intersection(x, contour_mada$geometry)\n  ratio <- st_area(inclus) / st_area(x)\n  return(ratio)\n}\n\n# On crée un grand polygone avec toutes les AP dans Vahatra\nAP_Vahatra_fusion <- st_union(AP_Vahatra)\n\n# On calcule pour les aires protégées de WDPA qui ne sont pas dans Vahatra\n# dans quelle mesure elles sont terrestres et pas superposées à d'autres AP\n# déjà dans Vahatra\nWDPA_exclu <- WDPA_exclu %>%\n  filter(st_geometry_type(.) == \"MULTIPOLYGON\") %>%\n  mutate(part_terrestre = map2_dbl(.$geometry, contour_mada$geometry, \n                                   ratio_inclus),\n         part_deja_autre = map2_dbl(.$geometry, AP_Vahatra_fusion, \n                                    ratio_inclus))\n\n# On garde celles qui sont au moins 25% terrestre et 75% pas superposées\nWDPA_a_inclure <- WDPA_exclu %>%\n  filter(part_terrestre >= 0.25 & part_deja_autre <= 0.25) %>%\n  mutate(full_name = paste(INT_CRIT, NAME)) %>%\n  select(nom = NAME, WDPAID, full_name, creation = STATUS_YR)\n\n\nOn a visiblement des aires protégées qu’il serait pertinent d’inclure et qui ne sont pas dans Vahatra."
  },
  {
    "objectID": "01-aires_protegees.html#enjeux-de-fiabilité-des-données-daires-protégées",
    "href": "01-aires_protegees.html#enjeux-de-fiabilité-des-données-daires-protégées",
    "title": "1  Aires protégées",
    "section": "1.4 Enjeux de fiabilité des données d’aires protégées",
    "text": "1.4 Enjeux de fiabilité des données d’aires protégées\nImportant pour l’analyse : si périmètres pas juste => phénomènes de leakage, faux positifs ou faux négatifs.\nEnjeu aussi des métadonnées : date ou type sont importants pour l’analyse et celle-ci perd en fiabilité si ces informations ne sont pas correctes.\n\n\n\n\nGoodman, Steven M., Marie Jeanne Raherilalao, Sébastien Wohlhauser, Jean Clarck N. Rabenandrasana, Herivololona M. Rakotondratsimba, Fanja Andriamialisoa, and Malalarisoa Razafimpahanana. 2018. Les Aires Protégées Terrestres de Madagascar: Leur Histoire, Description Et Biote. Association Vahatra."
  },
  {
    "objectID": "02-caracteristiques_AP.html",
    "href": "02-caracteristiques_AP.html",
    "title": "2  Caractéristiques spatiales",
    "section": "",
    "text": "Elle finit termine par enregistrer le jeu de données produit sur la machine qui exécute le code. Ce bloc ne s’exécute que si le jeu de données résultant n’est pas détecté sur la machine. Si le jeu de données résultant du script précédent est déjà disponible sur la machine, alors le bloc précédent ne s’exécute pas et celui qui s’exécute est le suivant\n\n\nCode\nlibrary(tidyverse)\nlibrary(mapme.biodiversity)\nlibrary(sf)\n\nif (file.exists(\"data/Vahatra_poly.rds\")) {\n  load(\"data/Vahatra_poly.rds\")\n} else {\n\n  Vahatra_poly <- AP_Vahatra %>%\n    filter(st_geometry_type(.) == \"MULTIPOLYGON\") %>%\n    st_cast(\"POLYGON\")\n  \n  # Constitution d'un portefeuille (voir la documentation)\n  Vahatra_poly <- init_portfolio(x = Vahatra_poly, \n                                 years = 2000:2020,\n                                 outdir = \"data/mapme_Vahatra\",\n                                 cores = 24,\n                                 add_resources = TRUE,\n                                 verbose = TRUE)\n  \n  # Données d'accessibilité de Nelson et al. (2018)\n  Vahatra_poly <-  get_resources(x = Vahatra_poly, resource = \"nelson_et_al\",  \n                                 range_traveltime = \"5k_110mio\")\n  # Modèle numérique de terrain SRTM de la NASA\n  Vahatra_poly <- get_resources(x = Vahatra_poly , resource = \"nasa_srtm\")\n  \n    # Indicateurs d'accessibilité\n  Vahatra_poly <- calc_indicators(x = Vahatra_poly,\n                                  \"traveltime\",  stats_accessibility = \"mean\",\n                                  engine = \"extract\")\n  # Indicateurs de relief de terrain\n  Vahatra_poly <- calc_indicators(x = Vahatra_poly,\n                                  indicators = c(\"tri\", \"elevation\"),\n                                  stats_tri = \"mean\", stats_elevation = \"mean\")\n  \n  #   # On récupère aussi les données de Global Forest Watch sur le couver forestier\n  # Vahatra_poly <- get_resources(x = Vahatra_poly, \n  #                               resources = c(\"gfw_treecover\", \"gfw_lossyear\"))\n  #   # Indicateurs de couvert forestier\n  # Vahatra_poly <- calc_indicators(x = Vahatra_poly,\n  #                                 indicators = \"treecover_area\", \n  #                                 min_cover = 30, min_size = 1)\n  \n  save(Vahatra_poly, file = \"data/Vahatra_poly.rds\")\n}\n\n\nMapme produit des colonnes imbriquées pour chaque observation, car dans bien des cas, on peut avoir plusieurs valeurs (par année) pour une même observation, voire plusieurs variables (par exemple, le calcul de l’indicateur traveltime produit des estimations de distance par rapport à une ville pour plusieurs tailles de ville possible. Lorsqu’on spécifie une taille, il produit deux variables : la distance estimée et la taille de la ville prise en compte pour l’estimation.\nCette imbrication n’est pas indispensable pour les trois variables calculées ici (indice de terrain accidenté, distance à une ville et altitude), car on ne cherche qu’une valeur par observation. On va donc dés-imbriquer les variables.\nOn va également procéder à une consolidation des données issues des traitements de {mapme.biodiversity}. Le jeu de données AP_Vahatra contenait 98 aires protégées, avec des géométries de types “multi-polygones”. Certaines de ces aires protégées étaient en effet composées de plusieurs polygones disjoints. Ces polygones disjoints ont été scindés pour être traités séparément dans le jeu de données AP_poly. Avant de repasser sur des analyses par aire protégée, on va agréger les statistiques d’AP_poly afin d’avoir pour chaque variable une valeur par aire protégée.\n\n\nCode\n# Valeur agrégées par AP (moyennes pondérées par la surface)\nVahatra_vars_terrain <- Vahatra_poly %>%\n  unnest(cols = c(tri, elevation, traveltime)) %>%\n  st_drop_geometry() %>%\n  select(nom, hectares, indice_accidente = tri_mean, dist_ville = minutes_mean, \n         altitude = elevation_mean) %>%\n  group_by(nom) %>%\n  summarise(indice_accidente = weighted.mean(indice_accidente, hectares,\n                                             na.rm = TRUE),\n            dist_ville = weighted.mean(dist_ville, hectares,\n                                       na.rm = TRUE),\n            altitude = weighted.mean(altitude, hectares,\n                                     na.rm = TRUE))\n# Valeurs qu'on insère dans le jeu de données de travail\nload(\"data/ch1_AP_Vahatra.rds\")\nAP_Vahatra <- AP_Vahatra %>%\n  left_join(Vahatra_vars_terrain, by = \"nom\")\n\nsave(AP_Vahatra, file = \"data/ch2_AP_Vahatra.rds\")\n\n\nOn doit aussi se rappeler que les aires protégées sont parfois composées de plusieurs polygones disjoints et que mapme.biodiversity a calculé chaque indicateur pour chaque polygone séparément. Pour chaque aire protégée, on va donc faire la moyenne de ces indicateurs, pondérée par la surface respective de chaque polygone.\nDonnées d’accessibilité : attention car elles présentent un possible biais d’endogénéité. La construction de route au cours des dernières décennies peut être lié à l’établissement ou non d’aires protégées. L’inclusion d’une variable de contrôle qui peut être en partie affectée par notre variable de traitement (la conservation) est susceptible de problème. Il existe une carte de 2000 qui pourrait être mobilisée :\nOn notera que plusieurs autres indicateurs peuvent être calculés à partir du pabkage mapme.biodiversity:\n\nactive_fire_counts: Calculate active fire counts based on NASA FIRMS polygonsactive_fire_properties: Calculate active fire properties based on NASA FIRMS polygons\nbiome: Calculate biomes statistics (TEOW) based on WWF\ndrought_indicator: Calculate drought indicator statistics\necoregion: Calculate terrestrial ecoregions statistics (TEOW) based on WWF\nlandcover: Calculate area of different landcover classes\nmangroves_area: Calculate mangrove extent based on Global Mangrove Watch (GMW)\npopulation_count: Calculate population count statistics (Worldpop)\nprecipitation_chirps: Calculate precipitation statistics based on CHIRPS\nprecipitation_wc: Calculate precipitation statistics\nsoilproperties: Calculate Zonal Soil Properties\ntemperature_max_wc: Calculate maximum temperature statistics\ntemperature_min_wc: Calculate minimum temperature statistics based on WorldClim\ntraveltime: Calculate accessibility statistics\ntreecover_area: Calculate treecover statistics\ntreecover_area_and_emissions: Calculate treeloss statistics\ntreecoverloss_emissions: Calculate emission statistics\ntri: Calculate Terrain Ruggedness Index (TRI) statistics"
  },
  {
    "objectID": "03-donnees_deforestation.html#carvalho-et-al.-source-modis",
    "href": "03-donnees_deforestation.html#carvalho-et-al.-source-modis",
    "title": "3  Couvert forestier",
    "section": "3.1 Carvalho et al. (source MODIS)",
    "text": "3.1 Carvalho et al. (source MODIS)\nPour commencer, on récupère le travail réalisé par Carvalho et al. (2020) qui complète les informations physiques de Goodman et al. (2018) avec des données relatives au couvert forestier en 1996, 2006 et 2016 et la diversité d’espèces présentes.\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(sf)\nlibrary(wdpar)\nlibrary(mapme.biodiversity)\n\n# Voir le chapitre \"Fondamentaux R\" pour une aide à l'import.\nsup2 <- read_xlsx(\"data/Carvalho2018sup2.xlsx\", # Enplacement du fichier\n                  skip = 8, # Premières lignes du tableau excel à ne pas lire\n                  n_max = 101,  # on ne lit pas les dernières lignes (notes)\n                  col_types = c(\"text\", \"text\", \"text\", \"text\", \n        \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \n        \"numeric\", \"numeric\", \"numeric\", \"numeric\"))\nsup4 <- read_xlsx(\"data/Carvalho2018sup4.xlsx\", skip = 6,\n                  col_types = c(\"text\", \"numeric\", \"text\", \"numeric\", \"numeric\", \n        \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\"))\n        \n\n# Carvalho et al. 2008 document in their supp. material 2: \"The three parcels that made up\n# Andohahela (Parcels I, II and III) comprised different types of dominant vegetation and\n# associated animal species, and were exposed to distinct pressures. Andohahela was analysed\n# in its entirety (site number 57), as well as separated\"\n\nsup2 <- sup2 %>% \n  mutate(PA = recode(PA, `Andohahela complete` = \"Andohahela\"),\n         num_atlas_ = as.integer(`Site number`))\n\nsup4 <- sup4 %>%\n  filter(`Habitat type` == \"TOTAL\") %>%\n  mutate(num_atlas_ = as.numeric(Parcel))\n\n\nload(\"data/ch2_AP_Vahatra.rds\")\n\nAP_Vahatra <- AP_Vahatra %>%\n  left_join(sup2, by = \"num_atlas_\") %>%\n  relocate(PA, .after = nom) %>%\n  left_join(sup4, by = \"num_atlas_\")\n\n\nOn complète cette information avec des données de couvert forestier."
  },
  {
    "objectID": "03-donnees_deforestation.html#mapme-exemple-gfc",
    "href": "03-donnees_deforestation.html#mapme-exemple-gfc",
    "title": "3  Couvert forestier",
    "section": "3.2 Mapme (exemple GFC)",
    "text": "3.2 Mapme (exemple GFC)\nLa procédure de traitement de ces fichiers sur Mapme est analogue à celle employée dans la section ?sec-caracteristiques.\n\n\nCode\n# On charge les polygones travaillés au chapitre 1\nWDPA_Mada <- wdpa_read(\"data/WDPA/WDPA_Oct2022_MDG-shapefile.zip\") \n\n# On charge aussi le contour de Madagascar\nload(\"data/contour_mada.rds\")\n\n# On charge les polygones travaillés au chapitre 1\nWDPA_poly  <- WDPA_Mada %>% # On enlève les AP pour lesquelles on n'a que des points\n  filter(st_geometry_type(.) == \"MULTIPOLYGON\") %>% \n  st_cast(\"POLYGON\")\n\nWDPA_poly <- init_portfolio(WDPA_poly,\n                           years = 2000:2020,\n                           outdir  = \"out\",\n                           cores = 18,\n                           add_resources = TRUE)\n\n\n# Get GFW data\nWDPA_poly  <- get_resources(x = WDPA_poly , \n                         resources = c(\"gfw_treecover\", \"gfw_lossyear\"))\n\n# Indicateurs de couvert forestier\nWDPA_poly  <- calc_indicators(x = WDPA_poly,\n                            indicators = \"treecover_area\", \n                            min_cover = 10, min_size = 1)\n\ndeforest_par_an <- WDPA_poly %>%\n  unnest(treecover_area) %>%\n  # filter(!is.na(years)) %>%\n  pivot_wider(names_from = \"years\", values_from = \"treecover\", \n              names_prefix = \"treecover_\") %>%\n  st_drop_geometry() %>%\n  select(-assetid) %>%\n  group_by(across(WDPAID:CONS_OBJ)) %>%\n  summarise(across(starts_with(\"treecover\"), sum, na.rm = TRUE))\n\n# Stats pour AP_Vahatra ------------------------------------\n\n# On charge les polygones travaillés au chapitre 2\nload(\"data/ch2_AP_Vahatra.rds\")\nAPV_poly  <-AP_Vahatra %>% # On enlève les AP pour lesquelles on n'a que des points\n  filter(st_geometry_type(.) == \"MULTIPOLYGON\") %>% \n  st_make_valid() %>% \n  st_cast(\"POLYGON\") %>% \n  st_make_valid()\n\nAPV_poly <- init_portfolio(APV_poly,\n                           years = 2000:2020,\n                           outdir  = \"out_Vahatra\",\n                           cores = 18,\n                           add_resources = TRUE)\n\n\n# Get GFW data\nAPV_poly  <- get_resources(x = APV_poly , \n                         resources = c(\"gfw_treecover\", \"gfw_lossyear\"))\n\n# Indicateurs de couvert forestier\nAPV_poly  <- calc_indicators(x = APV_poly,\n                            indicators = \"treecover_area\", \n                            min_cover = 10, min_size = 1)\n\nAPV_par_aire <- APV_poly %>%\n  unnest(treecover_area) %>%\n  # filter(!is.na(years)) %>%\n  pivot_wider(names_from = \"years\", values_from = \"treecover\", \n              names_prefix = \"treecover_\") %>%\n  st_drop_geometry() %>%\n  select(-assetid) %>%\n  group_by(across(!starts_with(\"treecover\"))) %>%\n  summarise(across(starts_with(\"treecover\"), sum, na.rm = TRUE))\n\n\n# Stats pour Mada --------------------------------------------------------\n\n# On charge les polygones travaillés au chapitre 1\nmada_poly  <- contour_mada %>% # On enlève les AP pour lesquelles on n'a que des points\n  filter(st_geometry_type(.) == \"MULTIPOLYGON\") %>% \n  st_cast(\"POLYGON\")\n\nmada_poly <- init_portfolio(mada_poly ,\n                           years = 2000:2020,\n                           outdir  = \"out_Mada\",\n                           cores = 18,\n                           add_resources = TRUE)\n\n\n# Get GFW data\nmada_poly  <- get_resources(x = mada_poly , \n                         resources = c(\"gfw_treecover\", \"gfw_lossyear\"))\n\n# Indicateurs de couvert forestier\nmada_poly  <- calc_indicators(x = mada_poly,\n                            indicators = \"treecover_area\", \n                            min_cover = 10, min_size = 1)\n\nmada_global <- mada_poly %>%\n  unnest(treecover_area) %>%\n  # filter(!is.na(years)) %>%\n  pivot_wider(names_from = \"years\", values_from = \"treecover\", \n              names_prefix = \"treecover_\") %>%\n  st_drop_geometry() %>%\n  select(-assetid) %>%\n  group_by(across(!starts_with(\"treecover\"))) %>%\n  summarise(across(starts_with(\"treecover\"), sum, na.rm = TRUE))\n\n\nlibrary(writexl)\nwrite_xlsx(list(WDPA = deforest_par_an,\n             Vahatra = APV_par_aire, \n             Madagascar = mada_global),\n        path = \"couvert_forestier_10_1.xlsx\")\n\n\nToutefois, en raison d’un problème liés à la gestion des calculs volumineux, les calculs pour certaines aires protégées renvoient des données aberrantes. Ce point sera mis à jour dans ce guide dès la résolution des erreurs rencontrées.\nA ce stade on se concentrera donc sur les données de TFM présentées plus bas."
  },
  {
    "objectID": "03-donnees_deforestation.html#google-earth-engine-exemple-gfc",
    "href": "03-donnees_deforestation.html#google-earth-engine-exemple-gfc",
    "title": "3  Couvert forestier",
    "section": "3.3 Google Earth Engine (exemple GFC)",
    "text": "3.3 Google Earth Engine (exemple GFC)\nLa plateforme Google Earth Engine est un outil particulièrement pratique et performant pour mobiliser et traiter des données satellitaires. Google Earth Engine peut être utilisé :\n\nen interrogeant son API, et notamment :\n\nen python, avec la librairie gee permet d’interroger l’API de Google Earth Engine.\nen R, au travers de la librairie rgee. Cette dernière est relativement facile d’usage, mais elle est difficile à configurer. Pour aller plus loin : https://r-earthengine.com/rgeebook/\n\ndirectement sur la plateforme https://code.earthengine.google.com/\n\nLa consolde de codage de Google Earth Engine prend la forme suivante :\n\n\n\nDiagramme des composants de la console Google Earth Engine\n\n\nLe langage utilisé sur cet interface est du Javascript. Ci-dessous un exemple de code qui génère les surface (en hectares) de perte de couvert forestier. Pour fonctionner, ce code doit être collé dans un script sur la plateforme Google Earth Engine lancé en cliquant sur “Run”, puis en cliquant sur “Tasks” pour exécuter le code.\n\n\nCode\n scale = 30\n    \n    // PREPARE DATA\n    //look at tree cover, find the area\n    var treeCover = gfc2021.select(['treecover2000']);\n    var areaCover = treeCover.multiply(ee.Image.pixelArea())\n                    .divide(10000).select([0],[\"areacover\"])\n    // total loss area\n    var loss = gfc2021.select(['loss']);\n    var areaLoss = loss.gt(0).multiply(ee.Image.pixelArea())\n                   .divide(10000).select([0],[\"arealoss\"]);\n    // total gain area\n    var gain = gfc2021.select(['gain'])\n    var areaGain = gain.gt(0).multiply(ee.Image.pixelArea())\n                   .divide(10000).select([0],[\"areagain\"]);\n    // final image\n    var total = gfc2021.addBands(areaCover)\n                .addBands(areaLoss)\n                .addBands(areaGain)\n\n    // TOTAL COVER\n    // Map cover area per feature\n    var districtSums = areaCover.reduceRegions({\n      collection: testgu,\n      reducer: ee.Reducer.sum(),\n      scale: scale,\n    });         \n    \n    var addVar = function(feature) {\n\n      // function to iterate over the sequence of years\n      var addVarYear = function(year, feat) {\n        // cast var\n        year = ee.Number(year).toInt()\n        feat = ee.Feature(feat)\n\n        // actual year to write as property\n        var actual_year = ee.Number(2000).add(year)\n\n        // filter year:\n        // 1st: get mask\n        var filtered = total.select(\"lossyear\").eq(year)\n        // 2nd: apply mask\n        filtered = total.updateMask(filtered)\n\n        // reduce variables over the feature\n        var reduc = filtered.reduceRegion({\n          geometry: feature.geometry(),\n          reducer: ee.Reducer.sum(),\n          scale: scale,\n          maxPixels: 1e9\n        })\n\n        // get results\n        var loss = ee.Number(reduc.get(\"arealoss\"))\n        var gain = ee.Number(reduc.get(\"areagain\"))\n\n        // set names\n        var nameloss = ee.String(\"loss_\").cat(actual_year)\n        var namegain = ee.String(\"gain_\").cat(actual_year)\n\n        // set properties to the feature\n        return feat.set(nameloss, loss, namegain, gain)\n      }\n\n      // iterate over the sequence\n      var newfeat = ee.Feature(years.iterate(addVarYear, feature));\n\n      // return feature with new properties\n      return newfeat\n    }\n\n    // Map over the FeatureCollection\n    var areas = districtSums.map(addVar);\n    \n    // Export PA deforestation to a CSV file.\n    Export.table.toDrive({\n      collection: areas,\n      description: 'forest_loss_WDPA_Madagascar',\n      fileFormat: 'CSV'\n    });"
  },
  {
    "objectID": "03-donnees_deforestation.html#python-exemple-tmf",
    "href": "03-donnees_deforestation.html#python-exemple-tmf",
    "title": "3  Couvert forestier",
    "section": "3.4 Python (exemple TMF)",
    "text": "3.4 Python (exemple TMF)\nFichiers préparés en python (code à venir), directement sur les rasters.\n\n\nCode\n# On charge les fichiers préparés par Marc en python (contient 2 feuilles)\ntableur_tmf <- \"data/TMFchangeYear_AP_Vahatra.xlsx\"\n# On commence par charger la feuille déforestation\ntmf_vahatra_defor <- read_excel(tableur_tmf,\n                              sheet = \"TMFdeforestationYear\") %>%\n  select(nom, starts_with(\"TMF\")) # on ne garde que les variables pertinentes\n# On fait ensuite de même avec la feuille dégradation\ntmf_vahatra_degrad <- read_excel(tableur_tmf,\n                              sheet = \"TMFdegradationYear\") %>%\n  select(nom, starts_with(\"TMF\")) # Onn ne garde que les feuilles pertinentes\n\nAP_Vahatra <- AP_Vahatra %>%\n  left_join(tmf_vahatra_degrad, by = \"nom\") %>%\n  left_join(tmf_vahatra_defor, by = \"nom\") \n\n\nTMF_ratios <- AP_Vahatra %>%\n  st_drop_geometry() %>%\n  select(nom, starts_with(\"Forest cover\"), starts_with(\"TMF\")) %>%\n  pivot_longer(cols = starts_with(\"TMF\"), \n               names_to = \"variable\", \n               values_to = \"surface_ha\") %>%\n  mutate(an_valeur = str_extract(variable, \"[:digit:]{4}\"),\n         an_valeur = as.numeric(an_valeur),\n         surface_ratio = case_when(\n           an_valeur < 2000 ~ surface_ha / `Forest cover (ha) in 2006`,\n           an_valeur > 2009 ~ surface_ha / `Forest cover (ha) in 2016`,\n           TRUE ~ surface_ha / `Forest cover (ha) in 2006`),\n         variable = str_replace(variable, \"HA\", \"ratio\")) %>%\n  select(nom, variable, surface_ratio) %>%\n  pivot_wider(names_from = variable, values_from = surface_ratio) %>%\n  select(nom, starts_with(\"TMF\"))\n\nAP_Vahatra <- AP_Vahatra %>%\n  left_join(TMF_ratios, by = \"nom\")\n\nsave(AP_Vahatra, file = \"data/ch3_AP_Vahatra.rds\")"
  },
  {
    "objectID": "03-donnees_deforestation.html#alternatives",
    "href": "03-donnees_deforestation.html#alternatives",
    "title": "3  Couvert forestier",
    "section": "3.5 Alternatives",
    "text": "3.5 Alternatives\nSi on n’est pas à l’aise avec les outils mentionnés plus haut, l’outil Geoquery d’AidData permet d’obtenir des statistiques par aire administrative. Il est également possible de formuler des demandes spécifiques pour d’autres polygones que des aires administratives au travers d’un formulaire dédié.\n\n\n\n\nCarvalho, Fabio, Kerry A. Brown, Adam D. Gordon, Gabriel U. Yesuf, Marie Jeanne Raherilalao, Achille P. Raselimanana, Voahangy Soarimalala, and Steven M. Goodman. 2020. “Methods for Prioritizing Protected Areas Using Individual and Aggregate Rankings.” Environmental Conservation 47 (2): 113–22. https://doi.org/10.1017/S0376892920000090.\n\n\nGoodman, Steven M., Marie Jeanne Raherilalao, Sébastien Wohlhauser, Jean Clarck N. Rabenandrasana, Herivololona M. Rakotondratsimba, Fanja Andriamialisoa, and Malalarisoa Razafimpahanana. 2018. Les Aires Protégées Terrestres de Madagascar: Leur Histoire, Description Et Biote. Association Vahatra."
  },
  {
    "objectID": "04-donnees_en_mailles.html#constitution-dun-maillage",
    "href": "04-donnees_en_mailles.html#constitution-dun-maillage",
    "title": "4  Données en mailles",
    "section": "4.1 Constitution d’un maillage",
    "text": "4.1 Constitution d’un maillage\nOn montre ci-dessous comment cette approche fonctionne. La première étape consiste à dessiner un carré autour des aires protégées malgaches, puis à subdiviser ce grand carré en un damier de formes hexagonales. Enfin, on ne garde que les hexagones qui se trouvent dans les frontières terrestres de Madagascar.\n\n\nCode\nlibrary(tidyverse)\nlibrary(tmap)\nlibrary(sf)\nlibrary(mapme.biodiversity)\nlibrary(tidygeocoder) # pour obtenir les coordo GPS d'un point à partir de son nom\nlibrary(maptiles) # Pour télécharger des fonds de carte\n\n\n# Surface des hexagones en km2\ntaille_hex <- 5\n\n# Ce qui suit jusqu'à la commande \"save\" ne s'execute que si le résultat n'a pas\n# déjà été généré lors d'une exécution précédente.\nif (file.exists(\"data/grille_mada_donnees_raster.rds\")) {\n  load(\"data/grille_mada_donnees_raster.rds\")\n} else {\n  \n  # Création d'un maillage du territoire émergé --------------------------------\n  \n  # On crée un cadre autour des aires protégées du pays\n  cadre_autour_mada = st_as_sf(st_as_sfc(st_bbox(aires_prot_mada)))\n  \n  # Cellules de 5km de rayon\n  surface_cellule <- taille_hex * (1e+6)\n  taille_cellule <- 2 * sqrt(surface_cellule / ((3 * sqrt(3) / 2))) * sqrt(3) / 2\n  grille_mada <- st_make_grid(x = cadre_autour_mada,\n                              cellsize = taille_cellule,\n                              square = FALSE)\n  # On découpe la grille pour ne garder que les terres émergées\n  cellules_emergees <- st_intersects(contour_mada, grille_mada) %>%\n    unlist()\n  grille_mada <- grille_mada[sort(cellules_emergees)] %>%\n    st_sf()\n} \n\n\nLe maillage produit est trop fin pour être visible à l’échelle du pays, mais on peut l’observer en zoomant sur une zone spécifique.\n\n\nCode\nsf_use_s2(TRUE) \n\n# On compte le nombre d'hexagones\nn_hex <- nrow(grille_mada)\n# Carte pour visualiser le résultat ------------------------------------------\n\n# A supprimer après validation, l'échappement ne fonctionne pas. \n# if (file.exists(\"data/carte_zoom.rds\")) {\n  # load(\"data/carte_zoom.rds\")\n  # load(\"data/elements_carte_zoom.rds\")\n# } else {\n\n## Carte de droite : zoom sur une zone spécifique-----------------------------\n# On part d'un dataframe contenant une adresse\nnom_centre_zoom <- \"Maroantsetra\"\nzoom_centre <- data.frame(address = nom_centre_zoom) %>%\n  geocode(address, method = \"osm\") %>% # on retrouve sa localisation xy\n  select(long, lat) %>% # on ne garde que le xy\n  as.numeric() %>% # qu'on passe en format numérique attendu par st_point\n  st_point() %>% # On le spécifie en point\n  st_sfc(crs = \"EPSG:4326\") \n\n# On crée une boîte de 100km \nzoom_boite <- zoom_centre %>% # On repart du centre\n  st_buffer(dist = 50000) %>% # On crée un cercle de 50km de rayon\n  st_make_grid(n = 1) \n\n# On filtre les alvéoles pour ne garder que celles qui sont dans le zoom\ngrille_zoom <- st_intersection(grille_mada, zoom_boite)\n\n# On télécharge un fond de carte pour la carte de droite\nfond_carte_zoom <- get_tiles(zoom_boite, provider = \"Stamen.Terrain\", \n                             zoom = 10, crop = TRUE) \n\nsave(n_hex, nom_centre_zoom, zoom_centre, zoom_boite, grille_zoom, \n     fond_carte_zoom, file = \"data/elements_carte_zoom.rds\")\n\n# On était restés en mode interactif, on repasse en mode statique pour les \n# cartes\ntmap_mode(\"plot\")\n\n# On génère la carte de droite\ncarte_zoom <- tm_shape(fond_carte_zoom) + \n  tm_rgb() +\n  tm_shape(grille_zoom) +\n  tm_borders() +\n  tm_shape(zoom_boite) + \n  tm_borders(col = \"red\") +\n  tm_layout(frame = FALSE,\n            main.title = paste(\"Zoom sur la zone de\", nom_centre_zoom),\n            main.title.size = 1) +\n  tm_credits(get_credit(\"Stamen.Toner\"),\n             bg.color = \"white\",\n             align = \"right\",\n             position = c(\"right\", \"BOTTOM\"))\nsave(carte_zoom, zoom_boite, file = \"data/carte_zoom.rds\")\n# }\n\n\n## Carte de gauche : simple à réaliser mais hexagones non visibles -------------\nload(\"data/contour_mada.rds\")\ncarte_grille <- tm_shape(contour_mada) +\n  tm_polygons(col = \"grey\") + \n  tm_shape(zoom_boite) +\n  tm_borders(col = \"red\") +\n  tm_layout(frame = FALSE) +\n  tm_layout(main.title = paste(\"Découpage en\", n_hex,\n                               \"hexagones de\", taille_hex, \"km2\"),\n            main.title.size = 1)\n\n# Assemblage des deux cartes ---------------------------------------------------\ntmap_arrange(carte_grille, carte_zoom, ncol = 2)"
  },
  {
    "objectID": "04-donnees_en_mailles.html#récupération-des-données-pour-le-maillage",
    "href": "04-donnees_en_mailles.html#récupération-des-données-pour-le-maillage",
    "title": "4  Données en mailles",
    "section": "4.2 Récupération des données pour le maillage",
    "text": "4.2 Récupération des données pour le maillage\nOn va ensuite utiliser le package mapme.biodiversity pour calculer, pour chaque hexagones, une série d’indicateurs : temps de parcours jusqu’à la ville (définie comme toute localité de 5000 habitants) la plus proche en 2015, teneur du sol en argile et couvert forestier par année).\n\n\nCode\nif (file.exists(\"data/grille_mada_donnees_raster.rds\")) {\n  load(\"data/grille_mada_donnees_raster.rds\")\n} else {\n  \n  # Traitement des données satellitaires avec {mapme.bidiversity}---------------\n  \n  # Constitution d'un portefeuille (voir la documentation)\n  grille_mada <- init_portfolio(x = grille_mada, \n                                years = 2000:2020,\n                                outdir = \"data_s3/mapme\",\n                                cores = 24,\n                                add_resources = TRUE,\n                                verbose = TRUE)\n  \n  # Acquisition des données satellitaires requises (rasters) ------------------- \n  # Données d'accessibilité de Nelson et al. (2018)\n  grille_mada <-  get_resources(x = grille_mada, resource = \"nelson_et_al\",  \n                                range_traveltime = \"5k_110mio\")\n  # Données de qualité des sols (uniquement teneur )\n  grille_mada <-  get_resources(x = grille_mada,\n                                resources = \"soilgrids\",  layers = \"clay\", \n                                depths = \"5-15cm\", stats = \"mean\")\n  # Données sur le couvert forestier de Global Forest Watch\n  grille_mada <- get_resources(x = grille_mada, \n                               resources = c(\"gfw_treecover\", \"gfw_lossyear\", \n                                             \"gfw_emissions\"))\n  # Modèle numérique de terrain SRTM de la NASA\n  grille_mada <- get_resources(x = grille_mada, resource = \"nasa_srtm\")\n  # Données de feux\n  grille_mada <- get_resources(x = grille_mada, resource = \"nasa_firms\",\n                               instrument = \"MODIS\")\n  \n  # Calcul des indicateurs -----------------------------------------------------\n  \n  # Indicateurs d'accessibilité\n  grille_mada <- calc_indicators(x = grille_mada,\n                                 \"traveltime\",  stats_accessibility = \"mean\",\n                                 engine = \"extract\")\n  # Indicateurs de sols\n  \n  grille_mada <- calc_indicators(x = grille_mada,\n                                 \"soilproperties\", stats_soil = \"mean\", \n                                 engine = \"extract\")\n \n   # Indicateurs de couvert forestier\n  grille_mada <- calc_indicators(x = grille_mada,\n                                 indicators = \"treecover_area_and_emissions\", \n                                 min_cover = 30, min_size = 1)\n  # Indicateurs de relief de terrain\n  grille_mada <- calc_indicators(x = grille_mada,\n                               indicators = c(\"tri\", \"elevation\"),\n                               stats_tri = \"mean\", stats_elevation = \"mean\")\n  # Indicateurs d'incendies\n  grille_mada <- calc_indicators(x = grille_mada,\n                                 \"active_fire_counts\")\n  grille_mada <- calc_indicators(x = grille_mada,\n                                 \"active_fire_properties\")\n  \n  # Sauvegarde du résultat\n  save(grille_mada, file = \"data_s3/grille_mada_donnees_raster.rds\")\n}\n\n# Assemblage des deux cartes ---------------------------------------------------\ntmap_arrange(carte_grille, carte_zoom, ncol = 2) \n\n\nOn peut représenter sous forme de cartes et d’histogrammes les différentes valeurs des indicateurs générés à partir des données satellitaires.\n\n\nCode\nif (file.exists(\"data/carte_mailles.rds\")) {\n  load(\"data/carte_mailles.rds\")\n} else {\n  grille_mada_summary <- grille_mada %>%\n    # On met à plat les données de distance\n    unnest(cols = c(traveltime, soilproperties, tri, elevation),\n           names_repair = \"universal\") %>%\n    select(-distance, -layer, -depth, -stat,  -active_fire_counts, \n           -active_fire_properties) %>%\n    rename(distance_minutes_5k_110mio = minutes_mean, mean_clay_5_15cm = mean) \n  \n  grille_mada_summary <- grille_mada_summary %>%\n    unnest(cols = treecover_area_and_emissions) %>%\n    pivot_wider(names_from = \"years\", values_from = c(\"treecover\", \"emissions\")) %>%\n    mutate(var_treecover = (treecover_2020 - treecover_2000)/treecover_2000,\n           sum_emissions = rowSums(across(starts_with(\"emission\")), na.rm = T)) %>%\n    rename(init_treecover_2000 = treecover_2000) %>% # pour le garder\n    select(-starts_with(\"treecover\"), -starts_with(\"emission\")) %>%\n    rename(treecover_2000 = init_treecover_2000) %>%\n    relocate(geometry, .after = last_col())\n  \n  carte_acces <- tm_shape(grille_mada_summary) +\n    tm_fill(\"distance_minutes_5k_110mio\",\n            title = \"Distance ville (>5K hab)\",\n            palette = \"Oranges\",\n            style = \"fisher\",\n            n = 8,\n            legend.hist = TRUE) +\n    tm_layout(legend.outside = TRUE,\n              # legend.title.size = 0.8,\n              # legend.text.size = 0.6,\n              legend.hist.width = 1,\n              legend.hist.height = 1)\n  \n  carte_sol <- tm_shape(grille_mada_summary) +\n    tm_fill(\"mean_clay_5_15cm\",\n            title = \"Sol argileux (5-15cm prof)\",\n            palette = \"YlOrBr\",\n            n = 8,\n            legend.hist = TRUE) +\n    tm_layout(legend.outside = TRUE,\n              # legend.title.size = 0.8,\n              # legend.text.size = 0.6\n              legend.hist.width = 1,\n              legend.hist.height = 1)\n  \n  carte_TRI <- tm_shape(grille_mada_summary) +\n    tm_fill(\"tri_mean\",\n            title = c(\"Terrain accidenté (TRI)\"),\n            palette = \"Blues\",\n            n = 8,\n            legend.hist = TRUE) +\n    tm_layout(legend.outside = TRUE,\n              # legend.title.size = 0.8,\n              # legend.text.size = 0.6,\n              legend.hist.width = 1,\n              legend.hist.height = 1)\n  \n  carte_alt <- tm_shape(grille_mada_summary) +\n    tm_fill(\"elevation_mean\",\n            title = \"Altitude\",\n            palette = \"Purples\",\n            n = 8,\n            legend.hist = TRUE) +\n    tm_layout(legend.outside = TRUE,\n              # legend.title.size = 0.8,\n              # legend.text.size = 0.6,\n              legend.hist.width = 1,\n              legend.hist.height = 1)\n  \n  carte_cover <- graph_alt <- tm_shape(grille_mada_summary) +\n    tm_fill(\"treecover_2000\",\n            title = \"Couvert arboré en 2000\",\n            palette = \"Greens\",\n            n = 8,\n            legend.hist = TRUE) +\n    tm_layout(legend.outside = TRUE,\n              # legend.title.size = 0.8,\n              # legend.text.size = 0.6,\n              legend.hist.width = 1,\n              legend.hist.height = 1)\n  \n  carte_loss <- graph_alt <- tm_shape(grille_mada_summary) +\n    tm_fill(\"var_treecover\",\n            title = \"Perte couvert (2000-2020)\",\n            palette = \"Reds\",\n            n = 8,\n            legend.hist = TRUE) +\n    tm_layout(legend.outside = TRUE,\n              # legend.title.size = 0.8,\n              # legend.text.size = 0.6,\n              legend.hist.width = 1,\n              legend.hist.height = 1)\n  \n  carte_mailles <- tmap_arrange(carte_acces, carte_sol, \n                                carte_alt, carte_TRI, \n                                carte_cover, carte_loss,\n                                ncol = 2, nrow = 3) %>%\n    tmap_save(\"data/carte_mailles.png\")\n}\n\ncarte_mailles\n\n\n\n\n\nLes cartes et histogrammes ci-dessus illustrent la distribution des variables spatiales calculées par hexagones."
  },
  {
    "objectID": "04-donnees_en_mailles.html#croisement-des-données-daires-protégées-et-satellitaires",
    "href": "04-donnees_en_mailles.html#croisement-des-données-daires-protégées-et-satellitaires",
    "title": "4  Données en mailles",
    "section": "4.3 Croisement des données d’aires protégées et satellitaires",
    "text": "4.3 Croisement des données d’aires protégées et satellitaires\nOn peut maintenant associer les données d’aires protégées aux hexagones afin de les croiser avec les indicateurs issus des données satellitaires déjà calculés pour ces hexagones.\n\n\nCode\nif (file.exists(\"data/grille_mada_AP.rds\")) {\n  load(\"data/grille_mada_AP.rds\")\n} else {\n  # On charge les données d'aires protégées élaborées au chapitre précédent\n  load(\"data/ch3_AP_Vahatra.rds\")\n  \n  # On prépare ces données pour les joindre avec celles en mailles\n  aires_prot_mada <- AP_Vahatra %>%\n    st_make_valid() %>% # Corrige les erreurs topo dans certains polygones\n    mutate(AP_ligne = row_number()) %>% # Intègre le numéro de ligne dans un champ\n    mutate(an_creation = year(date_creation)) # passe les dates en années\n  \n  # Le code suivant va asocier les hexagones aux aires protégées en se référant\n  # aux AP par leur rang dans la table des AP. On voudra plutôt leur identifiant, \n  # alors on crée une table d'équivalence rang/identifiant \n  aires_prot_mada_rang_id <- aires_prot_mada %>%\n    st_drop_geometry() %>% # Enlève l'information spatiale\n    select(AP_ligne, nom)\n  \n  \n  # On sélectionne des infos additionnelles qu'on va inclure dans les données\n  info_vahatra_a_inclure <- aires_prot_mada %>%\n    st_drop_geometry() %>% # Enlève l'information spatiale\n    select(AP_ligne, nom, an_creation, cat_iucn = cat__iucn, \n           gestionnaire = gest_2) # On ne garde que les variables d'intérêt\n  \n  # Pour chaque hexagone, on va maintenant identifier s'ils touchent (\"intersect\")\n  # ou s'ils sont strictiement inclus dans (\"within\") une aire protégé\n  grille_mada_AP <- grille_mada %>%\n    mutate(AP_ligne = st_intersects(., aires_prot_mada), # liste des n° de lignes d'AP qui recoupent\n           AP_ligne = map(AP_ligne, 1), # On extrait le 1° élément de la liste (toutes n'ont qu'1 élément)\n           AP_ligne = as.integer(as.character(AP_ligne))) %>%  # formattage en numérique\n    left_join(aires_prot_mada_rang_id, by = \"AP_ligne\") %>% # récupère l'id de l'AP\n    rename(AP_touche = nom) %>% # on renomme pour différentier\n    mutate(AP_ligne = st_within(., aires_prot_mada),\n           AP_ligne = map(AP_ligne, 1),\n           AP_ligne = as.integer(as.character(AP_ligne))) %>%\n    left_join(aires_prot_mada_rang_id, by = \"AP_ligne\") %>%\n    rename(AP_inclus = nom) %>%\n    select(-AP_ligne) \n  \n  grille_mada_AP <- grille_mada_AP %>%\n    st_sf() %>%\n    mutate(position_ap = ifelse(is.na(AP_touche), \"Extérieur\",\n                                ifelse(!is.na(AP_inclus), \"Intérieur\",\n                                       \"Frontière\")),\n           ref_AP = ifelse(position_ap == \"Intérieur\", AP_inclus, \n                           ifelse(position_ap == \"Frontière\", AP_touche, NA))) %>%\n    left_join(info_vahatra_a_inclure, by = c(\"ref_AP\" = \"nom\")) %>%\n    relocate(geometry, .after = last_col()) \n  \n  grille_mada_AP <- grille_mada_AP %>%\n    # On met à plat les données de distance\n    unnest(cols = c(traveltime, soilproperties, tri, elevation),\n           names_repair = \"universal\") %>%\n    select(-distance, -layer, -depth, -stat,  -active_fire_counts, \n           -active_fire_properties) %>%\n    rename(distance_minutes_5k_110mio = minutes_mean, mean_clay_5_15cm = mean)\n  save(grille_mada_AP, file = \"data/grille_mada_AP.rds\")\n}\n\n# Une vue après classification\ntm_shape(grille_mada_AP) +\n  tm_fill(col = \"position_ap\", title = \"par rapport aux aires protégées\") +\n  tm_layout(main.title = \"Localisation des hexagones\",\n            # NB : position en minuscules pour laisser un espace avec la marge\n            main.title.position = c(\"center\", \"top\"),\n            main.title.size = 1,\n            legend.position = c(\"left\", \"top\"),\n            legend.outside = FALSE)\n\n\n\n\n\nLa suite de l’analyse au chapitre Chapter 8"
  },
  {
    "objectID": "04b-recap_donnees_dispo.html#discussion-sur-la-construction-portée-et-limites-de-ces-données",
    "href": "04b-recap_donnees_dispo.html#discussion-sur-la-construction-portée-et-limites-de-ces-données",
    "title": "5  Récapitulatif et description des données disponibles",
    "section": "5.1 Discussion sur la construction, portée et limites de ces données",
    "text": "5.1 Discussion sur la construction, portée et limites de ces données\nCliquer sur ce lien pour la présentation générale des données mobilisées.\nUn point crucial à retenir est l’importance de toujours accompagner l’analyse d’une discussion critique des données mobilisées : quelles définitions sont utilisées pour établir les catégories que j’utilise (dans notre exemple, quelle définition de la forêt a été retenue) ? Y a-t-il des différences ou des nuances entre ce qui est mesuré et le phénomène que je veux analyser (dans notre exemple, la variation du couvert forestier n’est pas à proprement parler de la déforestation) ? Quels problèmes de qualité affectent mes données (dans notre exemple, les erreurs ou approximations qui affectent les données WDPA) ? etc."
  },
  {
    "objectID": "04b-recap_donnees_dispo.html#liste-des-variables",
    "href": "04b-recap_donnees_dispo.html#liste-des-variables",
    "title": "5  Récapitulatif et description des données disponibles",
    "section": "5.2 Liste des variables",
    "text": "5.2 Liste des variables\nOn réalise un résumé des données disponible. Les fonctions str() et summary() sont les plus couramment utilisées pour avoir une idée rapide du contenu des tables pendant qu’on étudie les données. Le package {} facilite l’élaboration d’une description rapide d’un jeu de données. C’est l’exemple qu’on prend ci-desous.\n\nTODO: le faire avec un package qui produit un joli rendu.\n\n\n\nCode\nload(\"data/ch3_AP_Vahatra.rds\")\nstr(AP_Vahatra)\n\n\nClasses 'sf' and 'data.frame':  98 obs. of  169 variables:\n $ nom                                               : chr  \"Agnakatrika\" \"Agnalazaha\" \"Ambatofotsy\" \"Ambatotsirongorongo\" ...\n $ PA                                                : chr  \"Ankarabolava\" \"Agnalazaha\" \"Ambatofotsy\" \"Ambatotsirongorongo\" ...\n $ cat__iucn                                         : chr  \"VI\" \"VI\" \"V\" \"V\" ...\n $ creation                                          : chr  \"Décret n°2015-794 du 28 avril 2015\" \"Décret n°2015-767 du 28 avril 2015\" \"Décret n°2015 -724 du 21 avril 2015\" \"Décret n°2015-792 du 28 avril 2015\" ...\n $ date_creation                                     : Date, format: \"2015-04-28\" \"2015-04-28\" ...\n $ date_modification                                 : Date, format: NA NA ...\n $ mention_changement                                : logi  FALSE FALSE FALSE FALSE TRUE FALSE ...\n $ hectares                                          : num  789 2745 1594 1030 78139 ...\n $ num_atlas_                                        : num  54 50 75 62 28 38 72 71 3 94 ...\n $ full_name                                         : chr  \"Réserve de Ressources Naturelles d'Agnakatrika\" \"Réserve de Ressources Naturelles d'Agnalazaha\" \"Paysage Harmonieux Protégé d'Ambatofotsy\" \"Réserve Spéciale d'Ambatotsirongorongo\\n\" ...\n $ province                                          : chr  \"Fianarantsoa\" \"Fianarantsoa\" \"Toamasina\" \"Toliary\" ...\n $ region                                            : chr  \"Atsimo Atsinanana\" \"Atsimo Atsinanana\" \"Alaotra Mangoro\" \"Anosy\" ...\n $ district                                          : chr  \"Vangaindrano\" \"Farafangana\" \"Anosibe an'Ala\" \"Taolagnaro (Fort Dauphin)\\n\" ...\n $ gest_1                                            : chr  \"Missouri Botanical Garden\" \"Missouri Botanical Garden\" \"Madagasikara Voakajy\" \"Ministère de l'Environnement, de l'Ecologie et des Forêts\\n\" ...\n $ gest_2                                            : chr  \"MBG\" \"MBG\" \"MV\" \"MEEF\\n\" ...\n $ type_ap                                           : chr  \"TERRESTRE\" \"TERRESTRE\" \"TERRESTRE\" \"TERRESTRE\\n\" ...\n $ nom_wdpa                                          : chr  \"Agnakatrika\" \"Agnalazaha\" \"Ambatofotsy\" \"Ambatotsirongorongo\" ...\n $ rownum                                            : int  1 2 3 4 5 6 7 8 9 10 ...\n $ indice_accidente                                  : num  5.88 1.77 16.72 26.56 15.02 ...\n $ dist_ville                                        : num  70.2 84.9 143.4 69.8 990.3 ...\n $ altitude                                          : num  74.31 9.76 857.63 349.3 755.48 ...\n $ Site number                                       : chr  \"54\" \"50\" \"75\" \"62\" ...\n $ Corridor                                          : chr  \"Eastern\" \"Eastern\" \"Eastern\" \"Eastern\" ...\n $ Type of vegetation                                : chr  \"Evergreen moist forest\" \"Littoral forest\" \"Evergreen moist forest\" \"Evergreen moist forest\" ...\n $ SoK                                               : num  8 13.5 5 42 30.5 1 42 95 57 67 ...\n $ Forest loss                                       : num  13 82 37 7 39 63 17 46.5 74 10 ...\n $ Forest loss acceleration                          : num  34.5 50 25 96 84 42 8 83 72 20 ...\n $ PA size                                           : num  12 25 14 4 82 18 45 20 32 78 ...\n $ Absolute species diversity                        : num  12.5 32.5 3 34 73 1 19 61.5 51 61.5 ...\n $ Relative species diversity                        : num  36.5 69 42 21 99 59 4 8 16 45 ...\n $ Unweighted                                        : num  4 12 9 22 34 1 18 66 49 42 ...\n $ PCA                                               : num  4 13 10 23 35 1 19 66 49 42 ...\n $ MC                                                : num  3 42 13 7 94 25 5 43 53 31 ...\n $ PageRank                                          : num  4.5 40.5 8 14.5 96.5 24 6 51 53 37 ...\n $ Name                                              : chr  \"Agnakatrika\" \"Agnalazaha\" \"Ambatofotsy\" \"Ambatotsirongorongo\" ...\n $ Parcel                                            : num  54 50 75 62 28 38 72 71 3 94 ...\n $ Habitat type                                      : chr  \"TOTAL\" \"TOTAL\" \"TOTAL\" \"TOTAL\" ...\n $ Forest cover (ha) in 1996                         : num  466 1412 690 269 67454 ...\n $ Forest cover (ha) in 2006                         : num  420 1410 665 173 62209 ...\n $ Forest cover (ha) in 2016                         : num  383 1403 619 173 60734 ...\n $ Forest loss (ha) between 1996-2006 (absolute loss): num  45.18 1.89 25.11 96.03 5244.84 ...\n $ Forest loss (ha) between 2006-2016 (absolute loss): num  37.53 7.38 45.81 0 1474.56 ...\n $ Forest loss (ha) between 1996-2006 (percent loss) : num  9.702 0.134 3.638 35.721 7.775 ...\n $ Forest loss (ha) between 2006-2016 (percent loss) : num  8.926 0.523 6.888 0 2.37 ...\n $ TMFdeg_HA_1990                                    : num  0 0.27 0 0.27 13.77 ...\n $ TMFdeg_HA_1991                                    : num  0.09 2.25 0 0.18 39.96 ...\n $ TMFdeg_HA_1992                                    : num  0.18 0.09 0 0.45 0 ...\n $ TMFdeg_HA_1993                                    : num  0.72 14.13 0 6.12 100.89 ...\n $ TMFdeg_HA_1994                                    : num  0.09 1.08 0 3.42 127.08 ...\n $ TMFdeg_HA_1995                                    : num  0.36 4.68 0 25.29 184.59 ...\n $ TMFdeg_HA_1996                                    : num  5.4 137.6 0 24.2 649.8 ...\n $ TMFdeg_HA_1997                                    : num  6.66 65.88 0 15.21 399.96 ...\n $ TMFdeg_HA_1998                                    : num  4.5 43.2 0 43 1572.9 ...\n $ TMFdeg_HA_1999                                    : num  7.65 30.87 0 3.15 265.32 ...\n $ TMFdeg_HA_2000                                    : num  4.68 107.1 0 16.83 1353.78 ...\n $ TMFdeg_HA_2001                                    : num  4.23 0.54 0 8.28 458.01 ...\n $ TMFdeg_HA_2002                                    : num  4.77 9.36 0 10.89 117.36 ...\n $ TMFdeg_HA_2003                                    : num  1.26 16.56 0 6.93 51.12 ...\n $ TMFdeg_HA_2004                                    : num  1.71 1.89 0 5.22 56.25 ...\n $ TMFdeg_HA_2005                                    : num  4.86 5.58 0 18.27 156.33 ...\n $ TMFdeg_HA_2006                                    : num  3.69 9.54 0 3.69 385.56 ...\n $ TMFdeg_HA_2007                                    : num  8.46 14.85 0 6.12 241.83 ...\n $ TMFdeg_HA_2008                                    : num  7.47 1.8 0 7.92 187.65 ...\n $ TMFdeg_HA_2009                                    : num  3.51 0.72 0 1.71 609.03 ...\n $ TMFdeg_HA_2010                                    : num  5.04 2.25 0 0.45 242.01 ...\n $ TMFdeg_HA_2011                                    : num  1.62 2.16 0 1.08 1002.96 ...\n $ TMFdeg_HA_2012                                    : num  14.58 1.62 0 1.26 514.26 ...\n $ TMFdeg_HA_2013                                    : num  18.36 7.11 0 0.63 621.36 ...\n $ TMFdeg_HA_2014                                    : num  0.54 5.58 0 0.54 863.64 ...\n $ TMFdeg_HA_2015                                    : num  3.33 3.78 0 3.6 426.6 ...\n $ TMFdeg_HA_2016                                    : num  6.3 13.7 0 1.8 583.6 ...\n $ TMFdeg_HA_2017                                    : num  21.24 69.21 0 2.61 811.98 ...\n $ TMFdeg_HA_2018                                    : num  2.16 1.89 0 1.89 2026.71 ...\n $ TMFdeg_HA_2019                                    : num  2.34 2.97 0 1.71 170.91 ...\n $ TMFdeg_HA_2020                                    : num  8.64 44.46 0 7.29 74.25 ...\n $ TMFly_HA_1990                                     : num  0 0.09 0 0 0.09 ...\n $ TMFly_HA_1991                                     : num  0 0 0 0 0.09 ...\n $ TMFly_HA_1992                                     : num  0 0 0 0.09 0 0 3.06 0 0 0.36 ...\n $ TMFly_HA_1993                                     : num  0 0 0 0.36 0.18 0.18 7.38 0 0 0.27 ...\n $ TMFly_HA_1994                                     : num  0 0.45 0 5.13 0.54 ...\n $ TMFly_HA_1995                                     : num  0.09 6.3 0 14.58 0.72 ...\n $ TMFly_HA_1996                                     : num  5.94 40.5 0 6.48 9.36 ...\n $ TMFly_HA_1997                                     : num  4.95 12.78 0 12.24 9.99 ...\n $ TMFly_HA_1998                                     : num  3.06 11.97 0 11.16 32.67 ...\n $ TMFly_HA_1999                                     : num  5.67 31.32 0 10.62 4.32 ...\n $ TMFly_HA_2000                                     : num  2.16 22.23 0 26.82 31.95 ...\n $ TMFly_HA_2001                                     : num  2.52 2.25 0 14.67 21.33 ...\n $ TMFly_HA_2002                                     : num  3.51 9.27 0 11.16 6.66 ...\n $ TMFly_HA_2003                                     : num  2.97 37.17 0 15.48 18.27 ...\n $ TMFly_HA_2004                                     : num  2.61 2.25 0 8.19 17.55 ...\n $ TMFly_HA_2005                                     : num  6.66 6.93 0 13.05 29.97 ...\n $ TMFly_HA_2006                                     : num  3.78 8.64 0 3.33 65.79 ...\n $ TMFly_HA_2007                                     : num  8.19 4.5 0 5.4 38.88 ...\n $ TMFly_HA_2008                                     : num  9.9 3.87 0 6.66 76.68 ...\n $ TMFly_HA_2009                                     : num  4.5 0.72 0 2.61 137.79 ...\n $ TMFly_HA_2010                                     : num  6.21 7.65 0 2.07 39.69 ...\n $ TMFly_HA_2011                                     : num  4.05 4.05 0 8.91 207.99 ...\n $ TMFly_HA_2012                                     : num  16.56 1.62 0 5.31 85.86 ...\n $ TMFly_HA_2013                                     : num  11.61 10.8 0 6.84 104.4 ...\n  [list output truncated]\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:168] \"nom\" \"PA\" \"cat__iucn\" \"creation\" ...\n\n\n\n5.2.1 Exercices\nProduire le même tableau de résumé pour les autres tables :"
  },
  {
    "objectID": "04b-recap_donnees_dispo.html#autres-sources-dinformation",
    "href": "04b-recap_donnees_dispo.html#autres-sources-dinformation",
    "title": "5  Récapitulatif et description des données disponibles",
    "section": "5.3 Autres sources d’information",
    "text": "5.3 Autres sources d’information\n\nDHS et MICS : principales enquêtes socio-sanitaires\nIHSN : la plupart des enquêtes nationales\nWorld Bank Microdata catalog : microdonnées de nombreuses autres enquêtes (notamment des grosses enquêtes sur l’eau par la Banque mondiale)\nWAPOR : données satellitaires préprocessées de productivité : rapport biomass water productivity, évapotranspiration, précipitations… (cliquez sur l’onglet « layers » en bas à gauche de l’écran pour voir la liste des donnés disponibles)\n\nIl y a encore plein d’autres choses sur l’accès à l’eau dans les établissements de santé ou les écoles, ou encore le satellitaire, mais c’est plus diffus et je ne veux pas vous noyer. On prépare un outil en ligne avec la KfW qui permettra aux REP et partenaires de mieux s’y retrouver."
  },
  {
    "objectID": "05-assignation_aleatoire.html",
    "href": "05-assignation_aleatoire.html",
    "title": "6  Méthode randomisée",
    "section": "",
    "text": "ATTENTION : Il va de soi que les AP malgaches n’ont à aucun moment été assignées aléatoirement. Lors de cette séquence, on fait “comme si”, pour montrer la manière dont les données sont analysées quand il y a eu assignation aléatoire. On verra en fin de session les limites d’une telle approche et dans les suivantes des manières de construire des contrefactuels plus vraisemblables pour un sujet comme celui-ci.\n\nL’analyse est effectuée partir des données préparées dans le Chapitre 3. On commence par vérifier s’il existe des déséquilibres flagrants entre les aires qui ont été protégées avant 2015 et celles qui ont été protégées en 2015, en matière de surface totale ou de part couverte par des forêts en 1996.\n\n\nCode\n# On charge les librairies utiles pour cette analyse\nlibrary(tidyverse) # Facilite la manipulation de données\nlibrary(gt) # Aide à formater de jolis tableaux de rendu\nlibrary(broom) # Aide à formater les rendus de régressions\nlibrary(stargazer) # idem\nlibrary(sf) # Pour les données spatiales\nlibrary(lubridate) # Pour gérer des dates\n\n# Désactiver les notations scientifiques\noptions(scipen =999)\n\nload(\"data/ch3_AP_Vahatra.rds\")\n\nrct_AP_Mada <- AP_Vahatra %>%\n  st_drop_geometry() %>%\n  rename(`Déforestation 1996-2006 (%)` = \n           `Forest loss (ha) between 1996-2006 (percent loss)`,\n         `Déforestation 2006-2016 (%)` = \n           `Forest loss (ha) between 2006-2016 (percent loss)`,\n         `Surface (ha)` = hectares) %>%\n  mutate(Groupe = ifelse(year(date_creation) < 2015, \"Traitement\", \"Controle\"),\n         `Couvert forestier en 1996 (%)` = `Forest cover (ha) in 1996` / \n                                              `Surface (ha)` * 100,\n         `Déforestation 1996-2016 (%)` = \n           (`Forest loss (ha) between 1996-2006 (absolute loss)` + \n             `Forest loss (ha) between 2006-2016 (absolute loss)`) /\n           `Forest cover (ha) in 1996` * 100)\n\n# On fait une série de tests de comparaison de moyenne\nt_tests <- rct_AP_Mada %>% \n  # On applique aux variables de déforestation, couvert en 96 et taille\n  summarise(across(ends_with(\"(%)\") | ends_with(\"(ha)\"),# toutes finissent ainsi\n                   ~ t.test(.[Groupe == \"Controle\"], # on applique un t.test\n                            .[Groupe == \"Traitement\"])$p.value)) %>%\n  mutate(Groupe = \"t-test\")\n\nequilibre_avant <- rct_AP_Mada %>%\n  group_by(Groupe) %>%\n  summarise(`Nombre d'aires` = n(),\n            `Sans forêt` = sum(is.na(`Couvert forestier en 1996 (%)`)), \n            `Surface (ha)` = mean(`Surface (ha)`),\n            `Couvert forestier en 1996 (%)` = \n              mean(`Couvert forestier en 1996 (%)`, na.rm = TRUE)) %>%\n  bind_rows(t_tests) %>% # On colle tous les t-tests \n  mutate(across(!Groupe, ~round(., 2))) %>%# arrondit tout sauf colonne \"Groupe\"\n  select(-starts_with(\"Déforestation\"))# On ne garde que les t-tests de baseline\n\n# Ce qui suit est une série d'opération pour formater le rendu en tableau\nequilibre_avant %>%\n  t() %>% # On transpose lignes <=> colonnes\n  as.data.frame() %>% # La transposition a altéré le format, on remet en tableau\n  tibble::rownames_to_column() %>% # On met le nom des lignes en 1° colonne\n  # \"Truc pour renommer avec le contenu de la première ligne\n  `colnames<-` (filter(., row_number() == 1)) %>% \n  filter(row_number() != 1)%>% # Enlève la 1° ligne qui est maintenant en entête\n  gt() %>%\n  tab_header(title = \"Equilibre des variables avant intervention\",\n             subtitle = \"(exercice : \\\"comme si\\\" c'était une RCT)\") %>%\n  tab_source_note(\"Source : Association Vahatra et Carvalho et al. 2018\")\n\n\n\n\n\n\n  \n    \n      Equilibre des variables avant intervention\n    \n    \n      (exercice : \"comme si\" c'était une RCT)\n    \n  \n  \n    \n      Groupe\n      Controle\n      Traitement\n      t-test\n    \n  \n  \n    Nombre d'aires\n53\n45\nNA\n    Sans forêt\n 4\n 0\nNA\n    Surface (ha)\n66308.62\n63513.89\n    0.88\n    Couvert forestier en 1996 (%)\n54.31\n62.24\n 0.14\n  \n  \n    \n      Source : Association Vahatra et Carvalho et al. 2018\n    \n  \n  \n\n\n\n\nOn a à première vue des déséquilibres limités “avant intervention”. En moyenne, les deux groupes sont assez proches en termes de surface et de couvert forestier et le test de Student ne permet pas de rejeter l’hypothèse nulle concernant une différence de moyenne sur ces critères.\nOn va maintenant s’intéresser aux différences de déforestation observées “après intervention” dans le groupe de traitement.\n\n\nCode\ncomparaison_apres <- rct_AP_Mada %>%\n  group_by(Groupe) %>%\n  summarise(across(starts_with(\"Déforestation\"), ~ mean(., na.rm = TRUE))) %>%\n  bind_rows(t_tests) %>% # On colle tous les t-tests \n  mutate(across(!Groupe, ~round(., 2))) %>%# arrondit tout sauf colonne \"Groupe\"\n  select(Groupe, starts_with(\"Déforestation\"))# On ne garde que les t-tests de baseline\n\n\n# Même procédure que plus haut pour formater le rendu en tableau\ncomparaison_apres  %>%\n  t() %>% # On transpose lignes <=> colonnes\n  as.data.frame() %>% # La transposition a altéré le format, on remet en tableau\n  tibble::rownames_to_column() %>% # On met le nom des lignes en 1° colonne\n  # \"Truc pour renommer avec le contenu de la première ligne\n  `colnames<-` (filter(., row_number() == 1)) %>% \n  filter(row_number() != 1)%>% # Enlève la 1° ligne qui est maintenant en entête\n  gt() %>%\n  tab_header(title = \"Moyennes après intervention\",\n             subtitle = \"(exercice : \\\"comme si\\\" c'était une RCT)\") %>%\n  tab_source_note(\"Source : Association Vahatra et Carvalho et al. 2018\")\n\n\n\n\n\n\n  \n    \n      Moyennes après intervention\n    \n    \n      (exercice : \"comme si\" c'était une RCT)\n    \n  \n  \n    \n      Groupe\n      Controle\n      Traitement\n      t-test\n    \n  \n  \n    Déforestation 1996-2006 (%)\n8.21\n4.12\n0.07\n    Déforestation 2006-2016 (%)\n8.50\n3.91\n0.01\n    Déforestation 1996-2016 (%)\n15.90\n 7.87\n 0.00\n  \n  \n    \n      Source : Association Vahatra et Carvalho et al. 2018\n    \n  \n  \n\n\n\n\nOn peut également réaliser une régression simple, qu’on présente selon le format courant pour la littérature en économie grâce au package {stargazer} (Hlavac 2022).\n\n\nCode\ndef_96_06 <- lm(`Déforestation 1996-2006 (%)`  ~ Groupe, data = rct_AP_Mada)\ndef_06_16 <- lm(`Déforestation 2006-2016 (%)`  ~ Groupe, data = rct_AP_Mada)\ndef_96_16 <- lm(`Déforestation 1996-2016 (%)`  ~ Groupe, data = rct_AP_Mada)\n\n# tidy(def_96_06) %>%\n#   gt() %>%\n#   tab_header(title = \"Déforestation 1996-2006 (%)\",\n#              subtitle = \"(exercice : \\\"comme si\\\" c'était une RCT)\") %>%\n#   tab_source_note(\"Source : Association Vahatra et Carvalho et al. 2018\")\n# \n# tidy(def_06_16) %>%\n#   gt() %>%\n#   tab_header(title = \"Déforestation 2006-2016 (%)\",\n#              subtitle = \"(exercice : \\\"comme si\\\" c'était une RCT)\") %>%\n#   tab_source_note(\"Source : Association Vahatra et Carvalho et al. 2018\")\n# \n# tidy(def_96_16) %>%\n#   gt() %>%\n#   tab_header(title = \"Déforestation 1996-2016 (%)\",\n#              subtitle = \"(exercice : \\\"comme si\\\" c'était une RCT)\") %>%\n#   tab_source_note(\"Source : Association Vahatra et Carvalho et al. 2018\")\n\nstargazer(def_96_06, def_06_16, def_96_16, type = \"text\",\n          title = \"Impact de la conservation sur la perte de couvert forestier\",\n          notes = \"Données : Association Vahatra et Carvalho et al. 2018\")\n\n\n\nImpact de la conservation sur la perte de couvert forestier\n=======================================================================================================================\n                                                                 Dependent variable:                                   \n                              -----------------------------------------------------------------------------------------\n                              `Déforestation 1996-2006 (%)` `Déforestation 2006-2016 (%)` `Déforestation 1996-2016 (%)`\n                                           (1)                           (2)                           (3)             \n-----------------------------------------------------------------------------------------------------------------------\nGroupeTraitement                         -4.092*                      -4.593***                     -8.031***          \n                                         (2.308)                       (1.745)                       (2.831)           \n                                                                                                                       \nConstant                                8.214***                      8.499***                      15.902***          \n                                         (1.597)                       (1.208)                       (1.959)           \n                                                                                                                       \n-----------------------------------------------------------------------------------------------------------------------\nObservations                               94                            94                            94              \nR2                                        0.033                         0.070                         0.080            \nAdjusted R2                               0.023                         0.060                         0.070            \nResidual Std. Error (df = 92)            11.179                         8.454                        13.713            \nF Statistic (df = 1; 92)                 3.143*                       6.924***                      8.046***           \n=======================================================================================================================\nNote:                                                                                       *p<0.1; **p<0.05; ***p<0.01\n                                                                  Données : Association Vahatra et Carvalho et al. 2018\n\n\nOn analyse ensuite la relation aux variables topologiques (altitude, indice de terrain accidenté) et de temps de trajet à la ville la plus proche en 2015. Le seuil retenu ici pour considérer une localité comme une ville est qu’elle ait au moins 5000 habitants.\n\n\nCode\nt_tests_autres <- rct_AP_Mada %>% \n  # On applique aux variables d'altitude, TRI et temps de trajet aux villes.\n  summarise(across(indice_accidente:altitude,# toutes finissent ainsi\n                   ~ t.test(.[Groupe == \"Controle\"], # on applique un t.test\n                            .[Groupe == \"Traitement\"])$p.value)) %>% \n  mutate(Groupe = \"t-test\")\n\n\nequilibre_autres <- rct_AP_Mada %>%\n  group_by(Groupe) %>%\n  summarise(`Nombre d'aires` = n(),\n            indice_accidente = mean(indice_accidente, na.rm = TRUE), \n            dist_ville = mean(dist_ville, na.rm = TRUE),\n            altitude = mean(altitude, na.rm = TRUE)) %>%\n  bind_rows(t_tests_autres) %>% # On colle tous les t-tests \n  mutate(across(!Groupe, ~round(., 2))) %>%# arrondit tout sauf colonne \"Groupe\"\n  select(-starts_with(\"Déforestation\"))# On ne garde que les t-tests de baseline\n\nequilibre_autres %>%\n  gt() %>%\n  tab_header(title = \"Equilibre entre les groupes en matière topologique\",\n             subtitle = \"(exercice : \\\"comme si\\\" c'était une RCT)\") %>%\n  tab_source_note(\"Source : Association Vahatra et Carvalho et al. 2018\")\n\n\n\n\n\n\n  \n    \n      Equilibre entre les groupes en matière topologique\n    \n    \n      (exercice : \"comme si\" c'était une RCT)\n    \n  \n  \n    \n      Groupe\n      Nombre d'aires\n      indice_accidente\n      dist_ville\n      altitude\n    \n  \n  \n    Controle\n53\n11.02\n148.77\n540.45\n    Traitement\n45\n12.08\n233.31\n538.63\n    t-test\nNA\n0.53\n0.03\n0.99\n  \n  \n    \n      Source : Association Vahatra et Carvalho et al. 2018\n    \n  \n  \n\n\n\n\nCode\nsave(rct_AP_Mada, file = \"data/rct_AP_Mada.rds\")\n\n\nLe temps de trajet aux villes est significativement distinct entre les deux groupes. Attention, car cette variable pose un problème d’endogénéité, car le jeu de données utilisé pour cela date de 2015, alors que notre période d’étude démarre en 1996. Or, il est possible que la présence d’aires protégées ait eu une incidence sur la construction ou l’amélioration des tronçons routiers à proximité (discussion en séance sur ce point). Il semble important de tenir compte de l’accessibilité géographiques des aires protégées, mais une donnée antérieure à 2015 serait préférable.\nOn essaye de limiter ce biais en ajoutant le temps de trajet à une ville comme variables de contrôle à notre régression.\n\n\nCode\ndef_96_16_controle <- lm(`Déforestation 1996-2016 (%)` ~ \n                           Groupe + dist_ville, \n                         data = rct_AP_Mada)\n\nstargazer(def_96_16, def_96_16_controle, type = \"text\")\n\n\n\n===============================================================\n                                Dependent variable:            \n                    -------------------------------------------\n                           `Déforestation 1996-2016 (%)`       \n                             (1)                   (2)         \n---------------------------------------------------------------\nGroupeTraitement          -8.031***             -6.660**       \n                           (2.831)               (2.958)       \n                                                               \ndist_ville                                       -0.013        \n                                                 (0.008)       \n                                                               \nConstant                  15.902***             18.013***      \n                           (1.959)               (2.341)       \n                                                               \n---------------------------------------------------------------\nObservations                 94                    90          \nR2                          0.080                 0.103        \nAdjusted R2                 0.070                 0.082        \nResidual Std. Error   13.713 (df = 92)      13.669 (df = 87)   \nF Statistic         8.046*** (df = 1; 92) 4.989*** (df = 2; 87)\n===============================================================\nNote:                               *p<0.1; **p<0.05; ***p<0.01\n\n\nApparemment, le traitement reste significatif une fois que l’on contrôle pour la distance aux villes.\n\n\n\n\nHlavac, Marek. 2022. Stargazer: Well-Formatted Regression and Summary Statistics Tables. https://CRAN.R-project.org/package=stargazer."
  },
  {
    "objectID": "06-matching_AP.html",
    "href": "06-matching_AP.html",
    "title": "7  Méthode d’appariement",
    "section": "",
    "text": "On a vu dans le chapitre précédent que les comparaisons simples réalisées entre les premières et les dernières aires à avoir été formellement protégées pose problème.\nOn va maintenant chercher à renforcer la comparabilité entre le goupe de traitment et le groupe de contrôle en réalisant un appariemment (cf. diapos de présentation).\nOn va utiliser le package {MatchIt}: ne pas hésiter à se référer à la documentation du package : [TODO: insérer le lien vers la doc]\nOn va commencer par réaliser quelques ajustements, car {MatchIt} requiert qu’aucune valeur des variables mobilisées ne soit manquante. On va donc retirer les observations comportant des NA.\n\n\nCode\nlibrary(tidyverse) # Simplifie la manipulation de données\nlibrary(lubridate) # Simplifie les opérations sur des dates\nlibrary(sf) # Pour traiter les données spatiales\nlibrary(MatchIt) # Pour réaliser les appariements.\nlibrary(cobalt) # Pour les tests d'équilibre sur l'appariement\nlibrary(gt) # Pour faire de jolies tables\nlibrary(stargazer) # Pour préssenter les résultats de régressions\n\n# Désactiver les notations scientifiques\noptions(scipen =999)\n# On recharge les données préparées dans le chapitre 3\nload(\"data/ch3_AP_Vahatra.rds\")\n\n# Harmoniser les données entre avant et après.\nload(\"data/rct_AP_Mada.rds\")\n\n\nrct_AP_Mada_noNA <- rct_AP_Mada %>%\n  # On enlève les observations pour lesquelles il manque des valeurs\n  filter(!is.na(`Déforestation 1996-2016 (%)`)) %>%\n  filter(!is.na(dist_ville)) %>%\n  # La vatiable de traitement doit être recodée en [0, 1]\n  mutate(traitement = ifelse(Groupe == \"Traitement\", 1, 0)) %>%\n  rename(surface_ha = `Surface (ha)`, \n         couv_foret_96 = `Couvert forestier en 1996 (%)`)\n\nrct_AP_Mada_noNA %>%\n  group_by(Groupe) %>%\n  summarize(`Nombre d'aires protégées` = n()) %>%\n  gt() %>%\n  tab_header(\"Observations par groupe avant appariemment\") %>%\n  tab_source_note(\"Source : Association Vahatra et Carvalho et al. 2018\")\n\n\n\n\n\n\n  \n    \n      Observations par groupe avant appariemment\n    \n    \n  \n  \n    \n      Groupe\n      Nombre d'aires protégées\n    \n  \n  \n    Controle\n47\n    Traitement\n43\n  \n  \n    \n      Source : Association Vahatra et Carvalho et al. 2018\n    \n  \n  \n\n\n\n\nPour commencer, on va estimer le un modèle qui estime dans quel mesure la propension pour une aire d’avoir été protégée avant 2015 dépend de sa taille, de son taux de couverture forestière en 1996, de son altitude, de son caractère accidenté et de sa distance d’une ville d’au moins 5000 habitants.\nCette spécification peut se représenter selon l’équation suivante : [TODO: revoir la spécification au format standard]\n\\[\nT = \\alpha + \\beta_{1}A + \\beta_{2}B + \\beta_{3}C + \\beta_{4}D + \\beta_{5}E + \\varepsilon\n\\tag{7.1}\\]\nOù Y est le traitement, A est la taille (surface en hectares, B le taux de couverture forestière en 1996, C l’altitude, D, le caractère accidenté et E le temps de parcours à une ville d’au moins 5000 habitants.\nCette même formule est encodée en R de la manière suivante :\n\npscor <- traitement ~  surface_ha + \n                       couv_foret_96 + \n                       altitude +\n                       indice_accidente + \n                       dist_ville\n\nOn va maintenant réaliser une régression pour connaître l’influence de ces facteurs dans la désignation des aires comme protégées.\n\nCode\nreg_select <- glm(formula = pscor,\n                  family = binomial(link = \"probit\"),\n                  data = rct_AP_Mada_noNA)\n\nstargazer(reg_select, type = \"html\")\n\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\ntraitement\n\n\n\n\n\n\n\n\nsurface_ha\n\n\n-0.00000\n\n\n\n\n\n\n(0.00000)\n\n\n\n\n\n\n\n\n\n\ncouv_foret_96\n\n\n0.005\n\n\n\n\n\n\n(0.006)\n\n\n\n\n\n\n\n\n\n\naltitude\n\n\n-0.0003\n\n\n\n\n\n\n(0.0004)\n\n\n\n\n\n\n\n\n\n\nindice_accidente\n\n\n0.004\n\n\n\n\n\n\n(0.023)\n\n\n\n\n\n\n\n\n\n\ndist_ville\n\n\n0.002**\n\n\n\n\n\n\n(0.001)\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n-0.498\n\n\n\n\n\n\n(0.364)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n90\n\n\n\n\nLog Likelihood\n\n\n-59.054\n\n\n\n\nAkaike Inf. Crit.\n\n\n130.108\n\n\n\n\n\n\n\n\nNote:\n\n\np<0.1; p<0.05; p<0.01\n\n\n\n\nOn va maintenant utiliser ce modèle pour comparer les aires protégées traitées en premier par rapport à celles traitées plus récemment.\n\n\nCode\n# Calcul du matching\ndef_96_16_match <- matchit(formula = pscor,\n                           family = binomial(link = \"probit\"),\n                           method = \"nearest\",\n                           discard = \"both\",\n                           replace = FALSE,\n                           distance = \"glm\",\n                           data = rct_AP_Mada_noNA)\n\nprint(def_96_16_match)\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching without replacement\n - distance: Propensity score [common support]\n             - estimated with logistic regression\n - common support: units from both groups dropped\n - number of obs.: 90 (original), 78 (matched)\n - target estimand: ATT\n - covariates: surface_ha, couv_foret_96, altitude, indice_accidente, dist_ville\n\n\nOn peut maintenant observer les équilibres entre les groupes traités et contrôle avant et après l’appariement.\n\n\nCode\nsummary(def_96_16_match)\n\n\n\nCall:\nmatchit(formula = pscor, data = rct_AP_Mada_noNA, method = \"nearest\", \n    distance = \"glm\", discard = \"both\", replace = FALSE, family = binomial(link = \"probit\"))\n\nSummary of Balance for All Data:\n                 Means Treated Means Control Std. Mean Diff. Var. Ratio\ndistance                0.5123        0.4462          0.4600     1.7294\nsurface_ha          64859.7293    71636.6002         -0.0856     0.5216\ncouv_foret_96          61.8218       55.4658          0.2363     1.1522\naltitude              538.6298      475.9134          0.1328     0.7177\nindice_accidente       12.0830       10.7187          0.1667     1.0636\ndist_ville            233.3141      152.0447          0.3811     2.1820\n                 eCDF Mean eCDF Max\ndistance            0.1409   0.2622\nsurface_ha          0.0910   0.2509\ncouv_foret_96       0.0795   0.2425\naltitude            0.0890   0.2103\nindice_accidente    0.0578   0.1390\ndist_ville          0.1333   0.2588\n\n\nSummary of Balance for Matched Data:\n                 Means Treated Means Control Std. Mean Diff. Var. Ratio\ndistance                0.4783        0.4712          0.0497     0.9995\nsurface_ha          67277.5891    56596.5970          0.1348     0.7366\ncouv_foret_96          60.8113       60.4309          0.0141     1.3400\naltitude              518.5203      503.7378          0.0313     0.8548\nindice_accidente       11.6356       11.6417         -0.0007     1.0171\ndist_ville            182.9262      166.4807          0.0771     0.8322\n                 eCDF Mean eCDF Max Std. Pair Dist.\ndistance            0.0379   0.1538          0.0883\nsurface_ha          0.1217   0.2821          1.0327\ncouv_foret_96       0.0473   0.1795          0.8761\naltitude            0.0490   0.1282          1.0065\nindice_accidente    0.0316   0.0769          1.1074\ndist_ville          0.0692   0.2051          0.3803\n\nSample Sizes:\n          Control Treated\nAll            47      43\nMatched        39      39\nUnmatched       6       0\nDiscarded       2       4\n\n\n\nExercice : Etudiez les tables ci-dessus. Quel effet a eu l’appariement sur l’équilibre des variables entre le groupe de traitement et le groupe de contrôle ? Combien d’observation ont été écartées.\n\nOn peut observer la distance entre groupe de traitement et de contrôle.\n\n\nCode\nplot(def_96_16_match, type = \"jitter\", interactive = FALSE)\n\n\n\n\n\nOn peut également représenter l’équilibre entre les variables avant et après traitement avec les graphiques suivants.\n\n\nCode\nbal.plot(def_96_16_match, var.name = \"dist_ville\", which = \"both\")\n\n\n\n\n\n\nExercice : Quel effet a eu l’appariement sur la varialbe de distance à la ville ? Les autres variables d’appariement produisent-elles un effet aussi visible ?\n\nLe modèle qu’on utilise pour estimer l’impact est très proche de celui exposé ci-dessus, à la différence que la variable de traitement passe dans la partie droite, et qu’elle est remplacée par la déforestation.\n\\[\nY = \\alpha + \\beta_{0}T + \\beta_{1}A + \\beta_{2}B + \\beta_{3}C + \\beta_{4}D + \\beta_{5}E + \\varepsilon\n\\]\nOù Y est la déforestation, T est le traitement, A est la taille (surface en hectares, B le taux de couverture forestière en 1996, C l’altitude, D, le caractère accidenté et E le temps de parcours à une ville d’au moins 5000 habitants.\nCette formule est codée en R de la manière suivante :\n\n\nCode\n# On extrait la donnée de l'appariement\n\n#| code-fold: false\nestimp <- `Déforestation 1996-2016 (%)` ~   \n                          traitement +\n                          surface_ha + \n                          couv_foret_96 + \n                          altitude +\n                          indice_accidente + \n                          dist_ville\n\n\nOn va donc réaliser une régression, en tenant compte des pondérations générées par l’algorithme d’appariement (variable “weight”).\n\n\nCode\n# On extrait les données de l'appariement\ndef_96_16_match_data <- match.data(def_96_16_match)\n# On effectue une régression simple avec la formule précédente\ndef_96_16_match_est <- lm(formula = estimp,\n                          data = def_96_16_match_data,\n                          weights = weights)\n# On visualise les résultats\nstargazer(def_96_16_match_est, type = \"text\")\n\n\n\n=================================================\n                         Dependent variable:     \n                    -----------------------------\n                    `Déforestation 1996-2016 (%)`\n-------------------------------------------------\ntraitement                    -6.781**           \n                               (3.166)           \n                                                 \nsurface_ha                     0.00000           \n                              (0.00002)          \n                                                 \ncouv_foret_96                  -0.083            \n                               (0.072)           \n                                                 \naltitude                        0.001            \n                               (0.005)           \n                                                 \nindice_accidente               -0.357            \n                               (0.260)           \n                                                 \ndist_ville                     -0.009            \n                               (0.015)           \n                                                 \nConstant                      25.457***          \n                               (4.826)           \n                                                 \n-------------------------------------------------\nObservations                     78              \nR2                              0.144            \nAdjusted R2                     0.072            \nResidual Std. Error       13.939 (df = 71)       \nF Statistic              1.992* (df = 6; 71)     \n=================================================\nNote:                 *p<0.1; **p<0.05; ***p<0.01\n\n\n\n7.0.1 Exercice simple\nAnalysez, interprétez et critiquez les résultats ci-dessus.\n\n\n7.0.2 Exercice intermédiaire\nAjoutez des variables d’interne et modifiez les paramètres de la fonction de matching.\n\n\n7.0.3 Exercice avancé\nRéalisez une analyse analogue avec les données de déforestation TMF. Rédigez une analyse interprétative."
  },
  {
    "objectID": "06b-matching_mailles.html#procédure-en-avecsans",
    "href": "06b-matching_mailles.html#procédure-en-avecsans",
    "title": "8  Appariement de mailles dans/hors aires protégées",
    "section": "8.1 Procédure en avec/sans",
    "text": "8.1 Procédure en avec/sans\nDans l’analyse par aire protégée, on a mené une analyse avant/après, c’est-à-dire qu’on a\nUne procédure détaillée est proposée dans https://github.com/openkfw/mapme.protectedareas\nOn commence ici par une approche naïve, dans le sens où on apparie simplement les zones dans les aires protégées avec les zones hors aires protégées pour expliquer le principe du matching (“appariement”, en français).\nLes données ne peuvent pas contenir de données manquantes sur les variables d’appariement, donc on les écarte.\n\n\nCode\nlibrary(tidyverse)\nlibrary(MatchIt)\nlibrary(stargazer)\nlibrary(sf)\nlibrary(cobalt)\nlibrary(tmap)\n# Taille des titres des cartes\ntaille_titres_cartes = 1\n\nload(\"data/grille_mada_summary_AP.rds\")\n\n# On référence le nom des variables qui vont servir à l'analyse\nvariables_analyse <- c(\"assetid\",\"treatment\",\"distance_minutes_5k_110mio\",\n                       \"tri_mean\", \"elevation_mean\", \"mean_clay_5_15cm\",\n                       \"treecover_2000\", \"var_treecover\")\n\n# On renomme le ficher 'df' (dataframe) : plus concis dans les commandes ensuite\ndf <- grille_mada_summary_AP %>%\n  # On supprime toutes les lignes pour lesquelles au moins 1 valeur variable \n  # est manquante parmi les variables d'analyse\n  mutate(treatment = position_ap == \"Intérieur\") %>% \n  drop_na(any_of(variables_analyse))\n\n\nOn analyse maintenant le score de propension.\n\n\nCode\n# Get propensity scores\nglm_out <- glm(treatment ~ \n                 distance_minutes_5k_110mio + \n                 mean_clay_5_15cm + \n                 tri_mean +\n                 elevation_mean + \n                 treecover_2000,  # Très étrange\n               family = binomial(link = \"probit\"),\n               data = df)\n\nstargazer(glm_out,\n          summary = TRUE,\n          type = \"text\",\n          title = \"Probit regression for matching frame \")\n\n\n\nProbit regression for matching frame\n======================================================\n                               Dependent variable:    \n                           ---------------------------\n                                    treatment         \n------------------------------------------------------\ndistance_minutes_5k_110mio          0.0004***         \n                                    (0.00003)         \n                                                      \nmean_clay_5_15cm                    -0.042***         \n                                     (0.002)          \n                                                      \ntri_mean                            0.015***          \n                                     (0.001)          \n                                                      \nelevation_mean                      0.0003***         \n                                    (0.00002)         \n                                                      \ntreecover_2000                      0.002***          \n                                    (0.00004)         \n                                                      \nConstant                            -1.449***         \n                                     (0.043)          \n                                                      \n------------------------------------------------------\nObservations                         117,610          \nLog Likelihood                     -23,367.050        \nAkaike Inf. Crit.                  46,746.090         \n======================================================\nNote:                      *p<0.1; **p<0.05; ***p<0.01\n\n\nOn visualise la localisation des cellules utilisées comme contrôles.\n\n\nCode\nm_out <- matchit(treatment ~ \n                   distance_minutes_5k_110mio + \n                   mean_clay_5_15cm + \n                   tri_mean +\n                   elevation_mean + \n                   treecover_2000,\n                 data = df,\n                 method = \"nearest\",\n                 replace = TRUE,\n                 # exact = ~ as.factor(NAME_0),\n                 distance = \"glm\", \n                 discard = \"both\", # common support: drop units from both groups \n                 link = \"probit\")\n\nprint(m_out)\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching with replacement\n - distance: Propensity score [common support]\n             - estimated with probit regression\n - common support: units from both groups dropped\n - number of obs.: 117610 (original), 12731 (matched)\n - target estimand: ATT\n - covariates: distance_minutes_5k_110mio, mean_clay_5_15cm, tri_mean, elevation_mean, treecover_2000\n\n\nCode\n# print(summary(m_out, un = FALSE))\nbal_table <- bal.tab(m_out, un = TRUE)\nprint(bal_table)\n\n\nBalance Measures\n                               Type Diff.Un Diff.Adj\ndistance                   Distance  0.6743   0.0001\ndistance_minutes_5k_110mio  Contin.  0.3110  -0.0441\nmean_clay_5_15cm            Contin.  0.0229  -0.0025\ntri_mean                    Contin.  0.4029  -0.0306\nelevation_mean              Contin.  0.2753  -0.0022\ntreecover_2000              Contin.  0.7104   0.0262\n\nSample sizes\n                       Control Treated\nAll                  110951.      6659\nMatched (ESS)          5439.42    6650\nMatched (Unweighted)   6081.      6650\nUnmatched            104721.         0\nDiscarded               149.         9\n\n\nCode\nm_data <- match.data(m_out) %>%\n  st_sf()\n# On charge le countour des frontières malgaches\nload(\"data/contour_mada.rds\")\n\n# On visualise les données appareillées\ntm_shape(contour_mada) +\n  tm_borders() +\n  tm_shape(m_data) +\n  tm_fill(col = \"treatment\", palette = \"Set1\", title = \"Groupes d'appariement\",\n          labels = c(\"Contrôle\", \"Traitement\")) +\n  tm_layout(legend.outside = TRUE,\n            main.title = \"Localisation des groupes de traitement et de contrôle\",\n            main.title.position = c(\"center\", \"top\"),\n            main.title.size = taille_titres_cartes)\n\n\n\n\n\nOn réalise la régression.\n\n\nCode\nmodele <- lm(formula = var_treecover ~\n               treatment +\n               distance_minutes_5k_110mio + \n               mean_clay_5_15cm + \n               tri_mean +\n               elevation_mean + \n               treecover_2000,\n             data = m_data,\n             weights = weights)\nstargazer(modele, type = \"text\")\n\n\n\n======================================================\n                               Dependent variable:    \n                           ---------------------------\n                                  var_treecover       \n------------------------------------------------------\ntreatment                           0.041***          \n                                     (0.003)          \n                                                      \ndistance_minutes_5k_110mio         0.00002***         \n                                    (0.00001)         \n                                                      \nmean_clay_5_15cm                    0.003***          \n                                    (0.0003)          \n                                                      \ntri_mean                            -0.003***         \n                                    (0.0002)          \n                                                      \nelevation_mean                      0.0001***         \n                                    (0.00000)         \n                                                      \ntreecover_2000                     -0.0004***         \n                                    (0.00001)         \n                                                      \nConstant                            -0.100***         \n                                     (0.009)          \n                                                      \n------------------------------------------------------\nObservations                         12,731           \nR2                                    0.191           \nAdjusted R2                           0.190           \nResidual Std. Error            0.151 (df = 12724)     \nF Statistic                499.650*** (df = 6; 12724) \n======================================================\nNote:                      *p<0.1; **p<0.05; ***p<0.01"
  },
  {
    "objectID": "07-avant_apres.html",
    "href": "07-avant_apres.html",
    "title": "9  Comparaison avant-après",
    "section": "",
    "text": "L’intuition initiale de cette stratégie est que le meilleur contrefactuel de l’AP est elle-même avant la mise en place du statut.\nAinsi, nous allons comparer pour chaque AP, les taux de déforestation entre les années qui précèdent la création de l’AP et les années qui suivent la création.\nEn revanche, comme vu dans la partie théorique, cette approche repose sur l’hypothèse que la seule différence entre les périodes est la mise en place de la politique.\nAutrement dit, le seul facteur entre ces différentes périodes qui impactent le taux de dégradation des forêts est la mise en place de l’AP.\nCi-dessous, un tableau représentant les dates de création des aires protégées.\n\n\nCode\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(sf)\nlibrary(gt)\n# Désactiver les notations scientifiques\noptions(scipen =999)\n\n# On reprend les données telles que préparées au chapitre 3\nload(\"data/ch3_AP_Vahatra.rds\")\n\nAP_Vahatra %>%\n  mutate(an_creation = year(date_creation)) %>%\n  select(nom, an_creation) %>%\n  ggplot(aes(x = an_creation)) +\n  geom_rect(xmin = 1995, xmax = 2016, ymin = 0, \n            ymax = 54, fill = \"yellow\", alpha = 0.3) +\n  geom_bar() +\n  xlim(c(NA, 2020)) + \n  geom_vline(xintercept = c(1990, 2020), col = \"red\") +\n  ylim(NA, 53) +\n  ggtitle(\"Dates de création des AP et de disponibilité\\ndes données TMF\")\n\n\n\n\n\nLes données mobilisées sont celles de TMF pour lesquelles on dispose d’un historique allant de 1990 à 2020. On se concentre sur les aires protégées dont le statut a été décrété entre ces deux dates.\nEn revanche, afin d’avoir non pas un unique taux de dégradation du couvert forestier mais une tendance (i.e l’évolution) de celui-ci, nous restreignons notre échantillon aux AP dont le statut a été octroyé entre 1995 et 2015.\nEn effet, si on se focalise uniquement sur le taux de déforestation juste avant et juste après, il se peut qu’un évènement ait impacté le taux de dégradation et ne représente pas réellement la dégradation du couvert forestier dans l’AP.\nPar exemple, si en t-1, il y a eu un énorme feu lié à un évènement naturel, alors nous risquons de surestimer la perte de couvert forestier avant et donc d’inférer à l’AP, un impact beaucoup plus bénéfique que ce qu’il est réellement.\nNotre échantillon final contient 72 AP (sur les 98 initiales de la base de données Vahatra _ en jaune sur le graphique).\nNous normalisons les dates d’octroi du statut d’AP c’est à dire qu’on transforme les années calendaires (1995, 1996,…) en année relative à la mise en place de l’AP.\nPar exemple, si une AP est créée en 2000 (qui correspondra à l’année 0), toutes les autres années seront exprimées relativement à celle-ci et donc, 1995 sera égale à -5 et 2005 à 5.\nCette transformation nous permet de pouvoir visualiser les données. Dans le tableau suivant, nous avons la moyenne annuelle de la surface (exprimée en hectare et en pourcentage) de l’AP qui a été dégradé sur les 5 années précédents et suivants la mise en place de l’AP.\n\n\nCode\n# Une fonction pour créer un jeu avec des dates normalisées\nans_vs_crea <- function(x, vars_commenct_par = \"TMFdeg_HA\",\n                       ans_marge = 5) {\n  avant_apres_abs <- AP_Vahatra %>%\n    st_drop_geometry() %>%\n    select(nom, date_creation, starts_with(vars_commenct_par)) %>%\n    filter(year(date_creation) >= 1995 & year(date_creation) <= 2017) %>%\n    pivot_longer(cols = starts_with(\"TMF\"),\n                 names_to = \"variable\",\n                 values_to = \"valeur\") %>%\n    mutate(an_valeur = str_extract(variable, \"[:digit:]{4}\"),\n           an_valeur = as.numeric(an_valeur),\n           an_creation = year(date_creation),\n           an_val_crea = an_valeur - an_creation,\n           sequence_crea = ifelse(an_val_crea < 0, \"Avant\",\n                                   ifelse(an_val_crea > 0, \"Après\", \"Création\"))) %>%\n    filter(an_val_crea >= ans_marge * -1 & an_val_crea <= ans_marge & an_val_crea != 0) %>%\n    mutate(sequence_crea = factor(sequence_crea, levels = c(\"Avant\", \"Après\")))\n}\n\n# Un jeu avec les dégradations 5 ans avant et 5 ans après\n## en valeur absolue\ndeg_avap_abs <- ans_vs_crea(AP_Vahatra, vars_commenct_par = \"TMFdeg_HA\",\n                       ans_marge = 5)\n## en valeur relative (ratio)\ndeg_avap_rel <- ans_vs_crea(AP_Vahatra, vars_commenct_par = \"TMFdeg_ratio\",\n                       ans_marge = 5)\n\nmoy_deg_avap_abs <- deg_avap_abs %>%\n  group_by(sequence_crea) %>%\n  summarise(`Moyenne sur 5 ans` = mean(valeur, na.rm = TRUE)) %>%\n  mutate(Indicateur = \"Surface en valeur absolue (ha)\")\n\nmoy_deg_avap_rel <- deg_avap_rel %>%\n  group_by(sequence_crea) %>%\n  summarise(`Moyenne sur 5 ans` = mean(valeur, na.rm = TRUE)*100) %>%\n  mutate(Indicateur = \"Surface en valeur relative (%)\")\n\nmoy_deg_avap <-bind_rows(moy_deg_avap_abs, moy_deg_avap_rel) %>%\n  mutate(`Moyenne sur 5 ans` = round(`Moyenne sur 5 ans`, 2)) %>%\n  pivot_wider(names_from = sequence_crea, values_from = `Moyenne sur 5 ans`) \n\ngt(moy_deg_avap) %>% \n  tab_header(title = \"Moyenne de dégradation annuelle sur 5 ans\")  %>% \n  tab_source_note(c(\"Source : TMF, Carvalho et al. 2018 et association Vahatra.\",\n                    \"Calculs des auteurs.\"))\n\n\n\n\n\n\n  \n    \n      Moyenne de dégradation annuelle sur 5 ans\n    \n    \n  \n  \n    \n      Indicateur\n      Avant\n      Après\n    \n  \n  \n    Surface en valeur absolue (ha)\n178.35\n264.25\n    Surface en valeur relative (%)\n0.49\n0.74\n  \n  \n    \n      Source : TMF, Carvalho et al. 2018 et association Vahatra.\n    \n    \n      Calculs des auteurs.\n    \n  \n  \n\n\n\n\nD’après le tableau ci-dessous, quelles conclusions pouvons-nous tirer ?\nOn peut aussi visualiser cette information sur les 10 plus grandes aires.\n\n\nCode\n# A compléter.\n\n\nOn va maintenant réaliser quelques tests statistiques pour analyser la significativité de ces différeces.\n\n\nCode\n# A completer."
  },
  {
    "objectID": "08-diff_in_diff.html#méthode-des-doubles-différences-échelonnées-staggered-matching",
    "href": "08-diff_in_diff.html#méthode-des-doubles-différences-échelonnées-staggered-matching",
    "title": "10  Doubles différences",
    "section": "10.1 Méthode des doubles différences échelonnées (staggered matching)",
    "text": "10.1 Méthode des doubles différences échelonnées (staggered matching)\nPour réaliser un diff-in-diff, on va utiliser la méthode de différence de différences échelonnées élaboréé par Callaway et Sant’Anna (2021b) et diffusée dans la librairie {did} (Callaway and Sant’Anna 2021a).\nLa spécification employée peut se traduire de la manière suivante :\nOn l’applique aux aires protégées et à leur déforestation entre 1990 et 2021. On commence par préparer le jeu de données tel qu’attendu par {did}, de sorte à obtenir :\n\n\nCode\n# On installe le package {did} si pas encore installé\nif (!(\"did\" %in% installed.packages())) {\n  install.packages(\"did\")\n}\nlibrary(did) # Pour des doubles-différences échelonnées\nlibrary(tidyverse) # Pur faciliter la manipulation de données\nlibrary(lubridate) # Pour modifier les dates\nlibrary(gt) # Pour de jolis tableaux\n\nload(\"data/ch3_AP_Vahatra.rds\") # On charge les données préparées au chapitre 3\noptions(scipen = 999) # On désactive les notations scientifiques\n\n# On prépare le jeu de données au format attendu par {did}\nap_did <- AP_Vahatra %>%\n  select(nom, date_creation, num_atlas = num_atlas_, starts_with(\"TMF\"),\n         cat_iucn = cat__iucn) %>%\n  mutate(annee_creation = year(date_creation)) %>%\n  pivot_longer(cols = starts_with(\"TMF\"), \n               names_to = \"TMF_variable\", \n               values_to = \"TMF_value\") %>%\n  mutate(annee = str_extract(TMF_variable, \"[:digit:]{4}\"),\n         annee = as.numeric(annee),\n         traitee = ifelse(annee > annee_creation, 1, 0),\n         TMF_variable = str_remove(TMF_variable, \"TMF\"),\n         TMF_variable = str_remove(TMF_variable, \"_[:digit:]{4}\"),\n         group = 1) %>%\n  pivot_wider(names_from = TMF_variable, values_from = TMF_value)\n\ngt(slice(ap_did, 20:30)) %>%\n  tab_header(title = \"Jeu de données 1990-2020 préparé pour {did}\",\n             subtitle = \"Echantillon des 10 lignes\") %>%\n  tab_source_note(\"Source : Aires protégées d'AP Vahatra, données TMF\")\n\n\n\n\n\n\n  \n    \n      Jeu de données 1990-2020 préparé pour {did}\n    \n    \n      Echantillon des 10 lignes\n    \n  \n  \n    \n      nom\n      date_creation\n      num_atlas\n      cat_iucn\n      annee_creation\n      annee\n      traitee\n      group\n      deg_HA\n      ly_HA\n      deg_ratio\n      ly_ratio\n    \n  \n  \n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2009\n0\n1\n3.51\n4.50\n0.008347603\n0.0107020548\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2010\n0\n1\n5.04\n6.21\n0.013160987\n0.0162162162\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2011\n0\n1\n1.62\n4.05\n0.004230317\n0.0105757932\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2012\n0\n1\n14.58\n16.56\n0.038072855\n0.0432432432\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2013\n0\n1\n18.36\n11.61\n0.047943596\n0.0303172738\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2014\n0\n1\n0.54\n1.62\n0.001410106\n0.0042303173\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2015\n0\n1\n3.33\n5.67\n0.008695652\n0.0148061105\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2016\n1\n1\n6.30\n15.12\n0.016451234\n0.0394829612\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2017\n1\n1\n21.24\n31.14\n0.055464160\n0.0813160987\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2018\n1\n1\n2.16\n0.18\n0.005640423\n0.0004700353\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2019\n1\n1\n2.34\n0.18\n0.006110458\n0.0004700353\n  \n  \n    \n      Source : Aires protégées d'AP Vahatra, données TMF\n    \n  \n  \n\n\n\n\nPour rappel, on récapitule les années d’assignation :\n\n\nCode\nap_did %>%\n  select(nom, annee_creation) %>%\n  filter(annee_creation > 1990) %>%\n  unique() %>%\n  group_by(annee_creation) %>%\n  summarize(`Nombre d'AP créées cette année` = n()) %>%\n  gt() %>%\n  tab_header(title = \"Années de création des aires protégées\")\n\n\n\n\n\n\n  \n    \n      Années de création des aires protégées\n    \n    \n  \n  \n    \n      annee_creation\n      Nombre d'AP créées cette année\n    \n  \n  \n    1991\n1\n    1997\n9\n    1998\n2\n    2002\n1\n    2003\n1\n    2004\n1\n    2007\n2\n    2011\n2\n    2012\n1\n    2015\n53"
  },
  {
    "objectID": "08-diff_in_diff.html#double-différences-pour-la-déforestation",
    "href": "08-diff_in_diff.html#double-différences-pour-la-déforestation",
    "title": "10  Doubles différences",
    "section": "10.2 Double différences pour la déforestation",
    "text": "10.2 Double différences pour la déforestation\nOn passe maintenant à l’estimation pour la déforestation.\n\n\nCode\nattgt_apmada_def <- att_gt(yname = \"ly_ratio\",\n                        tname = \"annee\",\n                        idname = \"num_atlas\",\n                        gname = \"annee_creation\",\n                        data = ap_did,\n                       control_group = \"notyettreated\")\nggdid(attgt_apmada_def) +\n  theme(axis.text.x =  element_text(angle = 45, hjust = 1))\n\n\n\n\n\nPeu d’effet ressortent graphiquement.\nOn aggrège les effets de traitment pour l’ensemble de la période\n\n\nCode\nagg.simple <- aggte(attgt_apmada_def, type = \"simple\", na.rm = TRUE)\n\nsummary(agg.simple)\n\n\n\nCall:\naggte(MP = attgt_apmada_def, type = \"simple\", na.rm = TRUE)\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. <https://doi.org/10.1016/j.jeconom.2020.12.001>, <https://arxiv.org/abs/1803.09015> \n\n     ATT    Std. Error     [ 95%  Conf. Int.] \n -0.0001         0.001    -0.0021      0.0019 \n\n\n---\nSignif. codes: `*' confidence band does not cover 0\n\nControl Group:  Not Yet Treated,  Anticipation Periods:  0\nEstimation Method:  Doubly Robust\n\n\nCode\n# gt(summary(agg.simple)) %>%\n#   tab_header(title = \"Effet aggrégé pour les traités de 1991 à 2011\") %>%\n#   tab_footnote(\"Résultats encore préliminaire à confirmer (erreurs possibles)\")\n\n\nPour la déforestation, on ne voit aucun effet net des aires protégées (ATT très faible et non significativement différent de 0). Mais la taille de l’échantillon est extrêmement restreinte et il est on ne peut pas vraiment en tirer d’interprétation."
  },
  {
    "objectID": "08-diff_in_diff.html#double-différence-pour-la-dégradation",
    "href": "08-diff_in_diff.html#double-différence-pour-la-dégradation",
    "title": "10  Doubles différences",
    "section": "10.3 Double différence pour la dégradation",
    "text": "10.3 Double différence pour la dégradation\nOn modifie la spécification en remplaçant la variable à expliquer “déforestation” par “dégradation” (cf. présentation des sources dans ?sec-recap_donnees).\n\n\nCode\nattgt_apmada_deg <- att_gt(yname = \"deg_ratio\",\n                        tname = \"annee\",\n                        idname = \"num_atlas\",\n                        gname = \"annee_creation\",\n                        data = ap_did,\n                       control_group = \"notyettreated\")\nggdid(attgt_apmada_deg) +\n  theme(axis.text.x =  element_text(angle = 45, hjust = 1))\n\n\n\n\n\nOn aggrège les résultats :\n\n\nCode\nagg.simple <- aggte(attgt_apmada_deg, type = \"simple\", na.rm = TRUE)\n\nsummary(agg.simple)\n\n\n\nCall:\naggte(MP = attgt_apmada_deg, type = \"simple\", na.rm = TRUE)\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. <https://doi.org/10.1016/j.jeconom.2020.12.001>, <https://arxiv.org/abs/1803.09015> \n\n     ATT    Std. Error     [ 95%  Conf. Int.] \n -0.0052        0.0027    -0.0105      0.0001 \n\n\n---\nSignif. codes: `*' confidence band does not cover 0\n\nControl Group:  Not Yet Treated,  Anticipation Periods:  0\nEstimation Method:  Doubly Robust\n\n\nCode\n# gt(summary(agg.simple)) %>%\n#   tab_header(title = \"Effet aggrégé pour les traités de 1991 à 2011\") %>%\n#   tab_footnote(\"Résultats encore préliminaire à confirmer (erreurs possibles)\")\n\n\nLà encore, l’effet mesuré est très faible et non significativement différent de 0.\n\nMise en garde : l’échantillon utilisé à titre d’exemple ici est trop petit pour cette méthode. Il convient de préférer une analyse avec un plus grand nombre d’observation, par exemple en se focalisant sur des pixels ou des cellules."
  },
  {
    "objectID": "09-bibliographie.html",
    "href": "09-bibliographie.html",
    "title": "References",
    "section": "",
    "text": "Barnier, Julien. 2022. “Introduction à r Et Au Tidyverse.”\nhttps://juba.github.io/tidyverse/index.html.\n\n\nBédécarrats, Florent, and Alexandre Hobeika. 2017. “Une\nAlternative à Word : Écrire En\nRMarkdown.” Billet. Data Sciences Sociales.\nhttp://data.hypotheses.org/1144.\n\n\nCallaway, Brantly, and Pedro H. C. Sant’Anna. 2021a.\n“Difference-in-Differences with Multiple Time Periods.” https://doi.org/10.1016/j.jeconom.2020.12.001.\n\n\n———. 2021b. “Difference-in-Differences with Multiple Time\nPeriods.” Journal of Econometrics, Themed Issue:\nTreatment Effect 1, 225 (2): 200–230. https://doi.org/10.1016/j.jeconom.2020.12.001.\n\n\nCarvalho, Fabio, Kerry A. Brown, Adam D. Gordon, Gabriel U. Yesuf, Marie\nJeanne Raherilalao, Achille P. Raselimanana, Voahangy Soarimalala, and\nSteven M. Goodman. 2020. “Methods for Prioritizing Protected Areas\nUsing Individual and Aggregate Rankings.” Environmental\nConservation 47 (2): 113–22. https://doi.org/10.1017/S0376892920000090.\n\n\nGaliana, Lino, and Olivier Meslin, eds. 2022. “utilitR:\nDocumentation Collaborative Sur r.” https://www.book.utilitr.org/.\n\n\nGoodman, Steven M., Marie Jeanne Raherilalao, Sébastien Wohlhauser, Jean\nClarck N. Rabenandrasana, Herivololona M. Rakotondratsimba, Fanja\nAndriamialisoa, and Malalarisoa Razafimpahanana. 2018. Les Aires\nProtégées Terrestres de Madagascar: Leur Histoire,\nDescription Et Biote. Association Vahatra.\n\n\nGörgen, Darius A., and Om Prakash Bhandari. 2022.\nMapme.biodiversity: Efficient Monitoring of Global Biodiversity\nPortfolios. https://CRAN.R-project.org/package=mapme.biodiversity.\n\n\nGrolemund, Garrett, and Hadley Wickham. 2022. R for Data Science:\nImport, Tidy, Transform, Visualize, and Model Data. 1st edition.\nSebastopol, CA: O’Reilly Media. https://r4ds.had.co.nz/.\n\n\nHlavac, Marek. 2022. Stargazer: Well-Formatted Regression and\nSummary Statistics Tables. https://CRAN.R-project.org/package=stargazer.\n\n\nKluve, Jochen, Johannes Schielain, Melvin Wong, and Yota Eilers. 2022.\n“The KfW Protected Areas\nPortfolio: A Rigorous Impact\nEvaluation.” Frankfürt.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2022.\nGeocomputation with R. Boca Raton London New York: Routledge.\nhttps://geocompr.robinlovelace.net/."
  },
  {
    "objectID": "10-fondamentaux_R.html#installation",
    "href": "10-fondamentaux_R.html#installation",
    "title": "11  Fondamentaux pour l’utilisation de R",
    "section": "11.1 Installation",
    "text": "11.1 Installation\nOn installe R et RStudio :\n\nTélécharger et installer R (page officielle proposant les installateurs et instructions d’installation)\nTélécharger et installer RStudio (page officielle proposant les installateurs et instructions d’installation)\n\n\nA noter : un nombre croissant d’utilisteurs utilise VS Code. C’est une alternative intéressante, pour des utilisateurs déjà confirmés :"
  },
  {
    "objectID": "10-fondamentaux_R.html#import-des-données",
    "href": "10-fondamentaux_R.html#import-des-données",
    "title": "11  Fondamentaux pour l’utilisation de R",
    "section": "11.2 Import des données",
    "text": "11.2 Import des données\nEn très bref :\n\nPour les fichiers excle ou csv, dans le volet “files” du panneau en bas à droite de l’interface Rstudio, cliquer sur le fichier en question et utiliser l’assistant d’import.\nPour les autres fichiers, se référer à l’aide ou chercher sur internet.\n\nVoir cette page pour un topo sur les imports. [#TODO:Préciser l’url]"
  },
  {
    "objectID": "10-fondamentaux_R.html#principes-élémentaires-de-manipulation-de-données-en-r",
    "href": "10-fondamentaux_R.html#principes-élémentaires-de-manipulation-de-données-en-r",
    "title": "11  Fondamentaux pour l’utilisation de R",
    "section": "11.3 Principes élémentaires de manipulation de données en R",
    "text": "11.3 Principes élémentaires de manipulation de données en R\nOn se focalise ici sur quelques aspects qui peuvent être requis pour la manipulation du code et à la marge. Points à traiter :\n\nLe signe <- correspond à l’assignation d’une valeur à une variable. Il est presque équivalent à =, avec quelques différences dans certaines circonstances particulières, qui fait qu’on privilégie toujours <-.\n\n\n# Ce qui suit un dièze n'est pas exécuté. On appelle ça un commentaire.\n\n# On commence par faire une opération simple\n3 + 4\n\n[1] 7\n\n# Ce qui équivaut à :\na <- 3\nb <- 4\na + b\n\n[1] 7\n\n# Et on peut également stocker le résultat dans une nouvelle variable \nc <- a + b\nc\n\n[1] 7\n\n\n\nR est constitué de fonctions. De nombreuses fonctions prédéfinies sont contenues dans la base de R ou dans des packages qu’on ajoute (qu’on verra plus tard). La meilleure manière de comprendre ce qu’est une fonction est d’en créer une soi même.\n\n\n# On crée une fonction \"ajoute\" qui prend deux paramètres. \n# x est Un premier et y est celui qu'on ajoute\najoute <- function(x, y) {\n  x + y\n}\n\n# On peut maintenant utiliser cette foncction\najoute(3, 4)\n\n[1] 7\n\n# On peut effectuer les mêmes opérations. Les valeurs a et b sont encore \n# en mémoire, donc on peut faire :\najoute(a, b)\n\n[1] 7\n\nc <- ajoute(a, b)\nc\n\n[1] 7\n\najoute(c, a)\n\n[1] 10\n\n\nLes fonctions disposent d’une documentation qu’on peut explorer en utilisant l’aide.\n\nExercice pratique sur la recherche d ’aide.\n\n\nLe signe %>% est un “tuyau”. On peut le lire à haute voix comme “ensuite”. Par exemple :\n\n\nlibrary(tidyverse)\n\nd <- a %>%\n  ajoute(b) %>%\n  ajoute(c)\n\nd\n\n[1] 14\n\n\n\nna.rm : Les valeurs manquantes, notées NA dans R (certaines peuvent avoir pour valeur NaN). On utilise na.rm pour les éluder dans les opérations simples.\n\n\n# On commence par créer les variables (les colonnes du tableau)\nnoms <- c(\"John\", \"Jack\", \"Cindy\", \"Samantha\")\nsexe <- c(\"homme\", \"homme\", \"femme\", \"femme\")\nages <- c(42, 57, 24, NA)\npoids <- c(87, 73, NA, NA)\ntailles <- c(174, 198, 192, 164)\n\n# On les rassemble dans un tableau \nma_table <- data.frame(noms, sexe, ages, poids, tailles)\n\n# On peut faire une moyenne sur les tailles car on a toutes les variables\nmean(ma_table$tailles)\n\n[1] 182\n\nsum(ma_table$tailles)\n\n[1] 728\n\n# Mais la moyenne ne fonctionne pas immédiatement sur les poids ou les âges\n# car il manque des variables\nmean(ma_table$ages)\n\n[1] NA\n\nsum(ma_table$poids)\n\n[1] NA\n\n# Il faut préciser qu'il faut omettre les variables manquantes\nmean(ma_table$ages, na.rm = TRUE)\n\n[1] 41\n\nsum(ma_table$poids, na.rm = TRUE)\n\n[1] 160\n\n\n\nverbes :\n\nselect : choisir des colonnes\nfilter : choisir des lignes\nmutate : modifier des valeurs\ngroup_by : variables pour des tris\ncréer des filtres : summarise\n\n\n\n# Un exemple qui combine ces opérations\nma_table %>%\n  filter(!is.na(ages)) %>%\n  select(sexe, ages, tailles, poids) %>%\n  group_by(sexe) %>%\n  summarise(nb_pers = n(),\n            somme_poids = sum(poids, na.rm = TRUE),\n            taille_max = max(tailles, na.rm = TRUE),\n            age_moy = mean(ages, na.rm = TRUE))\n\n# A tibble: 2 × 5\n  sexe  nb_pers somme_poids taille_max age_moy\n  <chr>   <int>       <dbl>      <dbl>   <dbl>\n1 femme       1           0        192    24  \n2 homme       2         160        198    49.5\n\n\nDeux opérations particulière requièrent une étude plus approfondies\n\nJointures : fusionner deux tableaux par une variable d’identification (“clé”)\nPivots : passer un tableau de long en large\nmap : appliquer des opérations successives\nunnest : déplier des listes imbriquées\n\nUn point important est relatif aux types des variables : numérique, catégorielles, textes, dates, spatiales… En général, les opérations ne peuvent concerner que des variables du même type. Les fonctions sont souvent contraignantes quant aux types des variables qu’elles prennent comme arguments.\nPour une analyse plus approfondie, voir juba."
  },
  {
    "objectID": "10-fondamentaux_R.html#produire-des-cartes-simples-avec-r",
    "href": "10-fondamentaux_R.html#produire-des-cartes-simples-avec-r",
    "title": "11  Fondamentaux pour l’utilisation de R",
    "section": "11.4 Produire des cartes simples avec R",
    "text": "11.4 Produire des cartes simples avec R\n\n# Les librairies requises \nlibrary(sf) # pour traiter des données spatiales\nlibrary(tmap) # pour faire des cartes\n\n# Charger une carte des \ncarte <- st_read(\"data/Vahatra/Vahatra98AP.shp\") %>%\n  st_make_valid()\n\nReading layer `Vahatra98AP' from data source \n  `/home/onyxia/work/conservation-deforestation-madagascar/data/Vahatra/Vahatra98AP.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 98 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 43.25742 ymin: -25.60502 xmax: 50.47724 ymax: -11.98301\nCRS:           NA\n\n# On projette la carte\ntm_shape(carte) +\n  tm_polygons(col = \"cat__iucn\") +\n  tmap_options(check.and.fix = TRUE) + # Parce qu'on a quelques erreurs topo\n  tm_layout(legend.outside = TRUE)"
  },
  {
    "objectID": "10-fondamentaux_R.html#produire-des-graphiques-avec-r",
    "href": "10-fondamentaux_R.html#produire-des-graphiques-avec-r",
    "title": "11  Fondamentaux pour l’utilisation de R",
    "section": "11.5 Produire des graphiques avec R",
    "text": "11.5 Produire des graphiques avec R\nOn utilise le package ggplot, avec la syntaxe suivante.\n\n\nCode\n# On réalise un graphique simple\ncarte %>%\n  ggplot(aes(x = cat__iucn, y = hectares)) +\n  geom_col()\n\n\n\n\n\n\n\n\n\nBarnier, Julien. 2022. “Introduction à r Et Au Tidyverse.” https://juba.github.io/tidyverse/index.html.\n\n\nGaliana, Lino, and Olivier Meslin, eds. 2022. “utilitR: Documentation Collaborative Sur r.” https://www.book.utilitr.org/.\n\n\nGörgen, Darius A., and Om Prakash Bhandari. 2022. Mapme.biodiversity: Efficient Monitoring of Global Biodiversity Portfolios. https://CRAN.R-project.org/package=mapme.biodiversity.\n\n\nGrolemund, Garrett, and Hadley Wickham. 2022. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. 1st edition. Sebastopol, CA: O’Reilly Media. https://r4ds.had.co.nz/.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2022. Geocomputation with R. Boca Raton London New York: Routledge. https://geocompr.robinlovelace.net/."
  },
  {
    "objectID": "06b-matching_mailles.html",
    "href": "06b-matching_mailles.html",
    "title": "8  Appariement de mailles dans/hors aires protégées",
    "section": "",
    "text": "Dans l’analyse par aire protégée, on a mené une analyse avant/après, c’est-à-dire qu’on a\nUne procédure détaillée est proposée dans https://github.com/openkfw/mapme.protectedareas\nOn commence ici par une approche naïve, dans le sens où on apparie simplement les zones dans les aires protégées avec les zones hors aires protégées pour expliquer le principe du matching (“appariement”, en français).\nLes données ne peuvent pas contenir de données manquantes sur les variables d’appariement, donc on les écarte.\n\n\nCode\nlibrary(tidyverse)\nlibrary(MatchIt)\nlibrary(stargazer)\nlibrary(sf)\nlibrary(cobalt)\nlibrary(tmap)\n\n# Taille des titres des cartes\ntaille_titres_cartes = 1\n\nload(\"data/grille_mada_summary_AP.rds\")\n\n# On référence le nom des variables qui vont servir à l'analyse\nvariables_analyse <- c(\"assetid\",\"treatment\",\"distance_minutes_5k_110mio\",\n                       \"tri_mean\", \"elevation_mean\", \"mean_clay_5_15cm\",\n                       \"treecover_2000\", \"var_treecover\")\n\n# On renomme le ficher 'df' (dataframe) : plus concis dans les commandes ensuite\ndf <- grille_mada_summary_AP %>%\n  # On supprime toutes les lignes pour lesquelles au moins 1 valeur variable \n  # est manquante parmi les variables d'analyse\n  mutate(treatment = position_ap == \"Intérieur\") %>% \n  drop_na(any_of(variables_analyse))\n\n\nOn analyse maintenant le score de propension.\n\nCode\n# Get propensity scores\nglm_out <- glm(treatment ~ \n                 distance_minutes_5k_110mio + \n                 mean_clay_5_15cm + \n                 tri_mean +\n                 elevation_mean + \n                 treecover_2000,  \n               family = binomial(link = \"probit\"),\n               data = df)\n\nstargazer(glm_out,\n          summary = TRUE,\n          type = \"html\",\n          title = \"Probit regression for matching frame \")\n\n\n\n\nProbit regression for matching frame\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\ntreatment\n\n\n\n\n\n\n\n\ndistance_minutes_5k_110mio\n\n\n0.0004***\n\n\n\n\n\n\n(0.00003)\n\n\n\n\n\n\n\n\n\n\nmean_clay_5_15cm\n\n\n-0.042***\n\n\n\n\n\n\n(0.002)\n\n\n\n\n\n\n\n\n\n\ntri_mean\n\n\n0.015***\n\n\n\n\n\n\n(0.001)\n\n\n\n\n\n\n\n\n\n\nelevation_mean\n\n\n0.0003***\n\n\n\n\n\n\n(0.00002)\n\n\n\n\n\n\n\n\n\n\ntreecover_2000\n\n\n0.002***\n\n\n\n\n\n\n(0.00004)\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n-1.449***\n\n\n\n\n\n\n(0.043)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n117,610\n\n\n\n\nLog Likelihood\n\n\n-23,367.050\n\n\n\n\nAkaike Inf. Crit.\n\n\n46,746.090\n\n\n\n\n\n\n\n\nNote:\n\n\np<0.1; p<0.05; p<0.01\n\n\n\n\nOn visualise la localisation des cellules utilisées comme contrôles.\n\n\nCode\nm_out <- matchit(treatment ~ \n                   distance_minutes_5k_110mio + \n                   mean_clay_5_15cm + \n                   tri_mean +\n                   elevation_mean + \n                   treecover_2000,\n                 data = df,\n                 method = \"nearest\",\n                 replace = TRUE,\n                 # exact = ~ as.factor(NAME_0),\n                 distance = \"glm\", \n                 discard = \"both\", # common support: drop units from both groups \n                 link = \"probit\")\n\nprint(m_out)\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching with replacement\n - distance: Propensity score [common support]\n             - estimated with probit regression\n - common support: units from both groups dropped\n - number of obs.: 117610 (original), 12731 (matched)\n - target estimand: ATT\n - covariates: distance_minutes_5k_110mio, mean_clay_5_15cm, tri_mean, elevation_mean, treecover_2000\n\n\nCode\n# print(summary(m_out, un = FALSE))\nbal_table <- bal.tab(m_out, un = TRUE)\nprint(bal_table)\n\n\nBalance Measures\n                               Type Diff.Un Diff.Adj\ndistance                   Distance  0.6743   0.0001\ndistance_minutes_5k_110mio  Contin.  0.3110  -0.0441\nmean_clay_5_15cm            Contin.  0.0229  -0.0025\ntri_mean                    Contin.  0.4029  -0.0306\nelevation_mean              Contin.  0.2753  -0.0022\ntreecover_2000              Contin.  0.7104   0.0262\n\nSample sizes\n                       Control Treated\nAll                  110951.      6659\nMatched (ESS)          5439.42    6650\nMatched (Unweighted)   6081.      6650\nUnmatched            104721.         0\nDiscarded               149.         9\n\n\nCode\nm_data <- match.data(m_out) %>%\n  st_sf()\n# On charge le countour des frontières malgaches\nload(\"data/contour_mada.rds\")\n\n# On visualise les données appareillées\ntm_shape(contour_mada) +\n  tm_borders() +\n  tm_shape(m_data) +\n  tm_fill(col = \"treatment\", palette = \"Set1\", title = \"Groupes d'appariement\",\n          labels = c(\"Contrôle\", \"Traitement\")) +\n  tm_layout(legend.outside = TRUE,\n            main.title = \"Localisation des groupes de traitement et de contrôle\",\n            main.title.position = c(\"center\", \"top\"),\n            main.title.size = taille_titres_cartes)\n\n\n\n\n\nOn réalise la régression.\n\nCode\nmodele <- lm(formula = var_treecover ~\n               treatment +\n               distance_minutes_5k_110mio + \n               mean_clay_5_15cm + \n               tri_mean +\n               elevation_mean + \n               treecover_2000,\n             data = m_data,\n             weights = weights)\nmodele_print <- stargazer(modele, type = \"html\")\n\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nvar_treecover\n\n\n\n\n\n\n\n\ntreatment\n\n\n0.041***\n\n\n\n\n\n\n(0.003)\n\n\n\n\n\n\n\n\n\n\ndistance_minutes_5k_110mio\n\n\n0.00002***\n\n\n\n\n\n\n(0.00001)\n\n\n\n\n\n\n\n\n\n\nmean_clay_5_15cm\n\n\n0.003***\n\n\n\n\n\n\n(0.0003)\n\n\n\n\n\n\n\n\n\n\ntri_mean\n\n\n-0.003***\n\n\n\n\n\n\n(0.0002)\n\n\n\n\n\n\n\n\n\n\nelevation_mean\n\n\n0.0001***\n\n\n\n\n\n\n(0.00000)\n\n\n\n\n\n\n\n\n\n\ntreecover_2000\n\n\n-0.0004***\n\n\n\n\n\n\n(0.00001)\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n-0.100***\n\n\n\n\n\n\n(0.009)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n12,731\n\n\n\n\nR2\n\n\n0.191\n\n\n\n\nAdjusted R2\n\n\n0.190\n\n\n\n\nResidual Std. Error\n\n\n0.151 (df = 12724)\n\n\n\n\nF Statistic\n\n\n499.650*** (df = 6; 12724)\n\n\n\n\n\n\n\n\nNote:\n\n\np<0.1; p<0.05; p<0.01"
  },
  {
    "objectID": "08-diff_in_diff.html",
    "href": "08-diff_in_diff.html",
    "title": "10  Doubles différences",
    "section": "",
    "text": "Cliquer ici pour télécharger le diaporama de présentation de la méthode diffusé en atelier.\nPour le cas d’études auquel on s’intéresse, on n’a pas une seule date de mise en oeuvre de l’intervention à évaluer, mais un échelonnement des dates de mises en oeuvre. En d’autres termes, les aires protégées ont été créées à des dates différentes. Pour ce type de cas, on va utiliser une variante de la méthode de différence de doubles différences, qui est dite “échelonnées” (staggered diff-in-diff). Cette méthode a été conceptualisée par Callaway et Sant’Anna (2021b) et ces mêmes auteurs ont programmé mise en oeuvre pour R dans la librairie {did} (Callaway and Sant’Anna 2021a)."
  },
  {
    "objectID": "04-donnees_en_mailles.html",
    "href": "04-donnees_en_mailles.html",
    "title": "4  Données en mailles",
    "section": "",
    "text": "Une approche courante consiste à diviser le territoires en mailles, carrées ou en forme d’alvéoles d’abeilles (hexagones), et à calculer des indicateurs pour chacune de ces mailles."
  },
  {
    "objectID": "03-donnees_deforestation.html",
    "href": "03-donnees_deforestation.html",
    "title": "3  Couvert forestier",
    "section": "",
    "text": "Pour commencer, on récupère le travail réalisé par Carvalho et al. (2020) qui complète les informations physiques de Goodman et al. (2018) avec des données relatives au couvert forestier en 1996, 2006 et 2016 et la diversité d’espèces présentes.\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(sf)\nlibrary(wdpar)\nlibrary(mapme.biodiversity)\n\n# Voir le chapitre \"Fondamentaux R\" pour une aide à l'import.\nsup2 <- read_xlsx(\"data/Carvalho2018sup2.xlsx\", # Enplacement du fichier\n                  skip = 8, # Premières lignes du tableau excel à ne pas lire\n                  n_max = 101,  # on ne lit pas les dernières lignes (notes)\n                  col_types = c(\"text\", \"text\", \"text\", \"text\", \n        \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \n        \"numeric\", \"numeric\", \"numeric\", \"numeric\"))\nsup4 <- read_xlsx(\"data/Carvalho2018sup4.xlsx\", skip = 6,\n                  col_types = c(\"text\", \"numeric\", \"text\", \"numeric\", \"numeric\", \n        \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\"))\n        \n\n# Carvalho et al. 2008 document in their supp. material 2: \"The three parcels that made up\n# Andohahela (Parcels I, II and III) comprised different types of dominant vegetation and\n# associated animal species, and were exposed to distinct pressures. Andohahela was analysed\n# in its entirety (site number 57), as well as separated\"\n\nsup2 <- sup2 %>% \n  mutate(PA = recode(PA, `Andohahela complete` = \"Andohahela\"),\n         num_atlas_ = as.integer(`Site number`))\n\nsup4 <- sup4 %>%\n  filter(`Habitat type` == \"TOTAL\") %>%\n  mutate(num_atlas_ = as.numeric(Parcel))\n\n\nload(\"data/ch2_AP_Vahatra.rds\")\n\nAP_Vahatra <- AP_Vahatra %>%\n  left_join(sup2, by = \"num_atlas_\") %>%\n  relocate(PA, .after = nom) %>%\n  left_join(sup4, by = \"num_atlas_\")\n\n\nOn complète cette information avec des données de couvert forestier."
  },
  {
    "objectID": "08-diff_in_diff.html#doubles-différences-échelonnées-avec-contrôles",
    "href": "08-diff_in_diff.html#doubles-différences-échelonnées-avec-contrôles",
    "title": "10  Doubles différences",
    "section": "10.4 Doubles différences échelonnées avec contrôles",
    "text": "10.4 Doubles différences échelonnées avec contrôles\nL’analyse précédente ne tient pas compte de certains facteurs dont on a vu qu’ils pouvaient influencer à la fois la sélection, mais aussi la déforestation, en particulier l’altitude, la qualité des sols, le temps de parcours à la ville la plus proche, ou encore le caractère accidenté du terrain. On va rajouter ces variables comme contrôles, en continuant à comparer les aires protégées créées avant 2015 avec celles créées en 2015.\n\n\nCode\n# On passe ces paramètres au package did\natt_mailles_def_crtl <- att_gt(yname = \"treecover\",\n                               tname = \"years\",\n                               idname = \"assetid\",\n                               gname = \"an_creation\",\n                               xformla = ~ distance_minutes_5k_110mio + \n                                 mean_clay_5_15cm + tri_mean + elevation_mean,\n                               data = grille_mada_AP_long,\n                               control_group = \"notyettreated\")\n# On visualise les résultats.\nggdid(att_mailles_def_crtl) +\n  theme(axis.text.x =  element_text(angle = 45, hjust = 1))\n\n\n\n\n\nOn aggrège les résultats.\n\n\nCode\nagg.simple <- aggte(att_mailles_def_crtl, type = \"simple\", na.rm = TRUE)\n\nsummary(agg.simple)\n\n\n\nCall:\naggte(MP = att_mailles_def_crtl, type = \"simple\", na.rm = TRUE)\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. <https://doi.org/10.1016/j.jeconom.2020.12.001>, <https://arxiv.org/abs/1803.09015> \n\n     ATT    Std. Error     [ 95%  Conf. Int.] \n -2.2241        1.1574    -4.4925      0.0443 \n\n\n---\nSignif. codes: `*' confidence band does not cover 0\n\nControl Group:  Not Yet Treated,  Anticipation Periods:  0\nEstimation Method:  Doubly Robust\n\n\nL’ajout des quatre variables de contrôle (temps de trajet à une ville, altitude, caractère accidenté du terrain et teneur en argile du sol) réduit l’effet moyen sur les traités (ATT) estimé et conduit l’intervalle de confiance à englober 0, ce qui nous empêche de conclure avec assurance à la présence d’effets significatifs.\nOn doit toutefois souligner : 1) Qu’on s’appuie ici sur les données GFC et qu’on ne dispose donc de recul que depuis 2000, à la différence des données TMF qui démarrent en 1990, avec toutefois une fiabilité limitée pour la première décennie ; 2) que la méthode prenant comme contrefactuel les zones situées dans des aires protégées en 2015 réduit la taille d’échantillon et la période d’observation, par opposition à l’approche consistant à utiliser comme contrefactuel des zones non traitées, par exemples celles désignées par matching dans le [Chapitre Chapter 8\nUne autre solution consisterait à utiliser des matching pour utiliser comme contrefactuel des zones hors aires protégées.\n\n\n\n\nCallaway, Brantly, and Pedro H. C. Sant’Anna. 2021a. “Difference-in-Differences with Multiple Time Periods.” https://doi.org/10.1016/j.jeconom.2020.12.001.\n\n\n———. 2021b. “Difference-in-Differences with Multiple Time Periods.” Journal of Econometrics, Themed Issue: Treatment Effect 1, 225 (2): 200–230. https://doi.org/10.1016/j.jeconom.2020.12.001."
  },
  {
    "objectID": "08-diff_in_diff.html#application-aux-polygones-daires-protégées",
    "href": "08-diff_in_diff.html#application-aux-polygones-daires-protégées",
    "title": "10  Doubles différences",
    "section": "10.2 Application aux polygones d’aires protégées",
    "text": "10.2 Application aux polygones d’aires protégées\nLa spécification employée peut se traduire de la manière suivante :\nOn l’applique aux aires protégées et à leur déforestation entre 1990 et 2021. On commence par préparer le jeu de données tel qu’attendu par {did}, de sorte à obtenir :\n\n\nCode\nlibrary(did) # Pour des doubles-différences échelonnées\nlibrary(tidyverse) # Pur faciliter la manipulation de données\nlibrary(lubridate) # Pour modifier les dates\nlibrary(gt) # Pour de jolis tableaux\n\nload(\"data/ch3_AP_Vahatra.rds\") # On charge les données préparées au chapitre 3\noptions(scipen = 999) # On désactive les notations scientifiques\n\n# On prépare le jeu de données au format attendu par {did}\nap_did <- AP_Vahatra %>%\n  select(nom, date_creation, num_atlas = num_atlas_, starts_with(\"TMF\"),\n         cat_iucn = cat__iucn) %>%\n  mutate(annee_creation = year(date_creation)) %>%\n  pivot_longer(cols = starts_with(\"TMF\"), \n               names_to = \"TMF_variable\", \n               values_to = \"TMF_value\") %>%\n  mutate(annee = str_extract(TMF_variable, \"[:digit:]{4}\"),\n         annee = as.numeric(annee),\n         traitee = ifelse(annee > annee_creation, 1, 0),\n         TMF_variable = str_remove(TMF_variable, \"TMF\"),\n         TMF_variable = str_remove(TMF_variable, \"_[:digit:]{4}\"),\n         group = 1) %>%\n  pivot_wider(names_from = TMF_variable, values_from = TMF_value)\n\ngt(slice(ap_did, 20:30)) %>%\n  tab_header(title = \"Jeu de données 1990-2020 préparé pour {did}\",\n             subtitle = \"Echantillon des 10 lignes\") %>%\n  tab_source_note(\"Source : Aires protégées d'AP Vahatra, données TMF\")\n\n\n\n\n\n\n  \n    \n      Jeu de données 1990-2020 préparé pour {did}\n    \n    \n      Echantillon des 10 lignes\n    \n  \n  \n    \n      nom\n      date_creation\n      num_atlas\n      cat_iucn\n      annee_creation\n      annee\n      traitee\n      group\n      deg_HA\n      ly_HA\n      deg_ratio\n      ly_ratio\n    \n  \n  \n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2009\n0\n1\n3.51\n4.50\n0.008347603\n0.0107020548\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2010\n0\n1\n5.04\n6.21\n0.013160987\n0.0162162162\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2011\n0\n1\n1.62\n4.05\n0.004230317\n0.0105757932\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2012\n0\n1\n14.58\n16.56\n0.038072855\n0.0432432432\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2013\n0\n1\n18.36\n11.61\n0.047943596\n0.0303172738\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2014\n0\n1\n0.54\n1.62\n0.001410106\n0.0042303173\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2015\n0\n1\n3.33\n5.67\n0.008695652\n0.0148061105\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2016\n1\n1\n6.30\n15.12\n0.016451234\n0.0394829612\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2017\n1\n1\n21.24\n31.14\n0.055464160\n0.0813160987\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2018\n1\n1\n2.16\n0.18\n0.005640423\n0.0004700353\n    Agnakatrika\n2015-04-28\n54\nVI\n2015\n2019\n1\n1\n2.34\n0.18\n0.006110458\n0.0004700353\n  \n  \n    \n      Source : Aires protégées d'AP Vahatra, données TMF\n    \n  \n  \n\n\n\n\nPour rappel, on récapitule les années d’assignation :\n\n\nCode\nap_did %>%\n  select(nom, annee_creation) %>%\n  filter(annee_creation > 1990) %>%\n  unique() %>%\n  group_by(annee_creation) %>%\n  summarize(`Nombre d'AP créées cette année` = n()) %>%\n  gt() %>%\n  tab_header(title = \"Années de création des aires protégées\")\n\n\n\n\n\n\n  \n    \n      Années de création des aires protégées\n    \n    \n  \n  \n    \n      annee_creation\n      Nombre d'AP créées cette année\n    \n  \n  \n    1991\n1\n    1997\n9\n    1998\n2\n    2002\n1\n    2003\n1\n    2004\n1\n    2007\n2\n    2011\n2\n    2012\n1\n    2015\n53\n  \n  \n  \n\n\n\n\nOn passe maintenant à l’estimation pour la déforestation.\n\n\nCode\nattgt_apmada_def <- att_gt(yname = \"ly_ratio\",\n                        tname = \"annee\",\n                        idname = \"num_atlas\",\n                        gname = \"annee_creation\",\n                        data = ap_did,\n                       control_group = \"notyettreated\")\nggdid(attgt_apmada_def) +\n  theme(axis.text.x =  element_text(angle = 45, hjust = 1))\n\n\n\n\n\nPeu d’effet ressortent graphiquement.\nOn aggrège les effets de traitment pour l’ensemble de la période\n\n\nCode\nagg.simple <- aggte(attgt_apmada_def, type = \"simple\", na.rm = TRUE)\n\nsummary(agg.simple)\n\n\n\nCall:\naggte(MP = attgt_apmada_def, type = \"simple\", na.rm = TRUE)\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. <https://doi.org/10.1016/j.jeconom.2020.12.001>, <https://arxiv.org/abs/1803.09015> \n\n     ATT    Std. Error     [ 95%  Conf. Int.] \n -0.0001         0.001     -0.002      0.0018 \n\n\n---\nSignif. codes: `*' confidence band does not cover 0\n\nControl Group:  Not Yet Treated,  Anticipation Periods:  0\nEstimation Method:  Doubly Robust\n\n\nCode\n# gt(summary(agg.simple)) %>%\n#   tab_header(title = \"Effet aggrégé pour les traités de 1991 à 2011\") %>%\n#   tab_footnote(\"Résultats encore préliminaire à confirmer (erreurs possibles)\")\n\n\nPour la déforestation, on ne voit aucun effet net des aires protégées (ATT très faible et non significativement différent de 0). Mais la taille de l’échantillon est extrêmement restreinte et il est on ne peut pas vraiment en tirer d’interprétation.\n\nMise en garde : l’échantillon utilisé à titre d’exemple ici est trop petit pour cette méthode. Il convient de préférer une analyse avec un plus grand nombre d’observation, par exemple en se focalisant sur des pixels ou des cellules."
  },
  {
    "objectID": "08-diff_in_diff.html#application-aux-données-par-mailles",
    "href": "08-diff_in_diff.html#application-aux-données-par-mailles",
    "title": "10  Doubles différences",
    "section": "10.3 Application aux données par mailles",
    "text": "10.3 Application aux données par mailles\nL’analyse reposant par aire protégée rassemble un nombre trop faible d’observations. On va donc procéder en réalisant l’analyse par maille. On va donc avoir une observation par hexagone de 5 km2, pour lequel on dispose du couvert forestier par année, de l’année de création de l’aire protégée. La première analyse est une première régression simple n’incluant pas de variables de contrôle. On commence par visualiser les tendances.\n\n\nCode\nlibrary(sf)\nload(\"data/grille_mada_AP.rds\") # On charge les données préparées au chapitre 4\n\n# On \"déplie\" les données de déforestation, ce qui produit un format long\ngrille_mada_AP_long <- grille_mada_AP %>%\n  unnest(cols = treecover_area_and_emissions)\n\n# On passe ces paramètres au package did\natt_mailles_def <- att_gt(yname = \"treecover\",\n                         tname = \"years\",\n                         idname = \"assetid\",\n                         gname = \"an_creation\",\n                         data = grille_mada_AP_long,\n                         control_group = \"notyettreated\")\n# On visualise les résultats.\nggdid(att_mailles_def) +\n  theme(axis.text.x =  element_text(angle = 45, hjust = 1))\n\n\n\n\n\nOn aggrège à nouveau les résultats de traitements pour l’ensemble de la période, ce qui produit le résumé suivant.\n\n\nCode\nagg.simple <- aggte(att_mailles_def, type = \"simple\", na.rm = TRUE)\n\nsummary(agg.simple)\n\n\n\nCall:\naggte(MP = att_mailles_def, type = \"simple\", na.rm = TRUE)\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. <https://doi.org/10.1016/j.jeconom.2020.12.001>, <https://arxiv.org/abs/1803.09015> \n\n     ATT    Std. Error     [ 95%  Conf. Int.]  \n -3.4758        0.6693    -4.7876      -2.164 *\n\n\n---\nSignif. codes: `*' confidence band does not cover 0\n\nControl Group:  Not Yet Treated,  Anticipation Periods:  0\nEstimation Method:  Doubly Robust\n\n\nLes résultats indiquent une baisse de la déforestation. TODO : coefficents à interpréter."
  }
]